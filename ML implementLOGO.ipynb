{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.274603Z",
     "iopub.status.busy": "2025-02-02T19:38:53.274384Z",
     "iopub.status.idle": "2025-02-02T19:38:53.278266Z",
     "shell.execute_reply": "2025-02-02T19:38:53.277467Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.274583Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.279583Z",
     "iopub.status.busy": "2025-02-02T19:38:53.279230Z",
     "iopub.status.idle": "2025-02-02T19:38:53.296252Z",
     "shell.execute_reply": "2025-02-02T19:38:53.295310Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.279552Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"./feature_image\"\n",
    "contestants = os.listdir(f\"{base_path}\")\n",
    "contestants = [c for c in contestants if c.endswith('csv')]\n",
    "add_data_path=\"./data_img_info_csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xử lý NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.297222Z",
     "iopub.status.busy": "2025-02-02T19:38:53.297015Z",
     "iopub.status.idle": "2025-02-02T19:38:53.448996Z",
     "shell.execute_reply": "2025-02-02T19:38:53.448249Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.297205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>...</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "      <th>img_name</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017239</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.176891</td>\n",
       "      <td>0.341711</td>\n",
       "      <td>0.028478</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.416213</td>\n",
       "      <td>0.601805</td>\n",
       "      <td>0.537354</td>\n",
       "      <td>0.211898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297471</td>\n",
       "      <td>0.045166</td>\n",
       "      <td>0.989468</td>\n",
       "      <td>0.470132</td>\n",
       "      <td>0.182868</td>\n",
       "      <td>0.682754</td>\n",
       "      <td>./image/P14/P14_1659070888638.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030872</td>\n",
       "      <td>0.009780</td>\n",
       "      <td>0.125229</td>\n",
       "      <td>0.264078</td>\n",
       "      <td>0.030885</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.532647</td>\n",
       "      <td>0.546128</td>\n",
       "      <td>0.187422</td>\n",
       "      <td>0.341496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628678</td>\n",
       "      <td>0.065833</td>\n",
       "      <td>0.990498</td>\n",
       "      <td>0.501712</td>\n",
       "      <td>0.313960</td>\n",
       "      <td>0.630475</td>\n",
       "      <td>./image/P14/P14_1659085749056.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.219520</td>\n",
       "      <td>0.173419</td>\n",
       "      <td>0.070296</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.506919</td>\n",
       "      <td>0.464037</td>\n",
       "      <td>0.232327</td>\n",
       "      <td>0.461129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479015</td>\n",
       "      <td>0.245514</td>\n",
       "      <td>0.990322</td>\n",
       "      <td>0.193106</td>\n",
       "      <td>0.368260</td>\n",
       "      <td>0.850828</td>\n",
       "      <td>./image/P14/P14_1659684037468.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007522</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.454181</td>\n",
       "      <td>0.181890</td>\n",
       "      <td>0.040242</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.275839</td>\n",
       "      <td>0.508276</td>\n",
       "      <td>0.269019</td>\n",
       "      <td>0.458627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819013</td>\n",
       "      <td>0.641877</td>\n",
       "      <td>0.937381</td>\n",
       "      <td>0.077706</td>\n",
       "      <td>0.319819</td>\n",
       "      <td>0.190604</td>\n",
       "      <td>./image/P14/P14_1659265517964.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024187</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.089908</td>\n",
       "      <td>0.288213</td>\n",
       "      <td>0.039413</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.543699</td>\n",
       "      <td>0.591552</td>\n",
       "      <td>0.371097</td>\n",
       "      <td>0.553130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.342236</td>\n",
       "      <td>0.050512</td>\n",
       "      <td>0.979466</td>\n",
       "      <td>0.422746</td>\n",
       "      <td>0.056997</td>\n",
       "      <td>0.569246</td>\n",
       "      <td>./image/P14/P14_1658984695198.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>0.040957</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.068325</td>\n",
       "      <td>0.171963</td>\n",
       "      <td>0.032893</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.670815</td>\n",
       "      <td>0.792422</td>\n",
       "      <td>0.662862</td>\n",
       "      <td>0.146113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.254034</td>\n",
       "      <td>0.063396</td>\n",
       "      <td>0.983158</td>\n",
       "      <td>0.445436</td>\n",
       "      <td>0.105169</td>\n",
       "      <td>0.638492</td>\n",
       "      <td>./image/P14/P14_1659279866187.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.145236</td>\n",
       "      <td>0.122815</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.650567</td>\n",
       "      <td>0.637243</td>\n",
       "      <td>0.314642</td>\n",
       "      <td>0.136442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>0.270353</td>\n",
       "      <td>0.974202</td>\n",
       "      <td>0.458458</td>\n",
       "      <td>0.115001</td>\n",
       "      <td>0.273430</td>\n",
       "      <td>./image/P14/P14_1659456638127.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.202055</td>\n",
       "      <td>0.284258</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.423687</td>\n",
       "      <td>0.624641</td>\n",
       "      <td>0.367987</td>\n",
       "      <td>0.292672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645095</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.900835</td>\n",
       "      <td>0.509297</td>\n",
       "      <td>0.077086</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>./image/P14/P14_1659456537639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.097032</td>\n",
       "      <td>0.256737</td>\n",
       "      <td>0.053264</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.559576</td>\n",
       "      <td>0.672477</td>\n",
       "      <td>0.596553</td>\n",
       "      <td>0.303114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.201306</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.470552</td>\n",
       "      <td>0.115043</td>\n",
       "      <td>0.567455</td>\n",
       "      <td>./image/P14/P14_1659510069849.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.481779</td>\n",
       "      <td>0.074605</td>\n",
       "      <td>0.030746</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.392362</td>\n",
       "      <td>0.596630</td>\n",
       "      <td>0.365489</td>\n",
       "      <td>0.304782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.674624</td>\n",
       "      <td>0.100138</td>\n",
       "      <td>0.986878</td>\n",
       "      <td>0.398863</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.681527</td>\n",
       "      <td>./image/P14/P14_1658932945727.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         anger   disgust      fear  happiness   sadness  surprise   neutral  \\\n",
       "0     0.017239  0.015235  0.176891   0.341711  0.028478  0.004233  0.416213   \n",
       "1     0.030872  0.009780  0.125229   0.264078  0.030885  0.006509  0.532647   \n",
       "2     0.005416  0.013230  0.219520   0.173419  0.070296  0.011200  0.506919   \n",
       "3     0.007522  0.009384  0.454181   0.181890  0.040242  0.030942  0.275839   \n",
       "4     0.024187  0.010670  0.089908   0.288213  0.039413  0.003910  0.543699   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "1915  0.040957  0.010263  0.068325   0.171963  0.032893  0.004782  0.670815   \n",
       "1916  0.009720  0.003048  0.145236   0.122815  0.060651  0.007962  0.650567   \n",
       "1917  0.029612  0.012102  0.202055   0.284258  0.032657  0.015629  0.423687   \n",
       "1918  0.013094  0.010975  0.097032   0.256737  0.053264  0.009323  0.559576   \n",
       "1919  0.007007  0.006672  0.481779   0.074605  0.030746  0.006829  0.392362   \n",
       "\n",
       "          AU01      AU02      AU04  ...      AU17  AU20      AU23      AU24  \\\n",
       "0     0.601805  0.537354  0.211898  ...  0.324528   1.0  0.297471  0.045166   \n",
       "1     0.546128  0.187422  0.341496  ...  0.377041   0.0  0.628678  0.065833   \n",
       "2     0.464037  0.232327  0.461129  ...  0.459882   1.0  0.479015  0.245514   \n",
       "3     0.508276  0.269019  0.458627  ...  0.637235   1.0  0.819013  0.641877   \n",
       "4     0.591552  0.371097  0.553130  ...  0.369656   1.0  0.342236  0.050512   \n",
       "...        ...       ...       ...  ...       ...   ...       ...       ...   \n",
       "1915  0.792422  0.662862  0.146113  ...  0.280971   1.0  0.254034  0.063396   \n",
       "1916  0.637243  0.314642  0.136442  ...  0.389752   0.0  0.760976  0.270353   \n",
       "1917  0.624641  0.367987  0.292672  ...  0.322887   1.0  0.645095  0.068958   \n",
       "1918  0.672477  0.596553  0.303114  ...  0.302141   1.0  0.547257  0.201306   \n",
       "1919  0.596630  0.365489  0.304782  ...  0.453735   1.0  0.674624  0.100138   \n",
       "\n",
       "          AU25      AU26      AU28      AU43  \\\n",
       "0     0.989468  0.470132  0.182868  0.682754   \n",
       "1     0.990498  0.501712  0.313960  0.630475   \n",
       "2     0.990322  0.193106  0.368260  0.850828   \n",
       "3     0.937381  0.077706  0.319819  0.190604   \n",
       "4     0.979466  0.422746  0.056997  0.569246   \n",
       "...        ...       ...       ...       ...   \n",
       "1915  0.983158  0.445436  0.105169  0.638492   \n",
       "1916  0.974202  0.458458  0.115001  0.273430   \n",
       "1917  0.900835  0.509297  0.077086  0.406576   \n",
       "1918  0.998685  0.470552  0.115043  0.567455   \n",
       "1919  0.986878  0.398863  0.058895  0.681527   \n",
       "\n",
       "                               img_name  level  \n",
       "0     ./image/P14/P14_1659070888638.png      0  \n",
       "1     ./image/P14/P14_1659085749056.png      0  \n",
       "2     ./image/P14/P14_1659684037468.png      0  \n",
       "3     ./image/P14/P14_1659265517964.png      0  \n",
       "4     ./image/P14/P14_1658984695198.png      0  \n",
       "...                                 ...    ...  \n",
       "1915  ./image/P14/P14_1659279866187.png      0  \n",
       "1916  ./image/P14/P14_1659456638127.png      0  \n",
       "1917  ./image/P14/P14_1659456537639.png      0  \n",
       "1918  ./image/P14/P14_1659510069849.png      0  \n",
       "1919  ./image/P14/P14_1658932945727.png      0  \n",
       "\n",
       "[1920 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in contestants:\n",
    "    temp = pd.read_csv(f\"{base_path}/{c}\")\n",
    "    temp = temp.dropna()\n",
    "#     temp =temp .drop('Unnamed: 0',axis=1)\n",
    "    temp['level'] = temp['level'].astype(float).astype(int)\n",
    "    temp=temp.loc[:,~temp.columns.str.contains('Unnamed',regex=True)]\n",
    "    os.remove(f\"{base_path}/{c}\")\n",
    "    temp.to_csv(f\"{base_path}/{c}\", index=False)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "person=[c.split('_')[0] for c in contestants]\n",
    "person=list(set(person))\n",
    "for per in person:\n",
    "    if len(contestants)<30:\n",
    "        break\n",
    "    contestant_split=[i for i in contestants if per in i]\n",
    "    merge=[]\n",
    "    for i in contestant_split:\n",
    "        temp = pd.read_csv(f\"{base_path}/{i}\")\n",
    "        os.remove(f\"{base_path}/{i}\")\n",
    "        merge.append(temp)\n",
    "    merge_df=pd.concat(merge,axis=0)\n",
    "    merge_df=merge_df.reset_index(drop=True)\n",
    "    merge_df.to_csv(f\"{base_path}/{per}.csv\", index=False)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.450042Z",
     "iopub.status.busy": "2025-02-02T19:38:53.449778Z",
     "iopub.status.idle": "2025-02-02T19:38:53.506199Z",
     "shell.execute_reply": "2025-02-02T19:38:53.505352Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.450020Z"
    }
   },
   "outputs": [],
   "source": [
    "depression = dict()\n",
    "contestants = os.listdir(f\"{base_path}\")\n",
    "contestants = [c for c in contestants if c.endswith('csv')]\n",
    "for c in contestants:\n",
    "    if not c.endswith('csv'):\n",
    "        continue\n",
    "    if c =='P27.csv':\n",
    "        continue\n",
    "    temp = pd.read_csv(f\"{base_path}/{c}\")\n",
    "    depression[c] = list(temp[\"level\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('P19.csv', [1]), ('P31.csv', [0]), ('P25.csv', [0]), ('P24.csv', [1]), ('P30.csv', [1]), ('P18.csv', [1]), ('P33.csv', [0]), ('P23.csv', [0]), ('P36.csv', [0]), ('P34.csv', [0]), ('P20.csv', [0]), ('P08.csv', [0]), ('P21.csv', [1, 0]), ('P35.csv', [0]), ('P38.csv', [0]), ('P10.csv', [0, 1]), ('P13.csv', [0]), ('P12.csv', [1]), ('P16.csv', [0]), ('P17.csv', [1]), ('P15.csv', [1, 0]), ('P29.csv', [0]), ('P28.csv', [0]), ('P14.csv', [0])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.507395Z",
     "iopub.status.busy": "2025-02-02T19:38:53.507117Z",
     "iopub.status.idle": "2025-02-02T19:38:53.514403Z",
     "shell.execute_reply": "2025-02-02T19:38:53.513507Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.507367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P31.csv',\n",
       " 'P25.csv',\n",
       " 'P33.csv',\n",
       " 'P23.csv',\n",
       " 'P36.csv',\n",
       " 'P34.csv',\n",
       " 'P20.csv',\n",
       " 'P08.csv',\n",
       " 'P35.csv',\n",
       " 'P38.csv',\n",
       " 'P13.csv',\n",
       " 'P16.csv',\n",
       " 'P29.csv',\n",
       " 'P28.csv',\n",
       " 'P14.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([key for key, value in depression.items() if value[0] == 0 and len(value) == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.515617Z",
     "iopub.status.busy": "2025-02-02T19:38:53.515336Z",
     "iopub.status.idle": "2025-02-02T19:38:53.528372Z",
     "shell.execute_reply": "2025-02-02T19:38:53.527684Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.515597Z"
    }
   },
   "outputs": [],
   "source": [
    "# (depression)\n",
    "# len(os.listdir(base_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chia train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', '.DS_Store', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n"
     ]
    }
   ],
   "source": [
    "contestants = os.listdir(f\"{base_path}\")\n",
    "print(contestants)\n",
    "contestants = [c for c in contestants if c.endswith('csv')]\n",
    "print(contestants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.529515Z",
     "iopub.status.busy": "2025-02-02T19:38:53.529235Z",
     "iopub.status.idle": "2025-02-02T19:38:53.543598Z",
     "shell.execute_reply": "2025-02-02T19:38:53.542782Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.529485Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "both = [key for key, value in depression.items() if len(value) == 2]\n",
    "# both.pop('P17.csv')\n",
    "contestants=[c for c in contestants if c.endswith('csv')]\n",
    "testPerson = [int(random.choice(only1).split('.')[0].split('P')[1])] + [int(random.choice(only0).split('.')[0].split('P')[1])]\n",
    "allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "trainPerson = [a for a in allPerson if a not in testPerson]\n",
    "# testPerson = [8]\n",
    "# trainPerson = [21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>...</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "      <th>img_name</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.374994</td>\n",
       "      <td>0.102363</td>\n",
       "      <td>0.049852</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>0.435509</td>\n",
       "      <td>0.713220</td>\n",
       "      <td>0.510258</td>\n",
       "      <td>0.059922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535557</td>\n",
       "      <td>0.490966</td>\n",
       "      <td>0.935579</td>\n",
       "      <td>0.121045</td>\n",
       "      <td>0.333033</td>\n",
       "      <td>0.121158</td>\n",
       "      <td>./image/P19/P19_1659487998833.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011412</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.171314</td>\n",
       "      <td>0.144660</td>\n",
       "      <td>0.163057</td>\n",
       "      <td>0.040847</td>\n",
       "      <td>0.466711</td>\n",
       "      <td>0.674876</td>\n",
       "      <td>0.313608</td>\n",
       "      <td>0.280145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635475</td>\n",
       "      <td>0.157254</td>\n",
       "      <td>0.975519</td>\n",
       "      <td>0.468108</td>\n",
       "      <td>0.318228</td>\n",
       "      <td>0.165630</td>\n",
       "      <td>./image/P19/P19_1659020214976.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.025150</td>\n",
       "      <td>0.251343</td>\n",
       "      <td>0.275955</td>\n",
       "      <td>0.048502</td>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.370671</td>\n",
       "      <td>0.538187</td>\n",
       "      <td>0.284743</td>\n",
       "      <td>0.386870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.679930</td>\n",
       "      <td>0.900595</td>\n",
       "      <td>0.114604</td>\n",
       "      <td>0.304304</td>\n",
       "      <td>0.082065</td>\n",
       "      <td>./image/P19/P19_1659075503842.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.194381</td>\n",
       "      <td>0.039042</td>\n",
       "      <td>0.111313</td>\n",
       "      <td>0.022853</td>\n",
       "      <td>0.619285</td>\n",
       "      <td>0.711540</td>\n",
       "      <td>0.427390</td>\n",
       "      <td>0.073868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498661</td>\n",
       "      <td>0.593501</td>\n",
       "      <td>0.636757</td>\n",
       "      <td>0.147229</td>\n",
       "      <td>0.222992</td>\n",
       "      <td>0.079755</td>\n",
       "      <td>./image/P19/P19_1659021205080.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.185530</td>\n",
       "      <td>0.082221</td>\n",
       "      <td>0.074113</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.645222</td>\n",
       "      <td>0.608201</td>\n",
       "      <td>0.277692</td>\n",
       "      <td>0.214240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.397525</td>\n",
       "      <td>0.039843</td>\n",
       "      <td>0.996547</td>\n",
       "      <td>0.306116</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.117396</td>\n",
       "      <td>./image/P19/P19_1659355704725.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>0.040957</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.068325</td>\n",
       "      <td>0.171963</td>\n",
       "      <td>0.032893</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.670815</td>\n",
       "      <td>0.792422</td>\n",
       "      <td>0.662862</td>\n",
       "      <td>0.146113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.254034</td>\n",
       "      <td>0.063396</td>\n",
       "      <td>0.983158</td>\n",
       "      <td>0.445436</td>\n",
       "      <td>0.105169</td>\n",
       "      <td>0.638492</td>\n",
       "      <td>./image/P14/P14_1659279866187.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.145236</td>\n",
       "      <td>0.122815</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.650567</td>\n",
       "      <td>0.637243</td>\n",
       "      <td>0.314642</td>\n",
       "      <td>0.136442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>0.270353</td>\n",
       "      <td>0.974202</td>\n",
       "      <td>0.458458</td>\n",
       "      <td>0.115001</td>\n",
       "      <td>0.273430</td>\n",
       "      <td>./image/P14/P14_1659456638127.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.202055</td>\n",
       "      <td>0.284258</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.423687</td>\n",
       "      <td>0.624641</td>\n",
       "      <td>0.367987</td>\n",
       "      <td>0.292672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645095</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.900835</td>\n",
       "      <td>0.509297</td>\n",
       "      <td>0.077086</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>./image/P14/P14_1659456537639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.097032</td>\n",
       "      <td>0.256737</td>\n",
       "      <td>0.053264</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.559576</td>\n",
       "      <td>0.672477</td>\n",
       "      <td>0.596553</td>\n",
       "      <td>0.303114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.201306</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.470552</td>\n",
       "      <td>0.115043</td>\n",
       "      <td>0.567455</td>\n",
       "      <td>./image/P14/P14_1659510069849.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.481779</td>\n",
       "      <td>0.074605</td>\n",
       "      <td>0.030746</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.392362</td>\n",
       "      <td>0.596630</td>\n",
       "      <td>0.365489</td>\n",
       "      <td>0.304782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.674624</td>\n",
       "      <td>0.100138</td>\n",
       "      <td>0.986878</td>\n",
       "      <td>0.398863</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.681527</td>\n",
       "      <td>./image/P14/P14_1658932945727.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34364 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         anger   disgust      fear  happiness   sadness  surprise   neutral  \\\n",
       "0     0.013205  0.005202  0.374994   0.102363  0.049852  0.018875  0.435509   \n",
       "1     0.011412  0.002000  0.171314   0.144660  0.163057  0.040847  0.466711   \n",
       "2     0.014839  0.025150  0.251343   0.275955  0.048502  0.013539  0.370671   \n",
       "3     0.011381  0.001744  0.194381   0.039042  0.111313  0.022853  0.619285   \n",
       "4     0.005302  0.002227  0.185530   0.082221  0.074113  0.005386  0.645222   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "1915  0.040957  0.010263  0.068325   0.171963  0.032893  0.004782  0.670815   \n",
       "1916  0.009720  0.003048  0.145236   0.122815  0.060651  0.007962  0.650567   \n",
       "1917  0.029612  0.012102  0.202055   0.284258  0.032657  0.015629  0.423687   \n",
       "1918  0.013094  0.010975  0.097032   0.256737  0.053264  0.009323  0.559576   \n",
       "1919  0.007007  0.006672  0.481779   0.074605  0.030746  0.006829  0.392362   \n",
       "\n",
       "          AU01      AU02      AU04  ...      AU17  AU20      AU23      AU24  \\\n",
       "0     0.713220  0.510258  0.059922  ...  0.466907   0.0  0.535557  0.490966   \n",
       "1     0.674876  0.313608  0.280145  ...  0.418187   1.0  0.635475  0.157254   \n",
       "2     0.538187  0.284743  0.386870  ...  0.407967   1.0  0.589100  0.679930   \n",
       "3     0.711540  0.427390  0.073868  ...  0.371300   0.0  0.498661  0.593501   \n",
       "4     0.608201  0.277692  0.214240  ...  0.430974   1.0  0.397525  0.039843   \n",
       "...        ...       ...       ...  ...       ...   ...       ...       ...   \n",
       "1915  0.792422  0.662862  0.146113  ...  0.280971   1.0  0.254034  0.063396   \n",
       "1916  0.637243  0.314642  0.136442  ...  0.389752   0.0  0.760976  0.270353   \n",
       "1917  0.624641  0.367987  0.292672  ...  0.322887   1.0  0.645095  0.068958   \n",
       "1918  0.672477  0.596553  0.303114  ...  0.302141   1.0  0.547257  0.201306   \n",
       "1919  0.596630  0.365489  0.304782  ...  0.453735   1.0  0.674624  0.100138   \n",
       "\n",
       "          AU25      AU26      AU28      AU43  \\\n",
       "0     0.935579  0.121045  0.333033  0.121158   \n",
       "1     0.975519  0.468108  0.318228  0.165630   \n",
       "2     0.900595  0.114604  0.304304  0.082065   \n",
       "3     0.636757  0.147229  0.222992  0.079755   \n",
       "4     0.996547  0.306116  0.034934  0.117396   \n",
       "...        ...       ...       ...       ...   \n",
       "1915  0.983158  0.445436  0.105169  0.638492   \n",
       "1916  0.974202  0.458458  0.115001  0.273430   \n",
       "1917  0.900835  0.509297  0.077086  0.406576   \n",
       "1918  0.998685  0.470552  0.115043  0.567455   \n",
       "1919  0.986878  0.398863  0.058895  0.681527   \n",
       "\n",
       "                               img_name  level  \n",
       "0     ./image/P19/P19_1659487998833.png      1  \n",
       "1     ./image/P19/P19_1659020214976.png      1  \n",
       "2     ./image/P19/P19_1659075503842.png      1  \n",
       "3     ./image/P19/P19_1659021205080.png      1  \n",
       "4     ./image/P19/P19_1659355704725.png      1  \n",
       "...                                 ...    ...  \n",
       "1915  ./image/P14/P14_1659279866187.png      0  \n",
       "1916  ./image/P14/P14_1659456638127.png      0  \n",
       "1917  ./image/P14/P14_1659456537639.png      0  \n",
       "1918  ./image/P14/P14_1659510069849.png      0  \n",
       "1919  ./image/P14/P14_1658932945727.png      0  \n",
       "\n",
       "[34364 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=[]\n",
    "for i in contestants:\n",
    "    all_data.append(pd.read_csv(f\"{base_path}/{i}\").dropna())\n",
    "all_df_data=pd.concat(all_data,axis=0)\n",
    "all_df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "emotion_features = all_df_data.columns[:-2]#7\n",
    "df_melted = pd.melt(all_df_data,\n",
    "                    id_vars=['level'],           # keep the level column as identifier\n",
    "                    value_vars=emotion_features, # the emotion feature columns to melt\n",
    "                    var_name='emotion',          # new column for emotion names\n",
    "                    value_name='value')          # new column for the corresponding values\n",
    "\n",
    "# If your level values are continuous but you want to treat them as categories, you can convert them to strings:\n",
    "df_melted['level'] = df_melted['level'].astype(str)\n",
    "\n",
    "# Step 3: Plot using Seaborn\n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.boxplot(y='emotion', x='value', hue='level', data=df_melted,showmeans=True,showfliers=False)\n",
    "# plt.title(\"Emotion Feature Distributions by Level\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Emotion/AU\") \n",
    "plt.legend(title=\"Level\")\n",
    "# plt.show()\n",
    "# plt.draw()\n",
    "plt.savefig('./image_paper/all_volunteer.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:47:21.222130Z",
     "iopub.status.busy": "2025-02-02T19:47:21.221776Z",
     "iopub.status.idle": "2025-02-02T19:47:35.119490Z",
     "shell.execute_reply": "2025-02-02T19:47:35.118444Z",
     "shell.execute_reply.started": "2025-02-02T19:47:21.222101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"['img_name'] not found in axis\"\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.84      0.76       678\n",
      "           1       0.88      0.76      0.82      1039\n",
      "\n",
      "    accuracy                           0.79      1717\n",
      "   macro avg       0.79      0.80      0.79      1717\n",
      "weighted avg       0.81      0.79      0.80      1717\n",
      "\n",
      "XGB  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.84      0.60       678\n",
      "           1       0.79      0.39      0.52      1039\n",
      "\n",
      "    accuracy                           0.57      1717\n",
      "   macro avg       0.63      0.61      0.56      1717\n",
      "weighted avg       0.66      0.57      0.55      1717\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.91      0.77       678\n",
      "           1       0.92      0.71      0.80      1039\n",
      "\n",
      "    accuracy                           0.79      1717\n",
      "   macro avg       0.80      0.81      0.79      1717\n",
      "weighted avg       0.82      0.79      0.79      1717\n",
      "\n",
      "\"['img_name'] not found in axis\"\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.54      0.32       536\n",
      "           1       0.92      0.75      0.82      3880\n",
      "\n",
      "    accuracy                           0.72      4416\n",
      "   macro avg       0.57      0.64      0.57      4416\n",
      "weighted avg       0.84      0.72      0.76      4416\n",
      "\n",
      "XGB  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.77      0.26       536\n",
      "           1       0.93      0.43      0.59      3880\n",
      "\n",
      "    accuracy                           0.47      4416\n",
      "   macro avg       0.54      0.60      0.42      4416\n",
      "weighted avg       0.84      0.47      0.55      4416\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.55      0.20       536\n",
      "           1       0.88      0.45      0.60      3880\n",
      "\n",
      "    accuracy                           0.46      4416\n",
      "   macro avg       0.50      0.50      0.40      4416\n",
      "weighted avg       0.79      0.46      0.55      4416\n",
      "\n",
      "\"['img_name'] not found in axis\"\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.78      0.49      1112\n",
      "           1       0.86      0.50      0.63      3042\n",
      "\n",
      "    accuracy                           0.57      4154\n",
      "   macro avg       0.61      0.64      0.56      4154\n",
      "weighted avg       0.73      0.57      0.59      4154\n",
      "\n",
      "XGB  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.92      0.50      1112\n",
      "           1       0.93      0.37      0.52      3042\n",
      "\n",
      "    accuracy                           0.51      4154\n",
      "   macro avg       0.64      0.64      0.51      4154\n",
      "weighted avg       0.77      0.51      0.52      4154\n",
      "\n",
      "LR  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.78      0.43      1112\n",
      "           1       0.80      0.33      0.46      3042\n",
      "\n",
      "    accuracy                           0.45      4154\n",
      "   macro avg       0.55      0.55      0.45      4154\n",
      "weighted avg       0.67      0.45      0.45      4154\n",
      "\n",
      "\"['img_name'] not found in axis\"\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.87      0.63       678\n",
      "           1       0.89      0.54      0.67      1312\n",
      "\n",
      "    accuracy                           0.65      1990\n",
      "   macro avg       0.69      0.71      0.65      1990\n",
      "weighted avg       0.76      0.65      0.66      1990\n",
      "\n",
      "XGB  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.85      0.59       678\n",
      "           1       0.86      0.46      0.60      1312\n",
      "\n",
      "    accuracy                           0.59      1990\n",
      "   macro avg       0.65      0.66      0.59      1990\n",
      "weighted avg       0.72      0.59      0.60      1990\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.92      0.63       678\n",
      "           1       0.92      0.47      0.62      1312\n",
      "\n",
      "    accuracy                           0.62      1990\n",
      "   macro avg       0.70      0.70      0.62      1990\n",
      "weighted avg       0.77      0.62      0.62      1990\n",
      "\n",
      "\"['img_name'] not found in axis\"\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.25      0.07       181\n",
      "           1       0.95      0.74      0.83      3880\n",
      "\n",
      "    accuracy                           0.72      4061\n",
      "   macro avg       0.50      0.50      0.45      4061\n",
      "weighted avg       0.91      0.72      0.80      4061\n",
      "\n",
      "XGB  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.50      0.07       181\n",
      "           1       0.95      0.43      0.59      3880\n",
      "\n",
      "    accuracy                           0.43      4061\n",
      "   macro avg       0.49      0.47      0.33      4061\n",
      "weighted avg       0.91      0.43      0.57      4061\n",
      "\n",
      "LR  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.41      0.06       181\n",
      "           1       0.94      0.45      0.61      3880\n",
      "\n",
      "    accuracy                           0.45      4061\n",
      "   macro avg       0.49      0.43      0.34      4061\n",
      "weighted avg       0.90      0.45      0.59      4061\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,\\\n",
    "f1_score,precision_score,recall_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "k=1\n",
    "\n",
    "f1=[]\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "roc_auc=[]\n",
    "model=[]\n",
    "\n",
    "testPersons=[['P31.csv','P19.csv'],\n",
    "            ['P20.csv','P24.csv'],\n",
    "            ['P13.csv','P30.csv'],#\n",
    "            ['P31.csv','P18.csv'],\n",
    "            ['P08.csv','P24.csv']#\n",
    "#             both\n",
    "            ]\n",
    "\n",
    "sm=SMOTE()\n",
    "for i in range(len(testPersons)):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # Scramble\n",
    "    random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "    only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "    only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "    both = [key for key, value in depression.items() if len(value) == 2]\n",
    "    # testPerson = ['08'] + ['24']#['16','08'] + ['24','30']\n",
    "#     testPerson = [random.choice(only0)] \\\n",
    "#     + [random.choice(only1)]\n",
    "#     print(testPerson)\n",
    "#     # testPerson = [13,17]\n",
    "#     allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "#     trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "#     testPerson = random.sample(only0,k) \\\n",
    "#     + random.sample(only1,k)\n",
    "    testPerson=testPersons[i]\n",
    "    # testPerson = [13,17]\n",
    "    allPerson = contestants\n",
    "    trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "\n",
    "#     # Merge train data and shuffle\n",
    "#     train_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in trainPerson]\n",
    "#     merged_train = pd.concat(train_list, ignore_index=True)\n",
    "#     shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "#     test_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in testPerson]\n",
    "#     merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_test = shuffled_test.drop([ 'img_name'], axis = 1)\n",
    "    for num in trainPerson:\n",
    "        train = pd.read_csv(f'{base_path}/{num}')\n",
    "        train=train.set_index('img_name')\n",
    "        duplicate_rows = train.index.duplicated()\n",
    "        train=train.loc[~duplicate_rows,:]\n",
    "        add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "        add_data=add_data.drop(['Unnamed: 0','level'],axis=1)\n",
    "        add_data=add_data.set_index('img_name')\n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        train_=pd.concat([train,add_data],axis=1)\n",
    "        train_=train_.reset_index()\n",
    "        train_=train_.dropna()\n",
    "        train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "        train_list.append(train)#train_ for addition data\n",
    "    \n",
    "    merged_train = pd.concat(train_list, ignore_index=True)\n",
    "    shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    try:\n",
    "        shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "    except:pass   \n",
    "\n",
    "    for num in testPerson:\n",
    "        test = pd.read_csv(f'{base_path}/{num}')\n",
    "        test=test.set_index('img_name')\n",
    "        duplicate_rows = test.index.duplicated()\n",
    "        test=test.loc[~duplicate_rows,:]\n",
    "        add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "        add_data=add_data.drop(['Unnamed: 0','level'],axis=1)\n",
    "        add_data=add_data.set_index('img_name')\n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        test_=pd.concat([test,add_data],axis=1)\n",
    "        test_=test_.reset_index()\n",
    "        test_=test_.dropna()\n",
    "        test_=test_.drop(['timestamp','ID'],axis=1)\n",
    "        test_list.append(test)#test_ for addition data\n",
    "    merged_test = pd.concat(test_list, ignore_index=True)\n",
    "    shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    try:\n",
    "#         shuffled_test=shuffled_test.reset_index(drop=False)\n",
    "#         shuffled_test['ts']=shuffled_test['img_name'].apply(lambda x :int(int(x.split('_')[-1][:-4])/1000))\n",
    "        shuffled_test = shuffled_test.drop(['img_name'], axis = 1)\n",
    "        \n",
    "    except Exception as e:print(e)\n",
    "#     add_train_from_test,shuffled_test=shuffled_test[shuffled_test['ts']<shuffled_test['ts'].median()],shuffled_test[shuffled_test['ts']>shuffled_test['ts'].median()]\n",
    "# #     add_train_from_test,shuffled_test=train_test_split(shuffled_test,test_size=0.5)\n",
    "#     add_train_from_test,shuffled_test=add_train_from_test.drop('ts',axis=1),shuffled_test.drop('ts',axis=1)\n",
    "#     shuffled_train=pd.concat([add_train_from_test,shuffled_train],axis=0)\n",
    "\n",
    "\n",
    "    X_train, y_train = shuffled_train.drop('level', axis = 1), shuffled_train['level']\n",
    "\n",
    "    X_test, y_test = shuffled_test.drop('level', axis = 1), shuffled_test['level']\n",
    "    y_train =y_train.astype('category')\n",
    "    y_test =y_test.astype('category')\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    X_train=pd.DataFrame(X_train,columns=X_train.columns)\n",
    "    # y_train=pd.DataFrame(y_train,columns=y_test.columns)\n",
    "    # Print train test contestants\n",
    "    print(\"Train: \", trainPerson)\n",
    "    print(\"Test: \", testPerson)\n",
    "    \n",
    "\n",
    "    # Logistic Regression\n",
    "    # log_reg = LogisticRegression(max_iter=10000)\n",
    "    # log_reg.fit(X_train, y_train)\n",
    "    # log_reg_pred = log_reg.predict(X_test)\n",
    "    # log_reg_acc = classification_report(y_test, log_reg_pred)\n",
    "    # print(f\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "\n",
    "    # K-Nearest Neighbors (KNN)\n",
    "    knn = KNeighborsClassifier(n_neighbors=100)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_rp = classification_report(y_test, knn_pred)\n",
    "    accuracy.append(accuracy_score(y_test, knn_pred))\n",
    "    f1.append(f1_score(y_test, knn_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, knn_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, knn_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, knn_pred))\n",
    "    model.append('KNN')\n",
    "    print('knn ',i)\n",
    "    print(knn_rp)\n",
    "    \n",
    "    \n",
    "#     # Support Vector Machine (SVM)\n",
    "    svm =  XGBClassifier(n_estimators=100)#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_rp = classification_report(y_test, svm_pred)\n",
    "    accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "    f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "    model.append('XGB')\n",
    "    print('XGB ',i)\n",
    "    print(svm_rp)\n",
    "    \n",
    "    svm =  LogisticRegression()#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_rp = classification_report(y_test, svm_pred)\n",
    "    accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "    f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "    model.append('LR')\n",
    "    print('LR ',i)\n",
    "    print(svm_rp)\n",
    "\n",
    "#     # Random Forest Classifier\n",
    "#     rf = RandomForestClassifier(n_estimators=1000)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     rf_pred = rf.predict(X_test)\n",
    "#     rf_acc = classification_report(y_test, rf_pred)\n",
    "#     print('rf ',i)\n",
    "#     print(rf_acc)\n",
    "\n",
    "#     xgb = XGBClassifier(n_estimators=1000)\n",
    "#     xgb.fit(X_train, y_train)\n",
    "#     xgb_pred = xgb.predict(X_test)\n",
    "#     xgb_acc = classification_report(y_test, xgb_pred)\n",
    "#     print('xgb ',i)\n",
    "#     print(xgb_acc)\n",
    "\n",
    "#     # Neural Network (MLP Classifier)\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000)\n",
    "#     mlp.fit(X_train, y_train)\n",
    "#     mlp_pred = mlp.predict(X_test)\n",
    "#     mlp_acc = classification_report(y_test, mlp_pred)\n",
    "#     print('MLP ',i)\n",
    "#     print(mlp_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Input_Features       p_values\n",
      "2            fear   0.000000e+00\n",
      "6         neutral   0.000000e+00\n",
      "5        surprise  9.950132e-242\n",
      "19           AU17  4.062776e-188\n",
      "11           AU06  2.458384e-123\n",
      "7            AU01  4.525344e-117\n",
      "14           AU10  1.826099e-105\n",
      "24           AU26   5.615461e-88\n",
      "22           AU24   2.014201e-66\n",
      "4         sadness   3.102235e-46\n",
      "13           AU09   1.226805e-43\n",
      "16           AU12   1.570522e-43\n",
      "3       happiness   2.206175e-34\n",
      "9            AU04   5.846971e-30\n",
      "18           AU15   2.208177e-28\n",
      "1         disgust   3.885659e-28\n",
      "0           anger   1.686125e-23\n",
      "8            AU02   1.010173e-19\n",
      "21           AU23   2.452284e-18\n",
      "12           AU07   8.523106e-18\n",
      "17           AU14   2.802793e-11\n",
      "25           AU28   8.219730e-11\n",
      "15           AU11   2.109093e-08\n",
      "23           AU25   3.323067e-04\n",
      "10           AU05   3.829205e-04\n",
      "26           AU43   1.278832e-02\n",
      "20           AU20   5.691520e-01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "fs = SelectKBest(score_func=f_regression,k=15)\n",
    "# Applying feature selection\n",
    "fit = fs.fit(X_train,y_train)\n",
    "features_score1 = pd.DataFrame(fit.pvalues_)\n",
    "features1 = pd.DataFrame(X_train.columns)\n",
    "feature_score1 = pd.concat([features1,features_score1],axis=1)\n",
    "# Assigning column names\n",
    "feature_score1.columns = [\"Input_Features\",\"p_values\"]\n",
    "feature_score1=feature_score1.sort_values('p_values', ascending=True)\n",
    "print(feature_score1.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>...</th>\n",
       "      <th>AU14</th>\n",
       "      <th>AU15</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028010</td>\n",
       "      <td>0.005050</td>\n",
       "      <td>0.112035</td>\n",
       "      <td>0.206918</td>\n",
       "      <td>0.039830</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.604798</td>\n",
       "      <td>0.441470</td>\n",
       "      <td>0.244222</td>\n",
       "      <td>0.247741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.287023</td>\n",
       "      <td>0.754294</td>\n",
       "      <td>0.373957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.409330</td>\n",
       "      <td>0.166060</td>\n",
       "      <td>0.988761</td>\n",
       "      <td>0.451363</td>\n",
       "      <td>0.073265</td>\n",
       "      <td>0.648741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.009691</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>0.030305</td>\n",
       "      <td>0.141141</td>\n",
       "      <td>0.071189</td>\n",
       "      <td>0.002137</td>\n",
       "      <td>0.743910</td>\n",
       "      <td>0.731117</td>\n",
       "      <td>0.309397</td>\n",
       "      <td>0.391120</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262104</td>\n",
       "      <td>0.439468</td>\n",
       "      <td>0.355174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.606937</td>\n",
       "      <td>0.048256</td>\n",
       "      <td>0.998899</td>\n",
       "      <td>0.476950</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>0.166353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.016050</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.104557</td>\n",
       "      <td>0.096812</td>\n",
       "      <td>0.163395</td>\n",
       "      <td>0.019642</td>\n",
       "      <td>0.596823</td>\n",
       "      <td>0.712513</td>\n",
       "      <td>0.417560</td>\n",
       "      <td>0.181214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371809</td>\n",
       "      <td>0.580586</td>\n",
       "      <td>0.481117</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.531415</td>\n",
       "      <td>0.172991</td>\n",
       "      <td>0.996616</td>\n",
       "      <td>0.186925</td>\n",
       "      <td>0.110731</td>\n",
       "      <td>0.100842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.034160</td>\n",
       "      <td>0.031738</td>\n",
       "      <td>0.046257</td>\n",
       "      <td>0.452628</td>\n",
       "      <td>0.027528</td>\n",
       "      <td>0.004036</td>\n",
       "      <td>0.403654</td>\n",
       "      <td>0.711828</td>\n",
       "      <td>0.534157</td>\n",
       "      <td>0.138964</td>\n",
       "      <td>...</td>\n",
       "      <td>0.687615</td>\n",
       "      <td>0.647505</td>\n",
       "      <td>0.292321</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.317085</td>\n",
       "      <td>0.036716</td>\n",
       "      <td>0.996456</td>\n",
       "      <td>0.603464</td>\n",
       "      <td>0.094943</td>\n",
       "      <td>0.554039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.008282</td>\n",
       "      <td>0.003689</td>\n",
       "      <td>0.145031</td>\n",
       "      <td>0.140706</td>\n",
       "      <td>0.034648</td>\n",
       "      <td>0.004140</td>\n",
       "      <td>0.663505</td>\n",
       "      <td>0.522221</td>\n",
       "      <td>0.258730</td>\n",
       "      <td>0.284942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363836</td>\n",
       "      <td>0.420816</td>\n",
       "      <td>0.332058</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.733109</td>\n",
       "      <td>0.254347</td>\n",
       "      <td>0.895926</td>\n",
       "      <td>0.153599</td>\n",
       "      <td>0.156247</td>\n",
       "      <td>0.125745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45737</th>\n",
       "      <td>0.023643</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>0.283459</td>\n",
       "      <td>0.379380</td>\n",
       "      <td>0.042853</td>\n",
       "      <td>0.005001</td>\n",
       "      <td>0.257473</td>\n",
       "      <td>0.694445</td>\n",
       "      <td>0.352160</td>\n",
       "      <td>0.377829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.363305</td>\n",
       "      <td>0.532680</td>\n",
       "      <td>0.373285</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.522888</td>\n",
       "      <td>0.022997</td>\n",
       "      <td>0.998845</td>\n",
       "      <td>0.671663</td>\n",
       "      <td>0.171927</td>\n",
       "      <td>0.771112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45738</th>\n",
       "      <td>0.031062</td>\n",
       "      <td>0.012623</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.348037</td>\n",
       "      <td>0.035925</td>\n",
       "      <td>0.004081</td>\n",
       "      <td>0.505549</td>\n",
       "      <td>0.639977</td>\n",
       "      <td>0.365755</td>\n",
       "      <td>0.395380</td>\n",
       "      <td>...</td>\n",
       "      <td>0.313843</td>\n",
       "      <td>0.784734</td>\n",
       "      <td>0.365937</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.426590</td>\n",
       "      <td>0.042443</td>\n",
       "      <td>0.997463</td>\n",
       "      <td>0.518530</td>\n",
       "      <td>0.107128</td>\n",
       "      <td>0.773185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45739</th>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.003845</td>\n",
       "      <td>0.118872</td>\n",
       "      <td>0.150546</td>\n",
       "      <td>0.061558</td>\n",
       "      <td>0.005379</td>\n",
       "      <td>0.638700</td>\n",
       "      <td>0.672093</td>\n",
       "      <td>0.346136</td>\n",
       "      <td>0.225100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.266576</td>\n",
       "      <td>0.662950</td>\n",
       "      <td>0.385453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.652936</td>\n",
       "      <td>0.124123</td>\n",
       "      <td>0.993760</td>\n",
       "      <td>0.557556</td>\n",
       "      <td>0.124696</td>\n",
       "      <td>0.765431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45740</th>\n",
       "      <td>0.029466</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0.071045</td>\n",
       "      <td>0.121074</td>\n",
       "      <td>0.072296</td>\n",
       "      <td>0.005605</td>\n",
       "      <td>0.694804</td>\n",
       "      <td>0.564858</td>\n",
       "      <td>0.403990</td>\n",
       "      <td>0.136709</td>\n",
       "      <td>...</td>\n",
       "      <td>0.412467</td>\n",
       "      <td>0.411790</td>\n",
       "      <td>0.546545</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.364880</td>\n",
       "      <td>0.152323</td>\n",
       "      <td>0.995162</td>\n",
       "      <td>0.265072</td>\n",
       "      <td>0.146190</td>\n",
       "      <td>0.228723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45741</th>\n",
       "      <td>0.028484</td>\n",
       "      <td>0.004752</td>\n",
       "      <td>0.101412</td>\n",
       "      <td>0.139453</td>\n",
       "      <td>0.042108</td>\n",
       "      <td>0.009139</td>\n",
       "      <td>0.674652</td>\n",
       "      <td>0.527925</td>\n",
       "      <td>0.175404</td>\n",
       "      <td>0.252268</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488882</td>\n",
       "      <td>0.603929</td>\n",
       "      <td>0.537600</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.422353</td>\n",
       "      <td>0.069708</td>\n",
       "      <td>0.985906</td>\n",
       "      <td>0.293692</td>\n",
       "      <td>0.157012</td>\n",
       "      <td>0.215156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>45742 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          anger   disgust      fear  happiness   sadness  surprise   neutral  \\\n",
       "0      0.028010  0.005050  0.112035   0.206918  0.039830  0.003359  0.604798   \n",
       "1      0.009691  0.001625  0.030305   0.141141  0.071189  0.002137  0.743910   \n",
       "2      0.016050  0.002721  0.104557   0.096812  0.163395  0.019642  0.596823   \n",
       "3      0.034160  0.031738  0.046257   0.452628  0.027528  0.004036  0.403654   \n",
       "4      0.008282  0.003689  0.145031   0.140706  0.034648  0.004140  0.663505   \n",
       "...         ...       ...       ...        ...       ...       ...       ...   \n",
       "45737  0.023643  0.008191  0.283459   0.379380  0.042853  0.005001  0.257473   \n",
       "45738  0.031062  0.012623  0.062723   0.348037  0.035925  0.004081  0.505549   \n",
       "45739  0.021099  0.003845  0.118872   0.150546  0.061558  0.005379  0.638700   \n",
       "45740  0.029466  0.005710  0.071045   0.121074  0.072296  0.005605  0.694804   \n",
       "45741  0.028484  0.004752  0.101412   0.139453  0.042108  0.009139  0.674652   \n",
       "\n",
       "           AU01      AU02      AU04  ...      AU14      AU15      AU17  AU20  \\\n",
       "0      0.441470  0.244222  0.247741  ...  0.287023  0.754294  0.373957   1.0   \n",
       "1      0.731117  0.309397  0.391120  ...  0.262104  0.439468  0.355174   1.0   \n",
       "2      0.712513  0.417560  0.181214  ...  0.371809  0.580586  0.481117   1.0   \n",
       "3      0.711828  0.534157  0.138964  ...  0.687615  0.647505  0.292321   1.0   \n",
       "4      0.522221  0.258730  0.284942  ...  0.363836  0.420816  0.332058   0.0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   ...   \n",
       "45737  0.694445  0.352160  0.377829  ...  0.363305  0.532680  0.373285   1.0   \n",
       "45738  0.639977  0.365755  0.395380  ...  0.313843  0.784734  0.365937   1.0   \n",
       "45739  0.672093  0.346136  0.225100  ...  0.266576  0.662950  0.385453   1.0   \n",
       "45740  0.564858  0.403990  0.136709  ...  0.412467  0.411790  0.546545   1.0   \n",
       "45741  0.527925  0.175404  0.252268  ...  0.488882  0.603929  0.537600   1.0   \n",
       "\n",
       "           AU23      AU24      AU25      AU26      AU28      AU43  \n",
       "0      0.409330  0.166060  0.988761  0.451363  0.073265  0.648741  \n",
       "1      0.606937  0.048256  0.998899  0.476950  0.135747  0.166353  \n",
       "2      0.531415  0.172991  0.996616  0.186925  0.110731  0.100842  \n",
       "3      0.317085  0.036716  0.996456  0.603464  0.094943  0.554039  \n",
       "4      0.733109  0.254347  0.895926  0.153599  0.156247  0.125745  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "45737  0.522888  0.022997  0.998845  0.671663  0.171927  0.771112  \n",
       "45738  0.426590  0.042443  0.997463  0.518530  0.107128  0.773185  \n",
       "45739  0.652936  0.124123  0.993760  0.557556  0.124696  0.765431  \n",
       "45740  0.364880  0.152323  0.995162  0.265072  0.146190  0.228723  \n",
       "45741  0.422353  0.069708  0.985906  0.293692  0.157012  0.215156  \n",
       "\n",
       "[45742 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num in trainPerson:\n",
    "#     train = pd.read_csv(f'{base_path}/{num}')\n",
    "#     train=train.set_index('img_name')\n",
    "#     duplicate_rows = train.index.duplicated()\n",
    "#     train=train.loc[~duplicate_rows,:]\n",
    "#     add_data=train.copy()\n",
    "#     add_data=add_data.shift(1)\n",
    "#     add_data.columns=[i+'_prev' for i in add_data.columns]\n",
    "#     train_=pd.concat([train,add_data],axis=1)\n",
    "#     train_=train_.reset_index()\n",
    "#     train_=train_.dropna()\n",
    "# #     train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "#     break\n",
    "# train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43', 'anger_time_lag', 'disgust_time_lag',\n",
      "       'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag',\n",
      "       'surprise_time_lag', 'neutral_time_lag', 'AU01_time_lag',\n",
      "       'AU02_time_lag', 'AU04_time_lag', 'AU05_time_lag', 'AU06_time_lag',\n",
      "       'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU11_time_lag',\n",
      "       'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU17_time_lag',\n",
      "       'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag',\n",
      "       'AU26_time_lag', 'AU28_time_lag', 'AU43_time_lag', 'anger_vel',\n",
      "       'disgust_vel', 'fear_vel', 'happiness_vel', 'sadness_vel',\n",
      "       'surprise_vel', 'neutral_vel', 'AU01_vel', 'AU02_vel', 'AU04_vel',\n",
      "       'AU05_vel', 'AU06_vel', 'AU07_vel', 'AU09_vel', 'AU10_vel', 'AU11_vel',\n",
      "       'AU12_vel', 'AU14_vel', 'AU15_vel', 'AU17_vel', 'AU20_vel', 'AU23_vel',\n",
      "       'AU24_vel', 'AU25_vel', 'AU26_vel', 'AU28_vel', 'AU43_vel'],\n",
      "      dtype='object')\n",
      "knn  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       676\n",
      "           1       0.93      0.87      0.90      1037\n",
      "\n",
      "    accuracy                           0.88      1713\n",
      "   macro avg       0.87      0.88      0.87      1713\n",
      "weighted avg       0.88      0.88      0.88      1713\n",
      "\n",
      "XGB_  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.98      0.63       676\n",
      "           1       0.95      0.28      0.43      1037\n",
      "\n",
      "    accuracy                           0.55      1713\n",
      "   macro avg       0.71      0.63      0.53      1713\n",
      "weighted avg       0.76      0.55      0.51      1713\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.84       676\n",
      "           1       0.98      0.77      0.86      1037\n",
      "\n",
      "    accuracy                           0.85      1713\n",
      "   macro avg       0.86      0.87      0.85      1713\n",
      "weighted avg       0.88      0.85      0.85      1713\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.34      0.23       534\n",
      "           1       0.90      0.77      0.83      3878\n",
      "\n",
      "    accuracy                           0.72      4412\n",
      "   macro avg       0.53      0.56      0.53      4412\n",
      "weighted avg       0.81      0.72      0.76      4412\n",
      "\n",
      "XGB_  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.80      0.26       534\n",
      "           1       0.94      0.40      0.56      3878\n",
      "\n",
      "    accuracy                           0.45      4412\n",
      "   macro avg       0.55      0.60      0.41      4412\n",
      "weighted avg       0.84      0.45      0.52      4412\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.56      0.19       534\n",
      "           1       0.87      0.41      0.56      3878\n",
      "\n",
      "    accuracy                           0.43      4412\n",
      "   macro avg       0.49      0.49      0.37      4412\n",
      "weighted avg       0.78      0.43      0.51      4412\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.78      0.45      1110\n",
      "           1       0.83      0.39      0.53      3040\n",
      "\n",
      "    accuracy                           0.49      4150\n",
      "   macro avg       0.57      0.58      0.49      4150\n",
      "weighted avg       0.69      0.49      0.51      4150\n",
      "\n",
      "XGB_  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.98      0.50      1110\n",
      "           1       0.97      0.29      0.45      3040\n",
      "\n",
      "    accuracy                           0.47      4150\n",
      "   macro avg       0.65      0.63      0.47      4150\n",
      "weighted avg       0.80      0.47      0.46      4150\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.86      0.45      1110\n",
      "           1       0.84      0.29      0.43      3040\n",
      "\n",
      "    accuracy                           0.44      4150\n",
      "   macro avg       0.57      0.57      0.44      4150\n",
      "weighted avg       0.70      0.44      0.43      4150\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.90      0.64       676\n",
      "           1       0.91      0.52      0.67      1310\n",
      "\n",
      "    accuracy                           0.65      1986\n",
      "   macro avg       0.70      0.71      0.65      1986\n",
      "weighted avg       0.77      0.65      0.66      1986\n",
      "\n",
      "XGB_  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.98      0.66       676\n",
      "           1       0.98      0.49      0.66      1310\n",
      "\n",
      "    accuracy                           0.66      1986\n",
      "   macro avg       0.74      0.74      0.66      1986\n",
      "weighted avg       0.82      0.66      0.66      1986\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.98      0.73       676\n",
      "           1       0.99      0.63      0.77      1310\n",
      "\n",
      "    accuracy                           0.75      1986\n",
      "   macro avg       0.78      0.81      0.75      1986\n",
      "weighted avg       0.85      0.75      0.75      1986\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.36      0.12       179\n",
      "           1       0.96      0.78      0.86      3878\n",
      "\n",
      "    accuracy                           0.76      4057\n",
      "   macro avg       0.52      0.57      0.49      4057\n",
      "weighted avg       0.92      0.76      0.83      4057\n",
      "\n",
      "XGB_  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.51      0.07       179\n",
      "           1       0.95      0.43      0.59      3878\n",
      "\n",
      "    accuracy                           0.43      4057\n",
      "   macro avg       0.49      0.47      0.33      4057\n",
      "weighted avg       0.91      0.43      0.57      4057\n",
      "\n",
      "LR_  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.36      0.05       179\n",
      "           1       0.94      0.43      0.59      3878\n",
      "\n",
      "    accuracy                           0.43      4057\n",
      "   macro avg       0.48      0.39      0.32      4057\n",
      "weighted avg       0.90      0.43      0.57      4057\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,\\\n",
    "f1_score,precision_score,recall_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "k=1\n",
    "\n",
    "# f1=[]\n",
    "# accuracy=[]\n",
    "# precision=[]\n",
    "# recall=[]\n",
    "# roc_auc=[]\n",
    "# model=[]\n",
    "# testPersons=[['P31.csv','P19.csv'],\n",
    "#             ['P14.csv','P24.csv'],\n",
    "#             ['P13.csv','P30.csv'],\n",
    "#             ['P31.csv','P18.csv'],\n",
    "#             ['P08.csv','P24.csv']]\n",
    "sm=SMOTE()\n",
    "j=True\n",
    "for i in range(len(testPersons)):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # Scramble\n",
    "    random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "    only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "    only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "    both = [key for key, value in depression.items() if len(value) == 2]\n",
    "    # testPerson = ['08'] + ['24']#['16','08'] + ['24','30']\n",
    "#     testPerson = [str(random.choice(only0).split('.')[0].split('P')[1])] \\\n",
    "#     + [str(random.choice(only1).split('.')[0].split('P')[1])]\n",
    "#     # testPerson = [13,17]\n",
    "#     allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "#     trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "#     testPerson = random.sample(only0,k) \\\n",
    "#     + random.sample(only1,k)\n",
    "    testPerson=testPersons[i]\n",
    "    # testPerson = [13,17]\n",
    "    allPerson = contestants\n",
    "    trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "\n",
    "#     # Merge train data and shuffle\n",
    "#     train_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in trainPerson]\n",
    "#     merged_train = pd.concat(train_list, ignore_index=True)\n",
    "#     shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "#     test_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in testPerson]\n",
    "#     merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_test = shuffled_test.drop([ 'img_name'], axis = 1)\n",
    "    for num in trainPerson:\n",
    "        train = pd.read_csv(f'{base_path}/{num}')\n",
    "        train=train.set_index('img_name')\n",
    "        duplicate_rows = train.index.duplicated()\n",
    "        train=train.loc[~duplicate_rows,:]\n",
    "        train_addata=train.copy()\n",
    "        train=train.drop('level',axis=1)\n",
    "        add_data=train.copy()\n",
    "        \n",
    "        add_data=add_data.shift(1)\n",
    "        add_data.columns=[i.split('_')[0]+'_time_lag' for i in train.columns]\n",
    "        \n",
    "#         add_data2=add_data.shift(2)\n",
    "#         add_data2.columns=[i+'_prev2' for i in add_data.columns]\n",
    "\n",
    "        add_vel=add_data.diff(1)\n",
    "        add_vel.columns=[i+'_vel' for i in train.columns]\n",
    "        \n",
    "#         duplicate_rows = add_data.index.duplicated()\n",
    "        train_=pd.concat([train_addata,add_data,add_vel],axis=1)\n",
    "        train_=train_.reset_index()\n",
    "        train_=train_.dropna()\n",
    "#         train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "        train_list.append(train_)#train_ for addition data\n",
    "    \n",
    "    merged_train = pd.concat(train_list, ignore_index=True)\n",
    "    shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    try:\n",
    "        shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "    except:pass   \n",
    "\n",
    "    for num in testPerson:\n",
    "        test = pd.read_csv(f'{base_path}/{num}')\n",
    "        test=test.set_index('img_name')\n",
    "        \n",
    "        \n",
    "        duplicate_rows = test.index.duplicated()\n",
    "        test=test.loc[~duplicate_rows,:]\n",
    "        test_add=test.copy()\n",
    "        test=test.drop('level',axis=1)\n",
    "        add_data=test.copy()\n",
    "        \n",
    "        add_data=add_data.shift(1)\n",
    "        add_data.columns=[i.split('_')[0]+'_time_lag' for i in test.columns]\n",
    "\n",
    "        add_vel=add_data.diff(1)\n",
    "        add_vel.columns=[i+'_vel' for i in test.columns]\n",
    "        \n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        test_=pd.concat([test_add,add_data,add_vel],axis=1)\n",
    "        test_=test_.reset_index()\n",
    "        test_=test_.dropna()\n",
    "\n",
    "        test_list.append(test_)#test_ for addition data\n",
    "    merged_test = pd.concat(test_list, ignore_index=True)\n",
    "    shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    try:\n",
    "#         shuffled_test=shuffled_test.reset_index(drop=False)\n",
    "#         shuffled_test['ts']=shuffled_test['img_name'].apply(lambda x :int(int(x.split('_')[-1][:-4])/1000))\n",
    "        shuffled_test = shuffled_test.drop(['img_name'], axis = 1)\n",
    "        \n",
    "    except Exception as e:print(e)\n",
    "#     add_train_from_test,shuffled_test=shuffled_test[shuffled_test['ts']<shuffled_test['ts'].median()],shuffled_test[shuffled_test['ts']>shuffled_test['ts'].median()]\n",
    "# #     add_train_from_test,shuffled_test=train_test_split(shuffled_test,test_size=0.5)\n",
    "#     add_train_from_test,shuffled_test=add_train_from_test.drop('ts',axis=1),shuffled_test.drop('ts',axis=1)\n",
    "#     shuffled_train=pd.concat([add_train_from_test,shuffled_train],axis=0)\n",
    "\n",
    "    X_train, y_train = shuffled_train.drop('level', axis = 1), shuffled_train['level']\n",
    "\n",
    "    X_test, y_test = shuffled_test.drop('level', axis = 1), shuffled_test['level']\n",
    "    y_train =y_train.astype('category')\n",
    "    y_test =y_test.astype('category')\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    X_train=pd.DataFrame(X_train,columns=X_train.columns)\n",
    "    # y_train=pd.DataFrame(y_train,columns=y_test.columns)\n",
    "    # Print train test contestants\n",
    "    print(\"Train: \", trainPerson)\n",
    "    print(\"Test: \", testPerson)\n",
    "    if j:\n",
    "        print(X_train.columns.T)\n",
    "        j=False\n",
    "\n",
    "    # Logistic Regression\n",
    "    # log_reg = LogisticRegression(max_iter=10000)\n",
    "    # log_reg.fit(X_train, y_train)\n",
    "    # log_reg_pred = log_reg.predict(X_test)\n",
    "    # log_reg_acc = classification_report(y_test, log_reg_pred)\n",
    "    # print(f\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "\n",
    "    # K-Nearest Neighbors (KNN)\n",
    "    knn = KNeighborsClassifier(n_neighbors=100, leaf_size=70)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_rp = classification_report(y_test, knn_pred)\n",
    "    accuracy.append(accuracy_score(y_test, knn_pred))\n",
    "    f1.append(f1_score(y_test, knn_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, knn_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, knn_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, knn_pred))\n",
    "    model.append('KNN_tlsd')\n",
    "    print('knn ',i)\n",
    "    print(knn_rp)\n",
    "    \n",
    "    \n",
    "#     # Support Vector Machine (SVM)\n",
    "    svm =  XGBClassifier(n_estimators=100)#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_rp = classification_report(y_test, svm_pred)\n",
    "    accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "    f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "    model.append('XGB_tlsd')\n",
    "    print('XGB_ ',i)\n",
    "    print(svm_rp)\n",
    "    \n",
    "        \n",
    "    svm =  LogisticRegression()#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_rp = classification_report(y_test, svm_pred)\n",
    "    accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "    f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "    model.append('LR_tlsd')\n",
    "    print('LR_ ',i)\n",
    "    print(svm_rp)\n",
    "\n",
    "#     # Random Forest Classifier\n",
    "#     rf = RandomForestClassifier(n_estimators=1000)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     rf_pred = rf.predict(X_test)\n",
    "#     rf_acc = classification_report(y_test, rf_pred)\n",
    "#     print('rf ',i)\n",
    "#     print(rf_acc)\n",
    "\n",
    "#     xgb = XGBClassifier(n_estimators=1000)\n",
    "#     xgb.fit(X_train, y_train)\n",
    "#     xgb_pred = xgb.predict(X_test)\n",
    "#     xgb_acc = classification_report(y_test, xgb_pred)\n",
    "#     print('xgb ',i)\n",
    "#     print(xgb_acc)\n",
    "\n",
    "#     # Neural Network (MLP Classifier)\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000)\n",
    "#     mlp.fit(X_train, y_train)\n",
    "#     mlp_pred = mlp.predict(X_test)\n",
    "#     mlp_acc = classification_report(y_test, mlp_pred)\n",
    "#     print('MLP ',i)\n",
    "#     print(mlp_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43', 'anger_time_lag', 'disgust_time_lag',\n",
      "       'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag',\n",
      "       'surprise_time_lag', 'neutral_time_lag', 'AU01_time_lag',\n",
      "       'AU02_time_lag', 'AU04_time_lag', 'AU05_time_lag', 'AU06_time_lag',\n",
      "       'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU11_time_lag',\n",
      "       'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU17_time_lag',\n",
      "       'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag',\n",
      "       'AU26_time_lag', 'AU28_time_lag', 'AU43_time_lag'],\n",
      "      dtype='object')\n",
      "knn  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       677\n",
      "           1       0.93      0.87      0.90      1038\n",
      "\n",
      "    accuracy                           0.88      1715\n",
      "   macro avg       0.87      0.89      0.88      1715\n",
      "weighted avg       0.89      0.88      0.88      1715\n",
      "\n",
      "XGB_  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.94      0.62       677\n",
      "           1       0.88      0.28      0.43      1038\n",
      "\n",
      "    accuracy                           0.54      1715\n",
      "   macro avg       0.67      0.61      0.52      1715\n",
      "weighted avg       0.71      0.54      0.50      1715\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.97      0.83       677\n",
      "           1       0.97      0.77      0.86      1038\n",
      "\n",
      "    accuracy                           0.85      1715\n",
      "   macro avg       0.85      0.87      0.85      1715\n",
      "weighted avg       0.88      0.85      0.85      1715\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.52      0.33       535\n",
      "           1       0.92      0.78      0.85      3879\n",
      "\n",
      "    accuracy                           0.75      4414\n",
      "   macro avg       0.58      0.65      0.59      4414\n",
      "weighted avg       0.84      0.75      0.79      4414\n",
      "\n",
      "XGB_  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.16      0.83      0.27       535\n",
      "           1       0.94      0.41      0.57      3879\n",
      "\n",
      "    accuracy                           0.46      4414\n",
      "   macro avg       0.55      0.62      0.42      4414\n",
      "weighted avg       0.85      0.46      0.53      4414\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.60      0.22       535\n",
      "           1       0.90      0.48      0.62      3879\n",
      "\n",
      "    accuracy                           0.49      4414\n",
      "   macro avg       0.52      0.54      0.42      4414\n",
      "weighted avg       0.80      0.49      0.57      4414\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.80      0.47      1111\n",
      "           1       0.85      0.41      0.56      3041\n",
      "\n",
      "    accuracy                           0.52      4152\n",
      "   macro avg       0.59      0.61      0.51      4152\n",
      "weighted avg       0.71      0.52      0.53      4152\n",
      "\n",
      "XGB_  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.97      0.51      1111\n",
      "           1       0.96      0.33      0.49      3041\n",
      "\n",
      "    accuracy                           0.50      4152\n",
      "   macro avg       0.66      0.65      0.50      4152\n",
      "weighted avg       0.80      0.50      0.50      4152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.30      0.82      0.44      1111\n",
      "           1       0.83      0.31      0.46      3041\n",
      "\n",
      "    accuracy                           0.45      4152\n",
      "   macro avg       0.57      0.57      0.45      4152\n",
      "weighted avg       0.69      0.45      0.45      4152\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.90      0.65       677\n",
      "           1       0.92      0.56      0.70      1311\n",
      "\n",
      "    accuracy                           0.68      1988\n",
      "   macro avg       0.72      0.73      0.67      1988\n",
      "weighted avg       0.78      0.68      0.68      1988\n",
      "\n",
      "XGB_  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.94      0.63       677\n",
      "           1       0.93      0.47      0.63      1311\n",
      "\n",
      "    accuracy                           0.63      1988\n",
      "   macro avg       0.71      0.70      0.63      1988\n",
      "weighted avg       0.78      0.63      0.63      1988\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.97      0.69       677\n",
      "           1       0.98      0.56      0.71      1311\n",
      "\n",
      "    accuracy                           0.70      1988\n",
      "   macro avg       0.75      0.76      0.70      1988\n",
      "weighted avg       0.82      0.70      0.70      1988\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.39      0.14       180\n",
      "           1       0.97      0.80      0.88      3879\n",
      "\n",
      "    accuracy                           0.79      4059\n",
      "   macro avg       0.53      0.60      0.51      4059\n",
      "weighted avg       0.93      0.79      0.84      4059\n",
      "\n",
      "XGB_  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.53      0.08       180\n",
      "           1       0.95      0.42      0.58      3879\n",
      "\n",
      "    accuracy                           0.43      4059\n",
      "   macro avg       0.50      0.48      0.33      4059\n",
      "weighted avg       0.91      0.43      0.56      4059\n",
      "\n",
      "LR_  4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.37      0.06       180\n",
      "           1       0.94      0.49      0.65      3879\n",
      "\n",
      "    accuracy                           0.49      4059\n",
      "   macro avg       0.49      0.43      0.35      4059\n",
      "weighted avg       0.90      0.49      0.62      4059\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,\\\n",
    "f1_score,precision_score,recall_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "k=1\n",
    "\n",
    "# f1=[]\n",
    "# accuracy=[]\n",
    "# precision=[]\n",
    "# recall=[]\n",
    "# roc_auc=[]\n",
    "# model=[]\n",
    "# testPersons=[['P31.csv','P19.csv'],\n",
    "#             ['P14.csv','P24.csv'],\n",
    "#             ['P13.csv','P30.csv'],\n",
    "#             ['P31.csv','P18.csv'],\n",
    "#             ['P08.csv','P24.csv']]\n",
    "sm=SMOTE()\n",
    "j=True\n",
    "for i in range(len(testPersons)):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # Scramble\n",
    "    random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "    only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "    only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "    both = [key for key, value in depression.items() if len(value) == 2]\n",
    "    # testPerson = ['08'] + ['24']#['16','08'] + ['24','30']\n",
    "#     testPerson = [str(random.choice(only0).split('.')[0].split('P')[1])] \\\n",
    "#     + [str(random.choice(only1).split('.')[0].split('P')[1])]\n",
    "#     # testPerson = [13,17]\n",
    "#     allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "#     trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "#     testPerson = random.sample(only0,k) \\\n",
    "#     + random.sample(only1,k)\n",
    "    testPerson=testPersons[i]\n",
    "    # testPerson = [13,17]\n",
    "    allPerson = contestants\n",
    "    trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "\n",
    "#     # Merge train data and shuffle\n",
    "#     train_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in trainPerson]\n",
    "#     merged_train = pd.concat(train_list, ignore_index=True)\n",
    "#     shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "#     test_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in testPerson]\n",
    "#     merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_test = shuffled_test.drop([ 'img_name'], axis = 1)\n",
    "    for num in trainPerson:\n",
    "        train = pd.read_csv(f'{base_path}/{num}')\n",
    "        train=train.set_index('img_name')\n",
    "        duplicate_rows = train.index.duplicated()\n",
    "        train=train.loc[~duplicate_rows,:]\n",
    "        train_addata=train.copy()\n",
    "        train=train.drop('level',axis=1)\n",
    "        add_data=train.copy()\n",
    "        \n",
    "        add_data=add_data.shift(1)\n",
    "        add_data.columns=[i.split('_')[0]+'_time_lag' for i in train.columns]\n",
    "        \n",
    "#         add_data2=add_data.shift(2)\n",
    "#         add_data2.columns=[i+'_prev2' for i in add_data.columns]\n",
    "\n",
    "        add_vel=add_data.diff(1)\n",
    "        add_vel.columns=[i+'_vel' for i in train.columns]\n",
    "        \n",
    "#         duplicate_rows = add_data.index.duplicated()\n",
    "        train_=pd.concat([train_addata,add_data],axis=1)\n",
    "        train_=train_.reset_index()\n",
    "        train_=train_.dropna()\n",
    "#         train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "        train_list.append(train_)#train_ for addition data\n",
    "    \n",
    "    merged_train = pd.concat(train_list, ignore_index=True)\n",
    "    shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    try:\n",
    "        shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "    except:pass   \n",
    "\n",
    "    for num in testPerson:\n",
    "        test = pd.read_csv(f'{base_path}/{num}')\n",
    "        test=test.set_index('img_name')\n",
    "        \n",
    "        \n",
    "        duplicate_rows = test.index.duplicated()\n",
    "        test=test.loc[~duplicate_rows,:]\n",
    "        test_add=test.copy()\n",
    "        test=test.drop('level',axis=1)\n",
    "        add_data=test.copy()\n",
    "        \n",
    "        add_data=add_data.shift(1)\n",
    "        add_data.columns=[i.split('_')[0]+'_time_lag' for i in test.columns]\n",
    "\n",
    "        add_vel=add_data.diff(1)\n",
    "        add_vel.columns=[i+'_vel' for i in test.columns]\n",
    "        \n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        test_=pd.concat([test_add,add_data],axis=1)\n",
    "        test_=test_.reset_index()\n",
    "        test_=test_.dropna()\n",
    "\n",
    "        test_list.append(test_)#test_ for addition data\n",
    "    merged_test = pd.concat(test_list, ignore_index=True)\n",
    "    shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    try:\n",
    "#         shuffled_test=shuffled_test.reset_index(drop=False)\n",
    "#         shuffled_test['ts']=shuffled_test['img_name'].apply(lambda x :int(int(x.split('_')[-1][:-4])/1000))\n",
    "#         shuffled_test['ts']=shuffled_test['ts'].apply(lambda x: datetime.fromtimestamp(0))\n",
    "        shuffled_test = shuffled_test.drop(['img_name'], axis = 1)\n",
    "        \n",
    "    except Exception as e:print(e)\n",
    "#     add_train_from_test,shuffled_test=shuffled_test[shuffled_test['ts']<shuffled_test['ts'].median()],shuffled_test[shuffled_test['ts']==shuffled_test['ts'].median()]\n",
    "# #     add_train_from_test,shuffled_test=train_test_split(shuffled_test,test_size=0.5)\n",
    "#     add_train_from_test,shuffled_test=add_train_from_test.drop('ts',axis=1),shuffled_test.drop('ts',axis=1)\n",
    "#     shuffled_train=pd.concat([add_train_from_test,shuffled_train],axis=0)\n",
    "\n",
    "    X_train, y_train = shuffled_train.drop('level', axis = 1), shuffled_train['level']\n",
    "\n",
    "    X_test, y_test = shuffled_test.drop('level', axis = 1), shuffled_test['level']\n",
    "    y_train =y_train.astype('category')\n",
    "    y_test =y_test.astype('category')\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    X_train=pd.DataFrame(X_train,columns=X_train.columns)\n",
    "    # y_train=pd.DataFrame(y_train,columns=y_test.columns)\n",
    "    # Print train test contestants\n",
    "    print(\"Train: \", trainPerson)\n",
    "    print(\"Test: \", testPerson)\n",
    "    if j:\n",
    "        print(X_train.columns.T)\n",
    "        j=False\n",
    "\n",
    "    # Logistic Regression\n",
    "    # log_reg = LogisticRegression(max_iter=10000)\n",
    "    # log_reg.fit(X_train, y_train)\n",
    "    # log_reg_pred = log_reg.predict(X_test)\n",
    "    # log_reg_acc = classification_report(y_test, log_reg_pred)\n",
    "    # print(f\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "\n",
    "    # K-Nearest Neighbors (KNN)\n",
    "    knn = KNeighborsClassifier(n_neighbors=100, leaf_size=70)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_rp = classification_report(y_test, knn_pred)\n",
    "    accuracy.append(accuracy_score(y_test, knn_pred))\n",
    "    f1.append(f1_score(y_test, knn_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, knn_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, knn_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, knn_pred))\n",
    "    model.append('KNN_TL')\n",
    "    print('knn ',i)\n",
    "    print(knn_rp)\n",
    "    \n",
    "    \n",
    "#     # Support Vector Machine (SVM)\n",
    "    svm =  XGBClassifier(n_estimators=100)#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_rp = classification_report(y_test, svm_pred)\n",
    "    accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "    f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "    model.append('XGB_TL')\n",
    "    print('XGB_ ',i)\n",
    "    print(svm_rp)\n",
    "    \n",
    "        \n",
    "    svm =  LogisticRegression()#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_rp = classification_report(y_test, svm_pred)\n",
    "    accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "    f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "    model.append('LR_TL')\n",
    "    print('LR_ ',i)\n",
    "    print(svm_rp)\n",
    "\n",
    "#     # Random Forest Classifier\n",
    "#     rf = RandomForestClassifier(n_estimators=1000)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     rf_pred = rf.predict(X_test)\n",
    "#     rf_acc = classification_report(y_test, rf_pred)\n",
    "#     print('rf ',i)\n",
    "#     print(rf_acc)\n",
    "\n",
    "#     xgb = XGBClassifier(n_estimators=1000)\n",
    "#     xgb.fit(X_train, y_train)\n",
    "#     xgb_pred = xgb.predict(X_test)\n",
    "#     xgb_acc = classification_report(y_test, xgb_pred)\n",
    "#     print('xgb ',i)\n",
    "#     print(xgb_acc)\n",
    "\n",
    "#     # Neural Network (MLP Classifier)\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000)\n",
    "#     mlp.fit(X_train, y_train)\n",
    "#     mlp_pred = mlp.predict(X_test)\n",
    "#     mlp_acc = classification_report(y_test, mlp_pred)\n",
    "#     print('MLP ',i)\n",
    "#     print(mlp_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>KNN</th>\n",
       "      <th>KNN_TL</th>\n",
       "      <th>KNN_tlsd</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_TL</th>\n",
       "      <th>LR_tlsd</th>\n",
       "      <th>XGB</th>\n",
       "      <th>XGB_TL</th>\n",
       "      <th>XGB_tlsd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">f1</th>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.605777</td>\n",
       "      <td>0.633254</td>\n",
       "      <td>0.607422</td>\n",
       "      <td>0.518030</td>\n",
       "      <td>0.553670</td>\n",
       "      <td>0.546770</td>\n",
       "      <td>0.485733</td>\n",
       "      <td>0.480837</td>\n",
       "      <td>0.480941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.124857</td>\n",
       "      <td>0.153127</td>\n",
       "      <td>0.163276</td>\n",
       "      <td>0.184007</td>\n",
       "      <td>0.208870</td>\n",
       "      <td>0.237171</td>\n",
       "      <td>0.106946</td>\n",
       "      <td>0.112201</td>\n",
       "      <td>0.123694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.453118</td>\n",
       "      <td>0.508256</td>\n",
       "      <td>0.489680</td>\n",
       "      <td>0.336333</td>\n",
       "      <td>0.353617</td>\n",
       "      <td>0.321414</td>\n",
       "      <td>0.333461</td>\n",
       "      <td>0.330447</td>\n",
       "      <td>0.332893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.561918</td>\n",
       "      <td>0.513298</td>\n",
       "      <td>0.491025</td>\n",
       "      <td>0.397397</td>\n",
       "      <td>0.421372</td>\n",
       "      <td>0.374918</td>\n",
       "      <td>0.423295</td>\n",
       "      <td>0.420353</td>\n",
       "      <td>0.408965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.571765</td>\n",
       "      <td>0.591153</td>\n",
       "      <td>0.530035</td>\n",
       "      <td>0.446569</td>\n",
       "      <td>0.449847</td>\n",
       "      <td>0.438592</td>\n",
       "      <td>0.514211</td>\n",
       "      <td>0.501808</td>\n",
       "      <td>0.473451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.652484</td>\n",
       "      <td>0.674791</td>\n",
       "      <td>0.652031</td>\n",
       "      <td>0.624612</td>\n",
       "      <td>0.697321</td>\n",
       "      <td>0.748134</td>\n",
       "      <td>0.562842</td>\n",
       "      <td>0.522826</td>\n",
       "      <td>0.530810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.789599</td>\n",
       "      <td>0.878773</td>\n",
       "      <td>0.874341</td>\n",
       "      <td>0.785241</td>\n",
       "      <td>0.846191</td>\n",
       "      <td>0.850795</td>\n",
       "      <td>0.594857</td>\n",
       "      <td>0.628749</td>\n",
       "      <td>0.658588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">acccuracy</th>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.691311</td>\n",
       "      <td>0.722596</td>\n",
       "      <td>0.701621</td>\n",
       "      <td>0.554039</td>\n",
       "      <td>0.594569</td>\n",
       "      <td>0.579404</td>\n",
       "      <td>0.516080</td>\n",
       "      <td>0.511713</td>\n",
       "      <td>0.513410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.082903</td>\n",
       "      <td>0.136682</td>\n",
       "      <td>0.142561</td>\n",
       "      <td>0.149673</td>\n",
       "      <td>0.171529</td>\n",
       "      <td>0.205283</td>\n",
       "      <td>0.066256</td>\n",
       "      <td>0.078481</td>\n",
       "      <td>0.093532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.572220</td>\n",
       "      <td>0.517100</td>\n",
       "      <td>0.492771</td>\n",
       "      <td>0.447039</td>\n",
       "      <td>0.449904</td>\n",
       "      <td>0.428149</td>\n",
       "      <td>0.434868</td>\n",
       "      <td>0.426952</td>\n",
       "      <td>0.433818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.653769</td>\n",
       "      <td>0.676056</td>\n",
       "      <td>0.652568</td>\n",
       "      <td>0.449643</td>\n",
       "      <td>0.487312</td>\n",
       "      <td>0.428604</td>\n",
       "      <td>0.469429</td>\n",
       "      <td>0.459221</td>\n",
       "      <td>0.446510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.716080</td>\n",
       "      <td>0.751699</td>\n",
       "      <td>0.721895</td>\n",
       "      <td>0.462636</td>\n",
       "      <td>0.490711</td>\n",
       "      <td>0.438795</td>\n",
       "      <td>0.514444</td>\n",
       "      <td>0.501927</td>\n",
       "      <td>0.474699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.721241</td>\n",
       "      <td>0.785908</td>\n",
       "      <td>0.762879</td>\n",
       "      <td>0.624623</td>\n",
       "      <td>0.697686</td>\n",
       "      <td>0.749748</td>\n",
       "      <td>0.566686</td>\n",
       "      <td>0.541691</td>\n",
       "      <td>0.553415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.793244</td>\n",
       "      <td>0.882216</td>\n",
       "      <td>0.877992</td>\n",
       "      <td>0.786255</td>\n",
       "      <td>0.847230</td>\n",
       "      <td>0.851722</td>\n",
       "      <td>0.594975</td>\n",
       "      <td>0.628773</td>\n",
       "      <td>0.658610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">precision</th>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.633152</td>\n",
       "      <td>0.658327</td>\n",
       "      <td>0.639276</td>\n",
       "      <td>0.606411</td>\n",
       "      <td>0.635201</td>\n",
       "      <td>0.638157</td>\n",
       "      <td>0.591151</td>\n",
       "      <td>0.615486</td>\n",
       "      <td>0.628921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.111368</td>\n",
       "      <td>0.139385</td>\n",
       "      <td>0.148331</td>\n",
       "      <td>0.134898</td>\n",
       "      <td>0.159689</td>\n",
       "      <td>0.172192</td>\n",
       "      <td>0.068715</td>\n",
       "      <td>0.087336</td>\n",
       "      <td>0.105387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.499094</td>\n",
       "      <td>0.525192</td>\n",
       "      <td>0.517467</td>\n",
       "      <td>0.488024</td>\n",
       "      <td>0.488098</td>\n",
       "      <td>0.481944</td>\n",
       "      <td>0.494321</td>\n",
       "      <td>0.496126</td>\n",
       "      <td>0.494740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.573869</td>\n",
       "      <td>0.584759</td>\n",
       "      <td>0.534061</td>\n",
       "      <td>0.500191</td>\n",
       "      <td>0.515493</td>\n",
       "      <td>0.493521</td>\n",
       "      <td>0.543563</td>\n",
       "      <td>0.553063</td>\n",
       "      <td>0.545653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.611691</td>\n",
       "      <td>0.591654</td>\n",
       "      <td>0.571566</td>\n",
       "      <td>0.549634</td>\n",
       "      <td>0.566354</td>\n",
       "      <td>0.574698</td>\n",
       "      <td>0.628900</td>\n",
       "      <td>0.655277</td>\n",
       "      <td>0.654273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.692622</td>\n",
       "      <td>0.715128</td>\n",
       "      <td>0.702729</td>\n",
       "      <td>0.698731</td>\n",
       "      <td>0.753234</td>\n",
       "      <td>0.782292</td>\n",
       "      <td>0.636340</td>\n",
       "      <td>0.667739</td>\n",
       "      <td>0.710920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.788483</td>\n",
       "      <td>0.874901</td>\n",
       "      <td>0.870554</td>\n",
       "      <td>0.795474</td>\n",
       "      <td>0.852827</td>\n",
       "      <td>0.858331</td>\n",
       "      <td>0.652629</td>\n",
       "      <td>0.705225</td>\n",
       "      <td>0.739017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">recall</th>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.656759</td>\n",
       "      <td>0.694068</td>\n",
       "      <td>0.661414</td>\n",
       "      <td>0.597626</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.626235</td>\n",
       "      <td>0.595669</td>\n",
       "      <td>0.611579</td>\n",
       "      <td>0.613617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.111409</td>\n",
       "      <td>0.119521</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.152836</td>\n",
       "      <td>0.178583</td>\n",
       "      <td>0.206414</td>\n",
       "      <td>0.075376</td>\n",
       "      <td>0.083249</td>\n",
       "      <td>0.095712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.495886</td>\n",
       "      <td>0.596610</td>\n",
       "      <td>0.558403</td>\n",
       "      <td>0.430193</td>\n",
       "      <td>0.429789</td>\n",
       "      <td>0.394475</td>\n",
       "      <td>0.467232</td>\n",
       "      <td>0.477675</td>\n",
       "      <td>0.469378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.638886</td>\n",
       "      <td>0.607215</td>\n",
       "      <td>0.572230</td>\n",
       "      <td>0.500444</td>\n",
       "      <td>0.536208</td>\n",
       "      <td>0.485223</td>\n",
       "      <td>0.598375</td>\n",
       "      <td>0.610599</td>\n",
       "      <td>0.600370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.641981</td>\n",
       "      <td>0.650055</td>\n",
       "      <td>0.582575</td>\n",
       "      <td>0.552845</td>\n",
       "      <td>0.567912</td>\n",
       "      <td>0.571185</td>\n",
       "      <td>0.613522</td>\n",
       "      <td>0.617389</td>\n",
       "      <td>0.627543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.706064</td>\n",
       "      <td>0.730456</td>\n",
       "      <td>0.712658</td>\n",
       "      <td>0.697145</td>\n",
       "      <td>0.764357</td>\n",
       "      <td>0.806368</td>\n",
       "      <td>0.643085</td>\n",
       "      <td>0.649412</td>\n",
       "      <td>0.634584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.800977</td>\n",
       "      <td>0.886002</td>\n",
       "      <td>0.881205</td>\n",
       "      <td>0.807502</td>\n",
       "      <td>0.868402</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>0.656130</td>\n",
       "      <td>0.702820</td>\n",
       "      <td>0.736210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">roc_auc</th>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.656759</td>\n",
       "      <td>0.694068</td>\n",
       "      <td>0.661414</td>\n",
       "      <td>0.597626</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.626235</td>\n",
       "      <td>0.595669</td>\n",
       "      <td>0.611579</td>\n",
       "      <td>0.613617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.111409</td>\n",
       "      <td>0.119521</td>\n",
       "      <td>0.137581</td>\n",
       "      <td>0.152836</td>\n",
       "      <td>0.178583</td>\n",
       "      <td>0.206414</td>\n",
       "      <td>0.075376</td>\n",
       "      <td>0.083249</td>\n",
       "      <td>0.095712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.495886</td>\n",
       "      <td>0.596610</td>\n",
       "      <td>0.558403</td>\n",
       "      <td>0.430193</td>\n",
       "      <td>0.429789</td>\n",
       "      <td>0.394475</td>\n",
       "      <td>0.467232</td>\n",
       "      <td>0.477675</td>\n",
       "      <td>0.469378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.638886</td>\n",
       "      <td>0.607215</td>\n",
       "      <td>0.572230</td>\n",
       "      <td>0.500444</td>\n",
       "      <td>0.536208</td>\n",
       "      <td>0.485223</td>\n",
       "      <td>0.598375</td>\n",
       "      <td>0.610599</td>\n",
       "      <td>0.600370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.641981</td>\n",
       "      <td>0.650055</td>\n",
       "      <td>0.582575</td>\n",
       "      <td>0.552845</td>\n",
       "      <td>0.567912</td>\n",
       "      <td>0.571185</td>\n",
       "      <td>0.613522</td>\n",
       "      <td>0.617389</td>\n",
       "      <td>0.627543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.706064</td>\n",
       "      <td>0.730456</td>\n",
       "      <td>0.712658</td>\n",
       "      <td>0.697145</td>\n",
       "      <td>0.764357</td>\n",
       "      <td>0.806368</td>\n",
       "      <td>0.643085</td>\n",
       "      <td>0.649412</td>\n",
       "      <td>0.634584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.800977</td>\n",
       "      <td>0.886002</td>\n",
       "      <td>0.881205</td>\n",
       "      <td>0.807502</td>\n",
       "      <td>0.868402</td>\n",
       "      <td>0.873927</td>\n",
       "      <td>0.656130</td>\n",
       "      <td>0.702820</td>\n",
       "      <td>0.736210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                 KNN    KNN_TL  KNN_tlsd        LR     LR_TL   LR_tlsd  \\\n",
       "f1        count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000   \n",
       "          mean   0.605777  0.633254  0.607422  0.518030  0.553670  0.546770   \n",
       "          std    0.124857  0.153127  0.163276  0.184007  0.208870  0.237171   \n",
       "          min    0.453118  0.508256  0.489680  0.336333  0.353617  0.321414   \n",
       "          25%    0.561918  0.513298  0.491025  0.397397  0.421372  0.374918   \n",
       "          50%    0.571765  0.591153  0.530035  0.446569  0.449847  0.438592   \n",
       "          75%    0.652484  0.674791  0.652031  0.624612  0.697321  0.748134   \n",
       "          max    0.789599  0.878773  0.874341  0.785241  0.846191  0.850795   \n",
       "acccuracy count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000   \n",
       "          mean   0.691311  0.722596  0.701621  0.554039  0.594569  0.579404   \n",
       "          std    0.082903  0.136682  0.142561  0.149673  0.171529  0.205283   \n",
       "          min    0.572220  0.517100  0.492771  0.447039  0.449904  0.428149   \n",
       "          25%    0.653769  0.676056  0.652568  0.449643  0.487312  0.428604   \n",
       "          50%    0.716080  0.751699  0.721895  0.462636  0.490711  0.438795   \n",
       "          75%    0.721241  0.785908  0.762879  0.624623  0.697686  0.749748   \n",
       "          max    0.793244  0.882216  0.877992  0.786255  0.847230  0.851722   \n",
       "precision count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000   \n",
       "          mean   0.633152  0.658327  0.639276  0.606411  0.635201  0.638157   \n",
       "          std    0.111368  0.139385  0.148331  0.134898  0.159689  0.172192   \n",
       "          min    0.499094  0.525192  0.517467  0.488024  0.488098  0.481944   \n",
       "          25%    0.573869  0.584759  0.534061  0.500191  0.515493  0.493521   \n",
       "          50%    0.611691  0.591654  0.571566  0.549634  0.566354  0.574698   \n",
       "          75%    0.692622  0.715128  0.702729  0.698731  0.753234  0.782292   \n",
       "          max    0.788483  0.874901  0.870554  0.795474  0.852827  0.858331   \n",
       "recall    count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000   \n",
       "          mean   0.656759  0.694068  0.661414  0.597626  0.633333  0.626235   \n",
       "          std    0.111409  0.119521  0.137581  0.152836  0.178583  0.206414   \n",
       "          min    0.495886  0.596610  0.558403  0.430193  0.429789  0.394475   \n",
       "          25%    0.638886  0.607215  0.572230  0.500444  0.536208  0.485223   \n",
       "          50%    0.641981  0.650055  0.582575  0.552845  0.567912  0.571185   \n",
       "          75%    0.706064  0.730456  0.712658  0.697145  0.764357  0.806368   \n",
       "          max    0.800977  0.886002  0.881205  0.807502  0.868402  0.873927   \n",
       "roc_auc   count  5.000000  5.000000  5.000000  5.000000  5.000000  5.000000   \n",
       "          mean   0.656759  0.694068  0.661414  0.597626  0.633333  0.626235   \n",
       "          std    0.111409  0.119521  0.137581  0.152836  0.178583  0.206414   \n",
       "          min    0.495886  0.596610  0.558403  0.430193  0.429789  0.394475   \n",
       "          25%    0.638886  0.607215  0.572230  0.500444  0.536208  0.485223   \n",
       "          50%    0.641981  0.650055  0.582575  0.552845  0.567912  0.571185   \n",
       "          75%    0.706064  0.730456  0.712658  0.697145  0.764357  0.806368   \n",
       "          max    0.800977  0.886002  0.881205  0.807502  0.868402  0.873927   \n",
       "\n",
       "model                 XGB    XGB_TL  XGB_tlsd  \n",
       "f1        count  5.000000  5.000000  5.000000  \n",
       "          mean   0.485733  0.480837  0.480941  \n",
       "          std    0.106946  0.112201  0.123694  \n",
       "          min    0.333461  0.330447  0.332893  \n",
       "          25%    0.423295  0.420353  0.408965  \n",
       "          50%    0.514211  0.501808  0.473451  \n",
       "          75%    0.562842  0.522826  0.530810  \n",
       "          max    0.594857  0.628749  0.658588  \n",
       "acccuracy count  5.000000  5.000000  5.000000  \n",
       "          mean   0.516080  0.511713  0.513410  \n",
       "          std    0.066256  0.078481  0.093532  \n",
       "          min    0.434868  0.426952  0.433818  \n",
       "          25%    0.469429  0.459221  0.446510  \n",
       "          50%    0.514444  0.501927  0.474699  \n",
       "          75%    0.566686  0.541691  0.553415  \n",
       "          max    0.594975  0.628773  0.658610  \n",
       "precision count  5.000000  5.000000  5.000000  \n",
       "          mean   0.591151  0.615486  0.628921  \n",
       "          std    0.068715  0.087336  0.105387  \n",
       "          min    0.494321  0.496126  0.494740  \n",
       "          25%    0.543563  0.553063  0.545653  \n",
       "          50%    0.628900  0.655277  0.654273  \n",
       "          75%    0.636340  0.667739  0.710920  \n",
       "          max    0.652629  0.705225  0.739017  \n",
       "recall    count  5.000000  5.000000  5.000000  \n",
       "          mean   0.595669  0.611579  0.613617  \n",
       "          std    0.075376  0.083249  0.095712  \n",
       "          min    0.467232  0.477675  0.469378  \n",
       "          25%    0.598375  0.610599  0.600370  \n",
       "          50%    0.613522  0.617389  0.627543  \n",
       "          75%    0.643085  0.649412  0.634584  \n",
       "          max    0.656130  0.702820  0.736210  \n",
       "roc_auc   count  5.000000  5.000000  5.000000  \n",
       "          mean   0.595669  0.611579  0.613617  \n",
       "          std    0.075376  0.083249  0.095712  \n",
       "          min    0.467232  0.477675  0.469378  \n",
       "          25%    0.598375  0.610599  0.600370  \n",
       "          50%    0.613522  0.617389  0.627543  \n",
       "          75%    0.643085  0.649412  0.634584  \n",
       "          max    0.656130  0.702820  0.736210  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_result=pd.DataFrame(np.array([f1,accuracy,precision,recall,roc_auc,model]).T,\n",
    "                       columns=['f1','acccuracy','precision','recall','roc_auc','model'])\n",
    "df_result2=df_result.iloc[:,:-1].astype(float)\n",
    "df_result2['model']=df_result['model']\n",
    "df_result2.groupby('model').describe().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "fs = SelectKBest(score_func=f_regression,k=15)\n",
    "# Applying feature selection\n",
    "fit = fs.fit(X_train,y_train)\n",
    "features_score = pd.DataFrame(fit.pvalues_)\n",
    "features = pd.DataFrame(X_train.columns)\n",
    "feature_score = pd.concat([features,features_score],axis=1)\n",
    "# Assigning column names\n",
    "feature_score.columns = [\"Input_Features\",\"p_values\"]\n",
    "feature_score=feature_score.sort_values('p_values', ascending=True)\n",
    "print(feature_score.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_group(x):\n",
    "    if 'lag' in x :\n",
    "        return \"Time Lag\"\n",
    "    if 'vel' in x:\n",
    "        return \"Succesive Different\"\n",
    "    if 'AU' in x:\n",
    "        return \"AU\"\n",
    "    if x in ['fear','neutral','happiness','surprise','sadness','anger','disgust']:\n",
    "        return \"Emotion\"\n",
    "    return \"Facial Characteristic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_score_all=pd.concat([feature_score,feature_score1],axis=0)\n",
    "# feature_score_all=feature_score_all.drop_duplicates()\n",
    "feature_score_all['Feature Type']=feature_score_all['Input_Features'].apply(to_group)\n",
    "print(feature_score_all.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(feature_score_all,y='Feature Type',x='p_values',hue='Feature Type')\n",
    "plt.savefig('./image_paper/p_value.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# # Create the explainer\n",
    "# explainer1 = shap.Explainer(xgb,X_train)#model_smotesvm\n",
    "\n",
    "# shap_values = explainer1(X_train, check_additivity=False)\n",
    "# print(\"Variable Importance Plot - Global Interpretation\")\n",
    "# # figure = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.beeswarm(shap_values,max_display=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=feature_score['Input_Features'].to_list()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num in ['P19.csv']:\n",
    "#     train = pd.read_csv(f'{base_path}/{num}')\n",
    "#     train=train.set_index('img_name')\n",
    "#     duplicate_rows = train.index.duplicated()\n",
    "#     train=train.loc[~duplicate_rows,:]\n",
    "#     add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "#     add_data=add_data.drop('Unnamed: 0',axis=1)\n",
    "#     add_data=add_data.set_index('img_name')\n",
    "#     duplicate_rows = add_data.index.duplicated()\n",
    "#     add_data=add_data.loc[~duplicate_rows,:]\n",
    "#     train_=pd.concat([add_data,train],axis=1)\n",
    "#     train_=train_.reset_index()\n",
    "#     train_=train_.dropna()\n",
    "#     train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,\\\n",
    "f1_score,precision_score,recall_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "k=1\n",
    "\n",
    "f1=[]\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "roc_auc=[]\n",
    "model=[]\n",
    "sm=SMOTE()\n",
    "for i in range(5):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # Scramble\n",
    "    random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "    only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "    only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "    both = [key for key, value in depression.items() if len(value) == 2]\n",
    "    # testPerson = ['08'] + ['24']#['16','08'] + ['24','30']\n",
    "#     testPerson = [str(random.choice(only0).split('.')[0].split('P')[1])] \\\n",
    "#     + [str(random.choice(only1).split('.')[0].split('P')[1])]\n",
    "#     # testPerson = [13,17]\n",
    "#     allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "#     trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "    testPerson = random.sample(only0,k) \\\n",
    "    + random.sample(only1,k)\n",
    "    # testPerson = [13,17]\n",
    "    allPerson = contestants\n",
    "    trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "\n",
    "#     # Merge train data and shuffle\n",
    "#     train_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in trainPerson]\n",
    "#     merged_train = pd.concat(train_list, ignore_index=True)\n",
    "#     shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "#     test_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in testPerson]\n",
    "#     merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_test = shuffled_test.drop([ 'img_name'], axis = 1)\n",
    "    for num in trainPerson:\n",
    "        train = pd.read_csv(f'{base_path}/{num}')\n",
    "        train=train.set_index('img_name')\n",
    "        duplicate_rows = train.index.duplicated()\n",
    "        train=train.loc[~duplicate_rows,:]\n",
    "        add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "        add_data=add_data.drop(['Unnamed: 0','level'],axis=1)\n",
    "        add_data=add_data.set_index('img_name')\n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        train_=pd.concat([train,add_data],axis=1)\n",
    "        train_=train_.reset_index()\n",
    "        train_=train_.dropna()\n",
    "        train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "        train_list.append(train_)\n",
    "    \n",
    "    merged_train = pd.concat(train_list, ignore_index=True)\n",
    "    shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "    for num in testPerson:\n",
    "        test = pd.read_csv(f'{base_path}/{num}')\n",
    "        test=test.set_index('img_name')\n",
    "        duplicate_rows = test.index.duplicated()\n",
    "        test=test.loc[~duplicate_rows,:]\n",
    "        add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "        add_data=add_data.drop(['Unnamed: 0','level'],axis=1)\n",
    "        add_data=add_data.set_index('img_name')\n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        test_=pd.concat([test,add_data],axis=1)\n",
    "        test_=test_.reset_index()\n",
    "        test_=test_.dropna()\n",
    "        test_=test_.drop(['timestamp','ID'],axis=1)\n",
    "        test_list.append(test_)\n",
    "    merged_test = pd.concat(test_list, ignore_index=True)\n",
    "    shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    shuffled_test = shuffled_test.drop(['img_name'], axis = 1)\n",
    "\n",
    "    X_train, y_train = shuffled_train.drop('level', axis = 1), shuffled_train['level']\n",
    "\n",
    "    X_test, y_test = shuffled_test.drop('level', axis = 1), shuffled_test['level']\n",
    "    y_train =y_train.astype('category')\n",
    "    y_test =y_test.astype('category')\n",
    "    X_train=X_train[feat]\n",
    "    X_test=X_test[feat]\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    X_train=pd.DataFrame(X_train,columns=X_test.columns)\n",
    "    # y_train=pd.DataFrame(y_train,columns=y_test.columns)\n",
    "    # Print train test contestants\n",
    "    print(\"Train: \", trainPerson)\n",
    "    print(\"Test: \", testPerson)\n",
    "    \n",
    "\n",
    "    # Logistic Regression\n",
    "    # log_reg = LogisticRegression(max_iter=10000)\n",
    "    # log_reg.fit(X_train, y_train)\n",
    "    # log_reg_pred = log_reg.predict(X_test)\n",
    "    # log_reg_acc = classification_report(y_test, log_reg_pred)\n",
    "    # print(f\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "\n",
    "    # K-Nearest Neighbors (KNN)\n",
    "    knn = KNeighborsClassifier(n_neighbors=100)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_rp = classification_report(y_test, knn_pred)\n",
    "    accuracy.append(accuracy_score(y_test, knn_pred))\n",
    "    f1.append(f1_score(y_test, knn_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, knn_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, knn_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, knn_pred))\n",
    "    model.append('KNN')\n",
    "    print('knn ',i)\n",
    "    print(knn_rp)\n",
    "    \n",
    "    \n",
    "#     # Support Vector Machine (SVM)\n",
    "#     svm = SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "#     svm.fit(X_train, y_train)\n",
    "#     svm_pred = svm.predict(X_test)\n",
    "#     svm_rp = classification_report(y_test, svm_pred)\n",
    "#     accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "#     f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "#     precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "#     recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "#     roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "#     model.append('SVM')\n",
    "#     print('SVM ',i)\n",
    "#     print(svm_rp)\n",
    "\n",
    "#     # Random Forest Classifier\n",
    "#     rf = RandomForestClassifier(n_estimators=1000)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     rf_pred = rf.predict(X_test)\n",
    "#     rf_acc = classification_report(y_test, rf_pred)\n",
    "#     print('rf ',i)\n",
    "#     print(rf_acc)\n",
    "\n",
    "#     xgb = XGBClassifier(n_estimators=1000)\n",
    "#     xgb.fit(X_train, y_train)\n",
    "#     xgb_pred = xgb.predict(X_test)\n",
    "#     xgb_acc = classification_report(y_test, xgb_pred)\n",
    "#     print('xgb ',i)\n",
    "#     print(xgb_acc)\n",
    "\n",
    "#     # Neural Network (MLP Classifier)\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000)\n",
    "#     mlp.fit(X_train, y_train)\n",
    "#     mlp_pred = mlp.predict(X_test)\n",
    "#     mlp_acc = classification_report(y_test, mlp_pred)\n",
    "#     print('MLP ',i)\n",
    "#     print(mlp_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=pd.DataFrame(np.array([f1,accuracy,precision,recall,roc_auc,model]).T,\n",
    "                       columns=['f1','acccuracy','precision','recall','roc_auc','model'])\n",
    "df_result2=df_result.iloc[:,:-1].astype(float)\n",
    "df_result2['model']=df_result['model']\n",
    "df_result2.groupby('model').describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:40:54.373921Z",
     "iopub.status.busy": "2025-02-02T19:40:54.373592Z",
     "iopub.status.idle": "2025-02-02T19:40:54.379421Z",
     "shell.execute_reply": "2025-02-02T19:40:54.378589Z",
     "shell.execute_reply.started": "2025-02-02T19:40:54.373896Z"
    }
   },
   "outputs": [],
   "source": [
    "(only0, only1, both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:45:05.965421Z",
     "iopub.status.busy": "2025-02-02T19:45:05.965087Z",
     "iopub.status.idle": "2025-02-02T19:45:06.018330Z",
     "shell.execute_reply": "2025-02-02T19:45:06.017393Z",
     "shell.execute_reply.started": "2025-02-02T19:45:05.965393Z"
    }
   },
   "outputs": [],
   "source": [
    "person_len = dict()\n",
    "for e in depression:\n",
    "    person_len[e] = len(pd.read_csv(f'{base_path}/{e}'))\n",
    "person_len = (sorted(person_len.items()))\n",
    "person_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6512233,
     "sourceId": 10529402,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
