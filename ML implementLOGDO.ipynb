{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.274603Z",
     "iopub.status.busy": "2025-02-02T19:38:53.274384Z",
     "iopub.status.idle": "2025-02-02T19:38:53.278266Z",
     "shell.execute_reply": "2025-02-02T19:38:53.277467Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.274583Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.279583Z",
     "iopub.status.busy": "2025-02-02T19:38:53.279230Z",
     "iopub.status.idle": "2025-02-02T19:38:53.296252Z",
     "shell.execute_reply": "2025-02-02T19:38:53.295310Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.279552Z"
    }
   },
   "outputs": [],
   "source": [
    "base_path = \"./feature_image\"\n",
    "contestants = os.listdir(f\"{base_path}\")\n",
    "contestants = [c for c in contestants if c.endswith('csv')]\n",
    "add_data_path=\"./data_img_info_csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xử lý NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.297222Z",
     "iopub.status.busy": "2025-02-02T19:38:53.297015Z",
     "iopub.status.idle": "2025-02-02T19:38:53.448996Z",
     "shell.execute_reply": "2025-02-02T19:38:53.448249Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.297205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>...</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "      <th>img_name</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017239</td>\n",
       "      <td>0.015235</td>\n",
       "      <td>0.176891</td>\n",
       "      <td>0.341711</td>\n",
       "      <td>0.028478</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>0.416213</td>\n",
       "      <td>0.601805</td>\n",
       "      <td>0.537354</td>\n",
       "      <td>0.211898</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324528</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.297471</td>\n",
       "      <td>0.045166</td>\n",
       "      <td>0.989468</td>\n",
       "      <td>0.470132</td>\n",
       "      <td>0.182868</td>\n",
       "      <td>0.682754</td>\n",
       "      <td>./image/P14/P14_1659070888638.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.030872</td>\n",
       "      <td>0.009780</td>\n",
       "      <td>0.125229</td>\n",
       "      <td>0.264078</td>\n",
       "      <td>0.030885</td>\n",
       "      <td>0.006509</td>\n",
       "      <td>0.532647</td>\n",
       "      <td>0.546128</td>\n",
       "      <td>0.187422</td>\n",
       "      <td>0.341496</td>\n",
       "      <td>...</td>\n",
       "      <td>0.377041</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628678</td>\n",
       "      <td>0.065833</td>\n",
       "      <td>0.990498</td>\n",
       "      <td>0.501712</td>\n",
       "      <td>0.313960</td>\n",
       "      <td>0.630475</td>\n",
       "      <td>./image/P14/P14_1659085749056.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.013230</td>\n",
       "      <td>0.219520</td>\n",
       "      <td>0.173419</td>\n",
       "      <td>0.070296</td>\n",
       "      <td>0.011200</td>\n",
       "      <td>0.506919</td>\n",
       "      <td>0.464037</td>\n",
       "      <td>0.232327</td>\n",
       "      <td>0.461129</td>\n",
       "      <td>...</td>\n",
       "      <td>0.459882</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.479015</td>\n",
       "      <td>0.245514</td>\n",
       "      <td>0.990322</td>\n",
       "      <td>0.193106</td>\n",
       "      <td>0.368260</td>\n",
       "      <td>0.850828</td>\n",
       "      <td>./image/P14/P14_1659684037468.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007522</td>\n",
       "      <td>0.009384</td>\n",
       "      <td>0.454181</td>\n",
       "      <td>0.181890</td>\n",
       "      <td>0.040242</td>\n",
       "      <td>0.030942</td>\n",
       "      <td>0.275839</td>\n",
       "      <td>0.508276</td>\n",
       "      <td>0.269019</td>\n",
       "      <td>0.458627</td>\n",
       "      <td>...</td>\n",
       "      <td>0.637235</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.819013</td>\n",
       "      <td>0.641877</td>\n",
       "      <td>0.937381</td>\n",
       "      <td>0.077706</td>\n",
       "      <td>0.319819</td>\n",
       "      <td>0.190604</td>\n",
       "      <td>./image/P14/P14_1659265517964.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.024187</td>\n",
       "      <td>0.010670</td>\n",
       "      <td>0.089908</td>\n",
       "      <td>0.288213</td>\n",
       "      <td>0.039413</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>0.543699</td>\n",
       "      <td>0.591552</td>\n",
       "      <td>0.371097</td>\n",
       "      <td>0.553130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.369656</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.342236</td>\n",
       "      <td>0.050512</td>\n",
       "      <td>0.979466</td>\n",
       "      <td>0.422746</td>\n",
       "      <td>0.056997</td>\n",
       "      <td>0.569246</td>\n",
       "      <td>./image/P14/P14_1658984695198.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>0.040957</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.068325</td>\n",
       "      <td>0.171963</td>\n",
       "      <td>0.032893</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.670815</td>\n",
       "      <td>0.792422</td>\n",
       "      <td>0.662862</td>\n",
       "      <td>0.146113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.254034</td>\n",
       "      <td>0.063396</td>\n",
       "      <td>0.983158</td>\n",
       "      <td>0.445436</td>\n",
       "      <td>0.105169</td>\n",
       "      <td>0.638492</td>\n",
       "      <td>./image/P14/P14_1659279866187.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.145236</td>\n",
       "      <td>0.122815</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.650567</td>\n",
       "      <td>0.637243</td>\n",
       "      <td>0.314642</td>\n",
       "      <td>0.136442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>0.270353</td>\n",
       "      <td>0.974202</td>\n",
       "      <td>0.458458</td>\n",
       "      <td>0.115001</td>\n",
       "      <td>0.273430</td>\n",
       "      <td>./image/P14/P14_1659456638127.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.202055</td>\n",
       "      <td>0.284258</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.423687</td>\n",
       "      <td>0.624641</td>\n",
       "      <td>0.367987</td>\n",
       "      <td>0.292672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645095</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.900835</td>\n",
       "      <td>0.509297</td>\n",
       "      <td>0.077086</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>./image/P14/P14_1659456537639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.097032</td>\n",
       "      <td>0.256737</td>\n",
       "      <td>0.053264</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.559576</td>\n",
       "      <td>0.672477</td>\n",
       "      <td>0.596553</td>\n",
       "      <td>0.303114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.201306</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.470552</td>\n",
       "      <td>0.115043</td>\n",
       "      <td>0.567455</td>\n",
       "      <td>./image/P14/P14_1659510069849.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.481779</td>\n",
       "      <td>0.074605</td>\n",
       "      <td>0.030746</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.392362</td>\n",
       "      <td>0.596630</td>\n",
       "      <td>0.365489</td>\n",
       "      <td>0.304782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.674624</td>\n",
       "      <td>0.100138</td>\n",
       "      <td>0.986878</td>\n",
       "      <td>0.398863</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.681527</td>\n",
       "      <td>./image/P14/P14_1658932945727.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         anger   disgust      fear  happiness   sadness  surprise   neutral  \\\n",
       "0     0.017239  0.015235  0.176891   0.341711  0.028478  0.004233  0.416213   \n",
       "1     0.030872  0.009780  0.125229   0.264078  0.030885  0.006509  0.532647   \n",
       "2     0.005416  0.013230  0.219520   0.173419  0.070296  0.011200  0.506919   \n",
       "3     0.007522  0.009384  0.454181   0.181890  0.040242  0.030942  0.275839   \n",
       "4     0.024187  0.010670  0.089908   0.288213  0.039413  0.003910  0.543699   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "1915  0.040957  0.010263  0.068325   0.171963  0.032893  0.004782  0.670815   \n",
       "1916  0.009720  0.003048  0.145236   0.122815  0.060651  0.007962  0.650567   \n",
       "1917  0.029612  0.012102  0.202055   0.284258  0.032657  0.015629  0.423687   \n",
       "1918  0.013094  0.010975  0.097032   0.256737  0.053264  0.009323  0.559576   \n",
       "1919  0.007007  0.006672  0.481779   0.074605  0.030746  0.006829  0.392362   \n",
       "\n",
       "          AU01      AU02      AU04  ...      AU17  AU20      AU23      AU24  \\\n",
       "0     0.601805  0.537354  0.211898  ...  0.324528   1.0  0.297471  0.045166   \n",
       "1     0.546128  0.187422  0.341496  ...  0.377041   0.0  0.628678  0.065833   \n",
       "2     0.464037  0.232327  0.461129  ...  0.459882   1.0  0.479015  0.245514   \n",
       "3     0.508276  0.269019  0.458627  ...  0.637235   1.0  0.819013  0.641877   \n",
       "4     0.591552  0.371097  0.553130  ...  0.369656   1.0  0.342236  0.050512   \n",
       "...        ...       ...       ...  ...       ...   ...       ...       ...   \n",
       "1915  0.792422  0.662862  0.146113  ...  0.280971   1.0  0.254034  0.063396   \n",
       "1916  0.637243  0.314642  0.136442  ...  0.389752   0.0  0.760976  0.270353   \n",
       "1917  0.624641  0.367987  0.292672  ...  0.322887   1.0  0.645095  0.068958   \n",
       "1918  0.672477  0.596553  0.303114  ...  0.302141   1.0  0.547257  0.201306   \n",
       "1919  0.596630  0.365489  0.304782  ...  0.453735   1.0  0.674624  0.100138   \n",
       "\n",
       "          AU25      AU26      AU28      AU43  \\\n",
       "0     0.989468  0.470132  0.182868  0.682754   \n",
       "1     0.990498  0.501712  0.313960  0.630475   \n",
       "2     0.990322  0.193106  0.368260  0.850828   \n",
       "3     0.937381  0.077706  0.319819  0.190604   \n",
       "4     0.979466  0.422746  0.056997  0.569246   \n",
       "...        ...       ...       ...       ...   \n",
       "1915  0.983158  0.445436  0.105169  0.638492   \n",
       "1916  0.974202  0.458458  0.115001  0.273430   \n",
       "1917  0.900835  0.509297  0.077086  0.406576   \n",
       "1918  0.998685  0.470552  0.115043  0.567455   \n",
       "1919  0.986878  0.398863  0.058895  0.681527   \n",
       "\n",
       "                               img_name  level  \n",
       "0     ./image/P14/P14_1659070888638.png      0  \n",
       "1     ./image/P14/P14_1659085749056.png      0  \n",
       "2     ./image/P14/P14_1659684037468.png      0  \n",
       "3     ./image/P14/P14_1659265517964.png      0  \n",
       "4     ./image/P14/P14_1658984695198.png      0  \n",
       "...                                 ...    ...  \n",
       "1915  ./image/P14/P14_1659279866187.png      0  \n",
       "1916  ./image/P14/P14_1659456638127.png      0  \n",
       "1917  ./image/P14/P14_1659456537639.png      0  \n",
       "1918  ./image/P14/P14_1659510069849.png      0  \n",
       "1919  ./image/P14/P14_1658932945727.png      0  \n",
       "\n",
       "[1920 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for c in contestants:\n",
    "    temp = pd.read_csv(f\"{base_path}/{c}\")\n",
    "    temp = temp.dropna()\n",
    "#     temp =temp .drop('Unnamed: 0',axis=1)\n",
    "    temp['level'] = temp['level'].astype(float).astype(int)\n",
    "    temp=temp.loc[:,~temp.columns.str.contains('Unnamed',regex=True)]\n",
    "    os.remove(f\"{base_path}/{c}\")\n",
    "    temp.to_csv(f\"{base_path}/{c}\", index=False)\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "person=[c.split('_')[0] for c in contestants]\n",
    "person=list(set(person))\n",
    "for per in person:\n",
    "    if len(contestants)<30:\n",
    "        break\n",
    "    contestant_split=[i for i in contestants if per in i]\n",
    "    merge=[]\n",
    "    for i in contestant_split:\n",
    "        temp = pd.read_csv(f\"{base_path}/{i}\")\n",
    "        os.remove(f\"{base_path}/{i}\")\n",
    "        merge.append(temp)\n",
    "    merge_df=pd.concat(merge,axis=0)\n",
    "    merge_df=merge_df.reset_index(drop=True)\n",
    "    merge_df.to_csv(f\"{base_path}/{per}.csv\", index=False)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.450042Z",
     "iopub.status.busy": "2025-02-02T19:38:53.449778Z",
     "iopub.status.idle": "2025-02-02T19:38:53.506199Z",
     "shell.execute_reply": "2025-02-02T19:38:53.505352Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.450020Z"
    }
   },
   "outputs": [],
   "source": [
    "depression = dict()\n",
    "contestants = os.listdir(f\"{base_path}\")\n",
    "contestants = [c for c in contestants if c.endswith('csv')]\n",
    "for c in contestants:\n",
    "    if not c.endswith('csv'):\n",
    "        continue\n",
    "    if c =='P27.csv':\n",
    "        continue\n",
    "    temp = pd.read_csv(f\"{base_path}/{c}\")\n",
    "    depression[c] = list(temp[\"level\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('P19.csv', [1]), ('P31.csv', [0]), ('P25.csv', [0]), ('P24.csv', [1]), ('P30.csv', [1]), ('P18.csv', [1]), ('P33.csv', [0]), ('P23.csv', [0]), ('P36.csv', [0]), ('P34.csv', [0]), ('P20.csv', [0]), ('P08.csv', [0]), ('P21.csv', [1, 0]), ('P35.csv', [0]), ('P38.csv', [0]), ('P10.csv', [0, 1]), ('P13.csv', [0]), ('P12.csv', [1]), ('P16.csv', [0]), ('P17.csv', [1]), ('P15.csv', [1, 0]), ('P29.csv', [0]), ('P28.csv', [0]), ('P14.csv', [0])])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depression.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.507395Z",
     "iopub.status.busy": "2025-02-02T19:38:53.507117Z",
     "iopub.status.idle": "2025-02-02T19:38:53.514403Z",
     "shell.execute_reply": "2025-02-02T19:38:53.513507Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.507367Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['P31.csv',\n",
       " 'P25.csv',\n",
       " 'P33.csv',\n",
       " 'P23.csv',\n",
       " 'P36.csv',\n",
       " 'P34.csv',\n",
       " 'P20.csv',\n",
       " 'P08.csv',\n",
       " 'P35.csv',\n",
       " 'P38.csv',\n",
       " 'P13.csv',\n",
       " 'P16.csv',\n",
       " 'P29.csv',\n",
       " 'P28.csv',\n",
       " 'P14.csv']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "([key for key, value in depression.items() if value[0] == 0 and len(value) == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.515617Z",
     "iopub.status.busy": "2025-02-02T19:38:53.515336Z",
     "iopub.status.idle": "2025-02-02T19:38:53.528372Z",
     "shell.execute_reply": "2025-02-02T19:38:53.527684Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.515597Z"
    }
   },
   "outputs": [],
   "source": [
    "# (depression)\n",
    "# len(os.listdir(base_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chia train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', '.DS_Store', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n"
     ]
    }
   ],
   "source": [
    "contestants = os.listdir(f\"{base_path}\")\n",
    "print(contestants)\n",
    "contestants = [c for c in contestants if c.endswith('csv')]\n",
    "print(contestants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:38:53.529515Z",
     "iopub.status.busy": "2025-02-02T19:38:53.529235Z",
     "iopub.status.idle": "2025-02-02T19:38:53.543598Z",
     "shell.execute_reply": "2025-02-02T19:38:53.542782Z",
     "shell.execute_reply.started": "2025-02-02T19:38:53.529485Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "both = [key for key, value in depression.items() if len(value) == 2]\n",
    "# both.pop('P17.csv')\n",
    "contestants=[c for c in contestants if c.endswith('csv')]\n",
    "testPerson = [int(random.choice(only1).split('.')[0].split('P')[1])] + [int(random.choice(only0).split('.')[0].split('P')[1])]\n",
    "allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "trainPerson = [a for a in allPerson if a not in testPerson]\n",
    "# testPerson = [8]\n",
    "# trainPerson = [21]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>...</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "      <th>img_name</th>\n",
       "      <th>level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.013205</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.374994</td>\n",
       "      <td>0.102363</td>\n",
       "      <td>0.049852</td>\n",
       "      <td>0.018875</td>\n",
       "      <td>0.435509</td>\n",
       "      <td>0.713220</td>\n",
       "      <td>0.510258</td>\n",
       "      <td>0.059922</td>\n",
       "      <td>...</td>\n",
       "      <td>0.466907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.535557</td>\n",
       "      <td>0.490966</td>\n",
       "      <td>0.935579</td>\n",
       "      <td>0.121045</td>\n",
       "      <td>0.333033</td>\n",
       "      <td>0.121158</td>\n",
       "      <td>./image/P19/P19_1659487998833.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011412</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>0.171314</td>\n",
       "      <td>0.144660</td>\n",
       "      <td>0.163057</td>\n",
       "      <td>0.040847</td>\n",
       "      <td>0.466711</td>\n",
       "      <td>0.674876</td>\n",
       "      <td>0.313608</td>\n",
       "      <td>0.280145</td>\n",
       "      <td>...</td>\n",
       "      <td>0.418187</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.635475</td>\n",
       "      <td>0.157254</td>\n",
       "      <td>0.975519</td>\n",
       "      <td>0.468108</td>\n",
       "      <td>0.318228</td>\n",
       "      <td>0.165630</td>\n",
       "      <td>./image/P19/P19_1659020214976.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014839</td>\n",
       "      <td>0.025150</td>\n",
       "      <td>0.251343</td>\n",
       "      <td>0.275955</td>\n",
       "      <td>0.048502</td>\n",
       "      <td>0.013539</td>\n",
       "      <td>0.370671</td>\n",
       "      <td>0.538187</td>\n",
       "      <td>0.284743</td>\n",
       "      <td>0.386870</td>\n",
       "      <td>...</td>\n",
       "      <td>0.407967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.679930</td>\n",
       "      <td>0.900595</td>\n",
       "      <td>0.114604</td>\n",
       "      <td>0.304304</td>\n",
       "      <td>0.082065</td>\n",
       "      <td>./image/P19/P19_1659075503842.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.011381</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.194381</td>\n",
       "      <td>0.039042</td>\n",
       "      <td>0.111313</td>\n",
       "      <td>0.022853</td>\n",
       "      <td>0.619285</td>\n",
       "      <td>0.711540</td>\n",
       "      <td>0.427390</td>\n",
       "      <td>0.073868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.498661</td>\n",
       "      <td>0.593501</td>\n",
       "      <td>0.636757</td>\n",
       "      <td>0.147229</td>\n",
       "      <td>0.222992</td>\n",
       "      <td>0.079755</td>\n",
       "      <td>./image/P19/P19_1659021205080.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005302</td>\n",
       "      <td>0.002227</td>\n",
       "      <td>0.185530</td>\n",
       "      <td>0.082221</td>\n",
       "      <td>0.074113</td>\n",
       "      <td>0.005386</td>\n",
       "      <td>0.645222</td>\n",
       "      <td>0.608201</td>\n",
       "      <td>0.277692</td>\n",
       "      <td>0.214240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.430974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.397525</td>\n",
       "      <td>0.039843</td>\n",
       "      <td>0.996547</td>\n",
       "      <td>0.306116</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>0.117396</td>\n",
       "      <td>./image/P19/P19_1659355704725.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>0.040957</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>0.068325</td>\n",
       "      <td>0.171963</td>\n",
       "      <td>0.032893</td>\n",
       "      <td>0.004782</td>\n",
       "      <td>0.670815</td>\n",
       "      <td>0.792422</td>\n",
       "      <td>0.662862</td>\n",
       "      <td>0.146113</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280971</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.254034</td>\n",
       "      <td>0.063396</td>\n",
       "      <td>0.983158</td>\n",
       "      <td>0.445436</td>\n",
       "      <td>0.105169</td>\n",
       "      <td>0.638492</td>\n",
       "      <td>./image/P14/P14_1659279866187.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1916</th>\n",
       "      <td>0.009720</td>\n",
       "      <td>0.003048</td>\n",
       "      <td>0.145236</td>\n",
       "      <td>0.122815</td>\n",
       "      <td>0.060651</td>\n",
       "      <td>0.007962</td>\n",
       "      <td>0.650567</td>\n",
       "      <td>0.637243</td>\n",
       "      <td>0.314642</td>\n",
       "      <td>0.136442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.389752</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.760976</td>\n",
       "      <td>0.270353</td>\n",
       "      <td>0.974202</td>\n",
       "      <td>0.458458</td>\n",
       "      <td>0.115001</td>\n",
       "      <td>0.273430</td>\n",
       "      <td>./image/P14/P14_1659456638127.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1917</th>\n",
       "      <td>0.029612</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.202055</td>\n",
       "      <td>0.284258</td>\n",
       "      <td>0.032657</td>\n",
       "      <td>0.015629</td>\n",
       "      <td>0.423687</td>\n",
       "      <td>0.624641</td>\n",
       "      <td>0.367987</td>\n",
       "      <td>0.292672</td>\n",
       "      <td>...</td>\n",
       "      <td>0.322887</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.645095</td>\n",
       "      <td>0.068958</td>\n",
       "      <td>0.900835</td>\n",
       "      <td>0.509297</td>\n",
       "      <td>0.077086</td>\n",
       "      <td>0.406576</td>\n",
       "      <td>./image/P14/P14_1659456537639.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1918</th>\n",
       "      <td>0.013094</td>\n",
       "      <td>0.010975</td>\n",
       "      <td>0.097032</td>\n",
       "      <td>0.256737</td>\n",
       "      <td>0.053264</td>\n",
       "      <td>0.009323</td>\n",
       "      <td>0.559576</td>\n",
       "      <td>0.672477</td>\n",
       "      <td>0.596553</td>\n",
       "      <td>0.303114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302141</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.547257</td>\n",
       "      <td>0.201306</td>\n",
       "      <td>0.998685</td>\n",
       "      <td>0.470552</td>\n",
       "      <td>0.115043</td>\n",
       "      <td>0.567455</td>\n",
       "      <td>./image/P14/P14_1659510069849.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>0.007007</td>\n",
       "      <td>0.006672</td>\n",
       "      <td>0.481779</td>\n",
       "      <td>0.074605</td>\n",
       "      <td>0.030746</td>\n",
       "      <td>0.006829</td>\n",
       "      <td>0.392362</td>\n",
       "      <td>0.596630</td>\n",
       "      <td>0.365489</td>\n",
       "      <td>0.304782</td>\n",
       "      <td>...</td>\n",
       "      <td>0.453735</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.674624</td>\n",
       "      <td>0.100138</td>\n",
       "      <td>0.986878</td>\n",
       "      <td>0.398863</td>\n",
       "      <td>0.058895</td>\n",
       "      <td>0.681527</td>\n",
       "      <td>./image/P14/P14_1658932945727.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34364 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         anger   disgust      fear  happiness   sadness  surprise   neutral  \\\n",
       "0     0.013205  0.005202  0.374994   0.102363  0.049852  0.018875  0.435509   \n",
       "1     0.011412  0.002000  0.171314   0.144660  0.163057  0.040847  0.466711   \n",
       "2     0.014839  0.025150  0.251343   0.275955  0.048502  0.013539  0.370671   \n",
       "3     0.011381  0.001744  0.194381   0.039042  0.111313  0.022853  0.619285   \n",
       "4     0.005302  0.002227  0.185530   0.082221  0.074113  0.005386  0.645222   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "1915  0.040957  0.010263  0.068325   0.171963  0.032893  0.004782  0.670815   \n",
       "1916  0.009720  0.003048  0.145236   0.122815  0.060651  0.007962  0.650567   \n",
       "1917  0.029612  0.012102  0.202055   0.284258  0.032657  0.015629  0.423687   \n",
       "1918  0.013094  0.010975  0.097032   0.256737  0.053264  0.009323  0.559576   \n",
       "1919  0.007007  0.006672  0.481779   0.074605  0.030746  0.006829  0.392362   \n",
       "\n",
       "          AU01      AU02      AU04  ...      AU17  AU20      AU23      AU24  \\\n",
       "0     0.713220  0.510258  0.059922  ...  0.466907   0.0  0.535557  0.490966   \n",
       "1     0.674876  0.313608  0.280145  ...  0.418187   1.0  0.635475  0.157254   \n",
       "2     0.538187  0.284743  0.386870  ...  0.407967   1.0  0.589100  0.679930   \n",
       "3     0.711540  0.427390  0.073868  ...  0.371300   0.0  0.498661  0.593501   \n",
       "4     0.608201  0.277692  0.214240  ...  0.430974   1.0  0.397525  0.039843   \n",
       "...        ...       ...       ...  ...       ...   ...       ...       ...   \n",
       "1915  0.792422  0.662862  0.146113  ...  0.280971   1.0  0.254034  0.063396   \n",
       "1916  0.637243  0.314642  0.136442  ...  0.389752   0.0  0.760976  0.270353   \n",
       "1917  0.624641  0.367987  0.292672  ...  0.322887   1.0  0.645095  0.068958   \n",
       "1918  0.672477  0.596553  0.303114  ...  0.302141   1.0  0.547257  0.201306   \n",
       "1919  0.596630  0.365489  0.304782  ...  0.453735   1.0  0.674624  0.100138   \n",
       "\n",
       "          AU25      AU26      AU28      AU43  \\\n",
       "0     0.935579  0.121045  0.333033  0.121158   \n",
       "1     0.975519  0.468108  0.318228  0.165630   \n",
       "2     0.900595  0.114604  0.304304  0.082065   \n",
       "3     0.636757  0.147229  0.222992  0.079755   \n",
       "4     0.996547  0.306116  0.034934  0.117396   \n",
       "...        ...       ...       ...       ...   \n",
       "1915  0.983158  0.445436  0.105169  0.638492   \n",
       "1916  0.974202  0.458458  0.115001  0.273430   \n",
       "1917  0.900835  0.509297  0.077086  0.406576   \n",
       "1918  0.998685  0.470552  0.115043  0.567455   \n",
       "1919  0.986878  0.398863  0.058895  0.681527   \n",
       "\n",
       "                               img_name  level  \n",
       "0     ./image/P19/P19_1659487998833.png      1  \n",
       "1     ./image/P19/P19_1659020214976.png      1  \n",
       "2     ./image/P19/P19_1659075503842.png      1  \n",
       "3     ./image/P19/P19_1659021205080.png      1  \n",
       "4     ./image/P19/P19_1659355704725.png      1  \n",
       "...                                 ...    ...  \n",
       "1915  ./image/P14/P14_1659279866187.png      0  \n",
       "1916  ./image/P14/P14_1659456638127.png      0  \n",
       "1917  ./image/P14/P14_1659456537639.png      0  \n",
       "1918  ./image/P14/P14_1659510069849.png      0  \n",
       "1919  ./image/P14/P14_1658932945727.png      0  \n",
       "\n",
       "[34364 rows x 29 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data=[]\n",
    "for i in contestants:\n",
    "    all_data.append(pd.read_csv(f\"{base_path}/{i}\").dropna())\n",
    "all_df_data=pd.concat(all_data,axis=0)\n",
    "all_df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "emotion_features = all_df_data.columns[:-2]#7\n",
    "df_melted = pd.melt(all_df_data,\n",
    "                    id_vars=['level'],           # keep the level column as identifier\n",
    "                    value_vars=emotion_features, # the emotion feature columns to melt\n",
    "                    var_name='emotion',          # new column for emotion names\n",
    "                    value_name='value')          # new column for the corresponding values\n",
    "\n",
    "# If your level values are continuous but you want to treat them as categories, you can convert them to strings:\n",
    "df_melted['level'] = df_melted['level'].astype(str)\n",
    "\n",
    "# Step 3: Plot using Seaborn\n",
    "plt.figure(figsize=(10, 15))\n",
    "sns.boxplot(y='emotion', x='value', hue='level', data=df_melted,showmeans=True,showfliers=False)\n",
    "# plt.title(\"Emotion Feature Distributions by Level\")\n",
    "plt.xlabel(\"Value\")\n",
    "plt.ylabel(\"Emotion/AU\") \n",
    "plt.legend(title=\"Level\")\n",
    "# plt.show()\n",
    "# plt.draw()\n",
    "plt.savefig('./image_paper/all_volunteer.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:47:21.222130Z",
     "iopub.status.busy": "2025-02-02T19:47:21.221776Z",
     "iopub.status.idle": "2025-02-02T19:47:35.119490Z",
     "shell.execute_reply": "2025-02-02T19:47:35.118444Z",
     "shell.execute_reply.started": "2025-02-02T19:47:21.222101Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        34\n",
      "           1       0.98      0.91      0.95        47\n",
      "\n",
      "    accuracy                           0.94        81\n",
      "   macro avg       0.93      0.94      0.94        81\n",
      "weighted avg       0.94      0.94      0.94        81\n",
      "\n",
      "XGB  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.91      0.72        34\n",
      "           1       0.90      0.55      0.68        47\n",
      "\n",
      "    accuracy                           0.70        81\n",
      "   macro avg       0.75      0.73      0.70        81\n",
      "weighted avg       0.77      0.70      0.70        81\n",
      "\n",
      "LR  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.94      0.88        34\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.89        81\n",
      "   macro avg       0.89      0.90      0.89        81\n",
      "weighted avg       0.90      0.89      0.89        81\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        63\n",
      "           1       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.89        96\n",
      "   macro avg       0.88      0.86      0.87        96\n",
      "weighted avg       0.88      0.89      0.88        96\n",
      "\n",
      "XGB  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        63\n",
      "           1       0.91      0.97      0.94        33\n",
      "\n",
      "    accuracy                           0.96        96\n",
      "   macro avg       0.95      0.96      0.95        96\n",
      "weighted avg       0.96      0.96      0.96        96\n",
      "\n",
      "LR  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91        63\n",
      "           1       0.87      0.79      0.83        33\n",
      "\n",
      "    accuracy                           0.89        96\n",
      "   macro avg       0.88      0.86      0.87        96\n",
      "weighted avg       0.88      0.89      0.88        96\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        18\n",
      "           1       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.97        37\n",
      "   macro avg       0.97      0.97      0.97        37\n",
      "weighted avg       0.97      0.97      0.97        37\n",
      "\n",
      "XGB  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        37\n",
      "   macro avg       1.00      1.00      1.00        37\n",
      "weighted avg       1.00      1.00      1.00        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        37\n",
      "   macro avg       1.00      1.00      1.00        37\n",
      "weighted avg       1.00      1.00      1.00        37\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        51\n",
      "           1       0.98      1.00      0.99        59\n",
      "\n",
      "    accuracy                           0.99       110\n",
      "   macro avg       0.99      0.99      0.99       110\n",
      "weighted avg       0.99      0.99      0.99       110\n",
      "\n",
      "XGB  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        59\n",
      "\n",
      "    accuracy                           1.00       110\n",
      "   macro avg       1.00      1.00      1.00       110\n",
      "weighted avg       1.00      1.00      1.00       110\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        51\n",
      "           1       0.91      0.90      0.91        59\n",
      "\n",
      "    accuracy                           0.90       110\n",
      "   macro avg       0.90      0.90      0.90       110\n",
      "weighted avg       0.90      0.90      0.90       110\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92        39\n",
      "           1       0.93      0.93      0.93        42\n",
      "\n",
      "    accuracy                           0.93        81\n",
      "   macro avg       0.93      0.93      0.93        81\n",
      "weighted avg       0.93      0.93      0.93        81\n",
      "\n",
      "XGB  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.87      0.75        39\n",
      "           1       0.83      0.57      0.68        42\n",
      "\n",
      "    accuracy                           0.72        81\n",
      "   macro avg       0.74      0.72      0.71        81\n",
      "weighted avg       0.74      0.72      0.71        81\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.88        39\n",
      "           1       0.90      0.86      0.88        42\n",
      "\n",
      "    accuracy                           0.88        81\n",
      "   macro avg       0.88      0.88      0.88        81\n",
      "weighted avg       0.88      0.88      0.88        81\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        11\n",
      "           1       1.00      0.91      0.96        35\n",
      "\n",
      "    accuracy                           0.93        46\n",
      "   macro avg       0.89      0.96      0.92        46\n",
      "weighted avg       0.95      0.93      0.94        46\n",
      "\n",
      "XGB  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.73      0.59        11\n",
      "           1       0.90      0.77      0.83        35\n",
      "\n",
      "    accuracy                           0.76        46\n",
      "   macro avg       0.70      0.75      0.71        46\n",
      "weighted avg       0.80      0.76      0.77        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      1.00      0.69        11\n",
      "           1       1.00      0.71      0.83        35\n",
      "\n",
      "    accuracy                           0.78        46\n",
      "   macro avg       0.76      0.86      0.76        46\n",
      "weighted avg       0.89      0.78      0.80        46\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n",
      "XGB  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.97      0.91        37\n",
      "           1       0.93      0.70      0.80        20\n",
      "\n",
      "    accuracy                           0.88        57\n",
      "   macro avg       0.90      0.84      0.86        57\n",
      "weighted avg       0.88      0.88      0.87        57\n",
      "\n",
      "XGB  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        37\n",
      "           1       0.95      0.90      0.92        20\n",
      "\n",
      "    accuracy                           0.95        57\n",
      "   macro avg       0.95      0.94      0.94        57\n",
      "weighted avg       0.95      0.95      0.95        57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.92      0.83        37\n",
      "           1       0.75      0.45      0.56        20\n",
      "\n",
      "    accuracy                           0.75        57\n",
      "   macro avg       0.75      0.68      0.70        57\n",
      "weighted avg       0.75      0.75      0.74        57\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        81\n",
      "           1       0.97      1.00      0.98        58\n",
      "\n",
      "    accuracy                           0.99       139\n",
      "   macro avg       0.98      0.99      0.99       139\n",
      "weighted avg       0.99      0.99      0.99       139\n",
      "\n",
      "XGB  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        58\n",
      "\n",
      "    accuracy                           1.00       139\n",
      "   macro avg       1.00      1.00      1.00       139\n",
      "weighted avg       1.00      1.00      1.00       139\n",
      "\n",
      "LR  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.95      0.97        81\n",
      "           1       0.93      0.98      0.96        58\n",
      "\n",
      "    accuracy                           0.96       139\n",
      "   macro avg       0.96      0.97      0.96       139\n",
      "weighted avg       0.97      0.96      0.96       139\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98        50\n",
      "           1       0.75      0.75      0.75         4\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.86      0.86      0.86        54\n",
      "weighted avg       0.96      0.96      0.96        54\n",
      "\n",
      "XGB  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98        50\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.96        54\n",
      "   macro avg       0.83      0.98      0.89        54\n",
      "weighted avg       0.98      0.96      0.97        54\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.93      0.83        45\n",
      "           1       0.92      0.70      0.80        47\n",
      "\n",
      "    accuracy                           0.82        92\n",
      "   macro avg       0.83      0.82      0.81        92\n",
      "weighted avg       0.84      0.82      0.81        92\n",
      "\n",
      "XGB  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98        45\n",
      "           1       1.00      0.96      0.98        47\n",
      "\n",
      "    accuracy                           0.98        92\n",
      "   macro avg       0.98      0.98      0.98        92\n",
      "weighted avg       0.98      0.98      0.98        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.93      0.85        45\n",
      "           1       0.92      0.74      0.82        47\n",
      "\n",
      "    accuracy                           0.84        92\n",
      "   macro avg       0.85      0.84      0.84        92\n",
      "weighted avg       0.85      0.84      0.84        92\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        38\n",
      "           1       0.94      0.94      0.94        18\n",
      "\n",
      "    accuracy                           0.96        56\n",
      "   macro avg       0.96      0.96      0.96        56\n",
      "weighted avg       0.96      0.96      0.96        56\n",
      "\n",
      "XGB  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        38\n",
      "           1       1.00      0.89      0.94        18\n",
      "\n",
      "    accuracy                           0.96        56\n",
      "   macro avg       0.97      0.94      0.96        56\n",
      "weighted avg       0.97      0.96      0.96        56\n",
      "\n",
      "LR  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        38\n",
      "           1       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.98        56\n",
      "   macro avg       0.99      0.97      0.98        56\n",
      "weighted avg       0.98      0.98      0.98        56\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.93      1.00      0.96        25\n",
      "\n",
      "    accuracy                           0.93        29\n",
      "   macro avg       0.96      0.75      0.81        29\n",
      "weighted avg       0.94      0.93      0.92        29\n",
      "\n",
      "XGB  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.75      0.86         4\n",
      "           1       0.96      1.00      0.98        25\n",
      "\n",
      "    accuracy                           0.97        29\n",
      "   macro avg       0.98      0.88      0.92        29\n",
      "weighted avg       0.97      0.97      0.96        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         4\n",
      "           1       0.93      1.00      0.96        25\n",
      "\n",
      "    accuracy                           0.93        29\n",
      "   macro avg       0.96      0.75      0.81        29\n",
      "weighted avg       0.94      0.93      0.92        29\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       1.00      0.79      0.88        14\n",
      "\n",
      "    accuracy                           0.91        35\n",
      "   macro avg       0.94      0.89      0.91        35\n",
      "weighted avg       0.93      0.91      0.91        35\n",
      "\n",
      "XGB  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        21\n",
      "           1       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.97        35\n",
      "   macro avg       0.98      0.96      0.97        35\n",
      "weighted avg       0.97      0.97      0.97        35\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "XGB  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       0.96      0.96      0.96        28\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.92      0.92      0.92        36\n",
      "weighted avg       0.94      0.94      0.94        36\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.90      0.74        39\n",
      "           1       0.98      0.91      0.94       223\n",
      "\n",
      "    accuracy                           0.90       262\n",
      "   macro avg       0.80      0.90      0.84       262\n",
      "weighted avg       0.93      0.90      0.91       262\n",
      "\n",
      "XGB  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.95      0.84        39\n",
      "           1       0.99      0.95      0.97       223\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.87      0.95      0.90       262\n",
      "weighted avg       0.96      0.95      0.95       262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.90      0.64        39\n",
      "           1       0.98      0.84      0.91       223\n",
      "\n",
      "    accuracy                           0.85       262\n",
      "   macro avg       0.74      0.87      0.77       262\n",
      "weighted avg       0.91      0.85      0.87       262\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.83      0.57        23\n",
      "           1       0.98      0.90      0.94       243\n",
      "\n",
      "    accuracy                           0.89       266\n",
      "   macro avg       0.71      0.86      0.75       266\n",
      "weighted avg       0.93      0.89      0.91       266\n",
      "\n",
      "XGB  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        23\n",
      "           1       1.00      0.93      0.97       243\n",
      "\n",
      "    accuracy                           0.94       266\n",
      "   macro avg       0.79      0.97      0.85       266\n",
      "weighted avg       0.96      0.94      0.95       266\n",
      "\n",
      "LR  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.83      0.34        23\n",
      "           1       0.98      0.71      0.82       243\n",
      "\n",
      "    accuracy                           0.72       266\n",
      "   macro avg       0.60      0.77      0.58       266\n",
      "weighted avg       0.91      0.72      0.78       266\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.92      0.72        36\n",
      "           1       0.99      0.90      0.94       222\n",
      "\n",
      "    accuracy                           0.90       258\n",
      "   macro avg       0.79      0.91      0.83       258\n",
      "weighted avg       0.93      0.90      0.91       258\n",
      "\n",
      "XGB  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        36\n",
      "           1       1.00      0.95      0.97       222\n",
      "\n",
      "    accuracy                           0.95       258\n",
      "   macro avg       0.88      0.97      0.91       258\n",
      "weighted avg       0.97      0.95      0.96       258\n",
      "\n",
      "LR  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.81      0.47        36\n",
      "           1       0.96      0.74      0.83       222\n",
      "\n",
      "    accuracy                           0.75       258\n",
      "   macro avg       0.65      0.77      0.65       258\n",
      "weighted avg       0.87      0.75      0.78       258\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.50      0.12         2\n",
      "           1       0.98      0.76      0.86        55\n",
      "\n",
      "    accuracy                           0.75        57\n",
      "   macro avg       0.52      0.63      0.49        57\n",
      "weighted avg       0.94      0.75      0.83        57\n",
      "\n",
      "XGB  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.50      0.22         2\n",
      "           1       0.98      0.89      0.93        55\n",
      "\n",
      "    accuracy                           0.88        57\n",
      "   macro avg       0.56      0.70      0.58        57\n",
      "weighted avg       0.95      0.88      0.91        57\n",
      "\n",
      "LR  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.50      0.14         2\n",
      "           1       0.98      0.80      0.88        55\n",
      "\n",
      "    accuracy                           0.79        57\n",
      "   macro avg       0.53      0.65      0.51        57\n",
      "weighted avg       0.95      0.79      0.85        57\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.84      0.67        37\n",
      "           1       0.98      0.92      0.95       297\n",
      "\n",
      "    accuracy                           0.91       334\n",
      "   macro avg       0.77      0.88      0.81       334\n",
      "weighted avg       0.93      0.91      0.92       334\n",
      "\n",
      "XGB  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        37\n",
      "           1       1.00      1.00      1.00       297\n",
      "\n",
      "    accuracy                           1.00       334\n",
      "   macro avg       0.99      1.00      0.99       334\n",
      "weighted avg       1.00      1.00      1.00       334\n",
      "\n",
      "LR  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.92      0.64        37\n",
      "           1       0.99      0.88      0.93       297\n",
      "\n",
      "    accuracy                           0.88       334\n",
      "   macro avg       0.74      0.90      0.78       334\n",
      "weighted avg       0.93      0.88      0.90       334\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      1.00      0.31         8\n",
      "           1       1.00      0.88      0.94       287\n",
      "\n",
      "    accuracy                           0.88       295\n",
      "   macro avg       0.59      0.94      0.62       295\n",
      "weighted avg       0.98      0.88      0.92       295\n",
      "\n",
      "XGB  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94         8\n",
      "           1       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       295\n",
      "   macro avg       0.94      1.00      0.97       295\n",
      "weighted avg       1.00      1.00      1.00       295\n",
      "\n",
      "LR  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      1.00      0.24         8\n",
      "           1       1.00      0.82      0.90       287\n",
      "\n",
      "    accuracy                           0.82       295\n",
      "   macro avg       0.57      0.91      0.57       295\n",
      "weighted avg       0.98      0.82      0.88       295\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.87      0.47        30\n",
      "           1       0.98      0.80      0.88       266\n",
      "\n",
      "    accuracy                           0.80       296\n",
      "   macro avg       0.65      0.83      0.68       296\n",
      "weighted avg       0.91      0.80      0.84       296\n",
      "\n",
      "XGB  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72        30\n",
      "           1       1.00      0.91      0.95       266\n",
      "\n",
      "    accuracy                           0.92       296\n",
      "   macro avg       0.78      0.96      0.84       296\n",
      "weighted avg       0.96      0.92      0.93       296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      0.83      0.41        30\n",
      "           1       0.98      0.75      0.85       266\n",
      "\n",
      "    accuracy                           0.76       296\n",
      "   macro avg       0.63      0.79      0.63       296\n",
      "weighted avg       0.90      0.76      0.81       296\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        23\n",
      "           1       0.98      0.99      0.99       104\n",
      "\n",
      "    accuracy                           0.98       127\n",
      "   macro avg       0.97      0.95      0.96       127\n",
      "weighted avg       0.98      0.98      0.98       127\n",
      "\n",
      "XGB  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00       104\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        23\n",
      "           1       0.98      0.98      0.98       104\n",
      "\n",
      "    accuracy                           0.97       127\n",
      "   macro avg       0.95      0.95      0.95       127\n",
      "weighted avg       0.97      0.97      0.97       127\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.98      0.83        53\n",
      "           1       0.99      0.88      0.93       166\n",
      "\n",
      "    accuracy                           0.90       219\n",
      "   macro avg       0.86      0.93      0.88       219\n",
      "weighted avg       0.93      0.90      0.91       219\n",
      "\n",
      "XGB  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        53\n",
      "           1       1.00      0.99      1.00       166\n",
      "\n",
      "    accuracy                           1.00       219\n",
      "   macro avg       0.99      1.00      0.99       219\n",
      "weighted avg       1.00      1.00      1.00       219\n",
      "\n",
      "LR  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.96      0.80        53\n",
      "           1       0.99      0.86      0.92       166\n",
      "\n",
      "    accuracy                           0.88       219\n",
      "   macro avg       0.83      0.91      0.86       219\n",
      "weighted avg       0.91      0.88      0.89       219\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59        19\n",
      "           1       0.73      0.76      0.75        29\n",
      "\n",
      "    accuracy                           0.69        48\n",
      "   macro avg       0.67      0.67      0.67        48\n",
      "weighted avg       0.68      0.69      0.69        48\n",
      "\n",
      "XGB  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73        19\n",
      "           1       0.87      0.69      0.77        29\n",
      "\n",
      "    accuracy                           0.75        48\n",
      "   macro avg       0.75      0.77      0.75        48\n",
      "weighted avg       0.78      0.75      0.75        48\n",
      "\n",
      "LR  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.26      0.30        19\n",
      "           1       0.59      0.69      0.63        29\n",
      "\n",
      "    accuracy                           0.52        48\n",
      "   macro avg       0.47      0.48      0.47        48\n",
      "weighted avg       0.50      0.52      0.50        48\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      1.00      0.49        10\n",
      "           1       1.00      0.93      0.97       311\n",
      "\n",
      "    accuracy                           0.93       321\n",
      "   macro avg       0.66      0.97      0.73       321\n",
      "weighted avg       0.98      0.93      0.95       321\n",
      "\n",
      "XGB  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        10\n",
      "           1       1.00      1.00      1.00       311\n",
      "\n",
      "    accuracy                           1.00       321\n",
      "   macro avg       0.95      1.00      0.98       321\n",
      "weighted avg       1.00      1.00      1.00       321\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.90      0.34        10\n",
      "           1       1.00      0.89      0.94       311\n",
      "\n",
      "    accuracy                           0.89       321\n",
      "   macro avg       0.60      0.90      0.64       321\n",
      "weighted avg       0.97      0.89      0.92       321\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        15\n",
      "           1       1.00      0.96      0.98       199\n",
      "\n",
      "    accuracy                           0.97       214\n",
      "   macro avg       0.84      0.98      0.90       214\n",
      "weighted avg       0.98      0.97      0.97       214\n",
      "\n",
      "XGB  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00       199\n",
      "\n",
      "    accuracy                           1.00       214\n",
      "   macro avg       1.00      1.00      1.00       214\n",
      "weighted avg       1.00      1.00      1.00       214\n",
      "\n",
      "LR  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67        15\n",
      "           1       1.00      0.92      0.96       199\n",
      "\n",
      "    accuracy                           0.93       214\n",
      "   macro avg       0.75      0.96      0.81       214\n",
      "weighted avg       0.96      0.93      0.94       214\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.57      0.24         7\n",
      "           1       0.96      0.77      0.85        95\n",
      "\n",
      "    accuracy                           0.75       102\n",
      "   macro avg       0.56      0.67      0.55       102\n",
      "weighted avg       0.91      0.75      0.81       102\n",
      "\n",
      "XGB  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78         7\n",
      "           1       1.00      0.96      0.98        95\n",
      "\n",
      "    accuracy                           0.96       102\n",
      "   macro avg       0.82      0.98      0.88       102\n",
      "weighted avg       0.98      0.96      0.96       102\n",
      "\n",
      "LR  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.57      0.18         7\n",
      "           1       0.95      0.64      0.77        95\n",
      "\n",
      "    accuracy                           0.64       102\n",
      "   macro avg       0.53      0.61      0.47       102\n",
      "weighted avg       0.89      0.64      0.73       102\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      1.00      0.44         7\n",
      "           1       1.00      0.89      0.94       164\n",
      "\n",
      "    accuracy                           0.89       171\n",
      "   macro avg       0.64      0.95      0.69       171\n",
      "weighted avg       0.97      0.89      0.92       171\n",
      "\n",
      "XGB  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00       164\n",
      "\n",
      "    accuracy                           1.00       171\n",
      "   macro avg       1.00      1.00      1.00       171\n",
      "weighted avg       1.00      1.00      1.00       171\n",
      "\n",
      "LR  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40         7\n",
      "           1       1.00      0.87      0.93       164\n",
      "\n",
      "    accuracy                           0.88       171\n",
      "   macro avg       0.62      0.94      0.67       171\n",
      "weighted avg       0.97      0.88      0.91       171\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.92      0.29        13\n",
      "           1       1.00      0.79      0.88       276\n",
      "\n",
      "    accuracy                           0.80       289\n",
      "   macro avg       0.58      0.86      0.59       289\n",
      "weighted avg       0.96      0.80      0.86       289\n",
      "\n",
      "XGB  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00       276\n",
      "\n",
      "    accuracy                           1.00       289\n",
      "   macro avg       1.00      1.00      1.00       289\n",
      "weighted avg       1.00      1.00      1.00       289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.92      0.23        13\n",
      "           1       0.99      0.71      0.83       276\n",
      "\n",
      "    accuracy                           0.72       289\n",
      "   macro avg       0.56      0.82      0.53       289\n",
      "weighted avg       0.96      0.72      0.80       289\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.94      0.73        35\n",
      "           1       0.99      0.87      0.92       177\n",
      "\n",
      "    accuracy                           0.88       212\n",
      "   macro avg       0.79      0.91      0.83       212\n",
      "weighted avg       0.92      0.88      0.89       212\n",
      "\n",
      "XGB  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       212\n",
      "   macro avg       1.00      1.00      1.00       212\n",
      "weighted avg       1.00      1.00      1.00       212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.83      0.64        35\n",
      "           1       0.96      0.85      0.90       177\n",
      "\n",
      "    accuracy                           0.84       212\n",
      "   macro avg       0.74      0.84      0.77       212\n",
      "weighted avg       0.89      0.84      0.86       212\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.88      0.48        25\n",
      "           1       0.98      0.79      0.88       213\n",
      "\n",
      "    accuracy                           0.80       238\n",
      "   macro avg       0.66      0.84      0.68       238\n",
      "weighted avg       0.91      0.80      0.84       238\n",
      "\n",
      "XGB  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        25\n",
      "           1       1.00      0.99      1.00       213\n",
      "\n",
      "    accuracy                           0.99       238\n",
      "   macro avg       0.96      1.00      0.98       238\n",
      "weighted avg       0.99      0.99      0.99       238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.96      0.55        25\n",
      "           1       0.99      0.82      0.90       213\n",
      "\n",
      "    accuracy                           0.83       238\n",
      "   macro avg       0.69      0.89      0.72       238\n",
      "weighted avg       0.93      0.83      0.86       238\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.79      0.47        14\n",
      "           1       0.93      0.63      0.75        59\n",
      "\n",
      "    accuracy                           0.66        73\n",
      "   macro avg       0.63      0.71      0.61        73\n",
      "weighted avg       0.81      0.66      0.69        73\n",
      "\n",
      "XGB  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.79      0.56        14\n",
      "           1       0.94      0.76      0.84        59\n",
      "\n",
      "    accuracy                           0.77        73\n",
      "   macro avg       0.69      0.77      0.70        73\n",
      "weighted avg       0.84      0.77      0.79        73\n",
      "\n",
      "LR  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.86      0.53        14\n",
      "           1       0.95      0.68      0.79        59\n",
      "\n",
      "    accuracy                           0.71        73\n",
      "   macro avg       0.67      0.77      0.66        73\n",
      "weighted avg       0.84      0.71      0.74        73\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.88      0.44        34\n",
      "           1       0.94      0.44      0.60       131\n",
      "\n",
      "    accuracy                           0.53       165\n",
      "   macro avg       0.61      0.66      0.52       165\n",
      "weighted avg       0.80      0.53      0.57       165\n",
      "\n",
      "XGB  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.91      0.41        34\n",
      "           1       0.94      0.34      0.49       131\n",
      "\n",
      "    accuracy                           0.45       165\n",
      "   macro avg       0.60      0.62      0.45       165\n",
      "weighted avg       0.80      0.45      0.48       165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.94      0.41        34\n",
      "           1       0.95      0.31      0.47       131\n",
      "\n",
      "    accuracy                           0.44       165\n",
      "   macro avg       0.61      0.63      0.44       165\n",
      "weighted avg       0.81      0.44      0.46       165\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.88      0.80        95\n",
      "           1       0.89      0.74      0.81       115\n",
      "\n",
      "    accuracy                           0.80       210\n",
      "   macro avg       0.81      0.81      0.80       210\n",
      "weighted avg       0.82      0.80      0.80       210\n",
      "\n",
      "XGB  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.98      0.89        95\n",
      "           1       0.98      0.83      0.90       115\n",
      "\n",
      "    accuracy                           0.90       210\n",
      "   macro avg       0.90      0.90      0.90       210\n",
      "weighted avg       0.91      0.90      0.90       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75        95\n",
      "           1       0.88      0.58      0.70       115\n",
      "\n",
      "    accuracy                           0.73       210\n",
      "   macro avg       0.76      0.74      0.73       210\n",
      "weighted avg       0.77      0.73      0.72       210\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        58\n",
      "           1       1.00      0.81      0.90       145\n",
      "\n",
      "    accuracy                           0.87       203\n",
      "   macro avg       0.84      0.91      0.85       203\n",
      "weighted avg       0.91      0.87      0.87       203\n",
      "\n",
      "XGB  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        58\n",
      "           1       1.00      0.99      0.99       145\n",
      "\n",
      "    accuracy                           0.99       203\n",
      "   macro avg       0.98      0.99      0.99       203\n",
      "weighted avg       0.99      0.99      0.99       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75        58\n",
      "           1       1.00      0.74      0.85       145\n",
      "\n",
      "    accuracy                           0.81       203\n",
      "   macro avg       0.80      0.87      0.80       203\n",
      "weighted avg       0.89      0.81      0.82       203\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.99      0.80        77\n",
      "           1       0.99      0.72      0.83       129\n",
      "\n",
      "    accuracy                           0.82       206\n",
      "   macro avg       0.83      0.85      0.82       206\n",
      "weighted avg       0.87      0.82      0.82       206\n",
      "\n",
      "XGB  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        77\n",
      "           1       0.99      0.99      0.99       129\n",
      "\n",
      "    accuracy                           0.99       206\n",
      "   macro avg       0.99      0.99      0.99       206\n",
      "weighted avg       0.99      0.99      0.99       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.76        77\n",
      "           1       0.98      0.64      0.78       129\n",
      "\n",
      "    accuracy                           0.77       206\n",
      "   macro avg       0.80      0.81      0.77       206\n",
      "weighted avg       0.84      0.77      0.77       206\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        66\n",
      "           1       1.00      0.83      0.91       142\n",
      "\n",
      "    accuracy                           0.88       208\n",
      "   macro avg       0.87      0.92      0.88       208\n",
      "weighted avg       0.92      0.88      0.89       208\n",
      "\n",
      "XGB  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        66\n",
      "           1       1.00      1.00      1.00       142\n",
      "\n",
      "    accuracy                           1.00       208\n",
      "   macro avg       1.00      1.00      1.00       208\n",
      "weighted avg       1.00      1.00      1.00       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        66\n",
      "           1       1.00      0.72      0.84       142\n",
      "\n",
      "    accuracy                           0.81       208\n",
      "   macro avg       0.81      0.86      0.80       208\n",
      "weighted avg       0.88      0.81      0.81       208\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.95      0.86        55\n",
      "           1       0.98      0.91      0.94       151\n",
      "\n",
      "    accuracy                           0.92       206\n",
      "   macro avg       0.88      0.93      0.90       206\n",
      "weighted avg       0.93      0.92      0.92       206\n",
      "\n",
      "XGB  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        55\n",
      "           1       1.00      1.00      1.00       151\n",
      "\n",
      "    accuracy                           1.00       206\n",
      "   macro avg       1.00      1.00      1.00       206\n",
      "weighted avg       1.00      1.00      1.00       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.98      0.85        55\n",
      "           1       0.99      0.88      0.93       151\n",
      "\n",
      "    accuracy                           0.91       206\n",
      "   macro avg       0.87      0.93      0.89       206\n",
      "weighted avg       0.93      0.91      0.91       206\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91        68\n",
      "           1       0.98      0.95      0.96       182\n",
      "\n",
      "    accuracy                           0.95       250\n",
      "   macro avg       0.92      0.95      0.94       250\n",
      "weighted avg       0.95      0.95      0.95       250\n",
      "\n",
      "XGB  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        68\n",
      "           1       1.00      1.00      1.00       182\n",
      "\n",
      "    accuracy                           1.00       250\n",
      "   macro avg       1.00      1.00      1.00       250\n",
      "weighted avg       1.00      1.00      1.00       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.91      0.78        68\n",
      "           1       0.96      0.84      0.90       182\n",
      "\n",
      "    accuracy                           0.86       250\n",
      "   macro avg       0.82      0.88      0.84       250\n",
      "weighted avg       0.89      0.86      0.87       250\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.97      0.86        75\n",
      "           1       0.99      0.88      0.93       177\n",
      "\n",
      "    accuracy                           0.91       252\n",
      "   macro avg       0.88      0.93      0.90       252\n",
      "weighted avg       0.92      0.91      0.91       252\n",
      "\n",
      "XGB  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        75\n",
      "           1       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       252\n",
      "   macro avg       1.00      1.00      1.00       252\n",
      "weighted avg       1.00      1.00      1.00       252\n",
      "\n",
      "LR  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85        75\n",
      "           1       0.99      0.85      0.92       177\n",
      "\n",
      "    accuracy                           0.89       252\n",
      "   macro avg       0.87      0.92      0.88       252\n",
      "weighted avg       0.92      0.89      0.90       252\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.93      0.86        81\n",
      "           1       0.87      0.69      0.77        58\n",
      "\n",
      "    accuracy                           0.83       139\n",
      "   macro avg       0.84      0.81      0.82       139\n",
      "weighted avg       0.83      0.83      0.82       139\n",
      "\n",
      "XGB  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        81\n",
      "           1       1.00      0.90      0.95        58\n",
      "\n",
      "    accuracy                           0.96       139\n",
      "   macro avg       0.97      0.95      0.95       139\n",
      "weighted avg       0.96      0.96      0.96       139\n",
      "\n",
      "LR  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.94      0.89        81\n",
      "           1       0.90      0.76      0.82        58\n",
      "\n",
      "    accuracy                           0.86       139\n",
      "   macro avg       0.87      0.85      0.86       139\n",
      "weighted avg       0.87      0.86      0.86       139\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.90      0.57        21\n",
      "           1       0.97      0.67      0.79        83\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.69      0.79      0.68       104\n",
      "weighted avg       0.85      0.72      0.75       104\n",
      "\n",
      "XGB  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.71      0.43        21\n",
      "           1       0.89      0.59      0.71        83\n",
      "\n",
      "    accuracy                           0.62       104\n",
      "   macro avg       0.60      0.65      0.57       104\n",
      "weighted avg       0.77      0.62      0.65       104\n",
      "\n",
      "LR  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.86      0.55        21\n",
      "           1       0.95      0.69      0.80        83\n",
      "\n",
      "    accuracy                           0.72       104\n",
      "   macro avg       0.68      0.77      0.68       104\n",
      "weighted avg       0.84      0.72      0.75       104\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.95      0.62        39\n",
      "           1       0.97      0.62      0.76       113\n",
      "\n",
      "    accuracy                           0.70       152\n",
      "   macro avg       0.72      0.78      0.69       152\n",
      "weighted avg       0.84      0.70      0.72       152\n",
      "\n",
      "XGB  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        39\n",
      "           1       1.00      0.96      0.98       113\n",
      "\n",
      "    accuracy                           0.97       152\n",
      "   macro avg       0.95      0.98      0.97       152\n",
      "weighted avg       0.98      0.97      0.97       152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.90      0.64        39\n",
      "           1       0.95      0.68      0.79       113\n",
      "\n",
      "    accuracy                           0.74       152\n",
      "   macro avg       0.72      0.79      0.72       152\n",
      "weighted avg       0.83      0.74      0.75       152\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.25      0.14         4\n",
      "           1       0.94      0.85      0.89        59\n",
      "\n",
      "    accuracy                           0.81        63\n",
      "   macro avg       0.52      0.55      0.52        63\n",
      "weighted avg       0.89      0.81      0.85        63\n",
      "\n",
      "XGB  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.50      0.19         4\n",
      "           1       0.96      0.75      0.84        59\n",
      "\n",
      "    accuracy                           0.73        63\n",
      "   macro avg       0.54      0.62      0.51        63\n",
      "weighted avg       0.90      0.73      0.80        63\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.50      0.36         4\n",
      "           1       0.96      0.92      0.94        59\n",
      "\n",
      "    accuracy                           0.89        63\n",
      "   macro avg       0.62      0.71      0.65        63\n",
      "weighted avg       0.92      0.89      0.90        63\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.91      0.75        45\n",
      "           1       0.90      0.60      0.72        58\n",
      "\n",
      "    accuracy                           0.74       103\n",
      "   macro avg       0.77      0.76      0.74       103\n",
      "weighted avg       0.79      0.74      0.74       103\n",
      "\n",
      "XGB  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.84        45\n",
      "           1       0.98      0.72      0.83        58\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.86      0.85      0.83       103\n",
      "weighted avg       0.87      0.83      0.83       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.89      0.79        45\n",
      "           1       0.89      0.72      0.80        58\n",
      "\n",
      "    accuracy                           0.80       103\n",
      "   macro avg       0.80      0.81      0.80       103\n",
      "weighted avg       0.82      0.80      0.80       103\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        63\n",
      "           1       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.94        78\n",
      "   macro avg       0.91      0.88      0.89        78\n",
      "weighted avg       0.93      0.94      0.94        78\n",
      "\n",
      "XGB  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        63\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        78\n",
      "   macro avg       1.00      1.00      1.00        78\n",
      "weighted avg       1.00      1.00      1.00        78\n",
      "\n",
      "LR  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        63\n",
      "           1       1.00      0.67      0.80        15\n",
      "\n",
      "    accuracy                           0.94        78\n",
      "   macro avg       0.96      0.83      0.88        78\n",
      "weighted avg       0.94      0.94      0.93        78\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        71\n",
      "           1       0.85      1.00      0.92        23\n",
      "\n",
      "    accuracy                           0.96        94\n",
      "   macro avg       0.93      0.97      0.95        94\n",
      "weighted avg       0.96      0.96      0.96        94\n",
      "\n",
      "XGB  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00        94\n",
      "   macro avg       1.00      1.00      1.00        94\n",
      "weighted avg       1.00      1.00      1.00        94\n",
      "\n",
      "LR  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        71\n",
      "           1       0.85      1.00      0.92        23\n",
      "\n",
      "    accuracy                           0.96        94\n",
      "   macro avg       0.93      0.97      0.95        94\n",
      "weighted avg       0.96      0.96      0.96        94\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        48\n",
      "           1       1.00      0.83      0.91       106\n",
      "\n",
      "    accuracy                           0.88       154\n",
      "   macro avg       0.86      0.92      0.87       154\n",
      "weighted avg       0.91      0.88      0.89       154\n",
      "\n",
      "XGB  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00       106\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n",
      "LR  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        48\n",
      "           1       1.00      0.89      0.94       106\n",
      "\n",
      "    accuracy                           0.92       154\n",
      "   macro avg       0.90      0.94      0.91       154\n",
      "weighted avg       0.94      0.92      0.92       154\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78        46\n",
      "           1       0.97      0.61      0.75        61\n",
      "\n",
      "    accuracy                           0.77       107\n",
      "   macro avg       0.81      0.79      0.77       107\n",
      "weighted avg       0.84      0.77      0.76       107\n",
      "\n",
      "XGB  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        46\n",
      "           1       1.00      0.98      0.99        61\n",
      "\n",
      "    accuracy                           0.99       107\n",
      "   macro avg       0.99      0.99      0.99       107\n",
      "weighted avg       0.99      0.99      0.99       107\n",
      "\n",
      "LR  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        46\n",
      "           1       1.00      0.64      0.78        61\n",
      "\n",
      "    accuracy                           0.79       107\n",
      "   macro avg       0.84      0.82      0.79       107\n",
      "weighted avg       0.86      0.79      0.79       107\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.95      0.90        38\n",
      "           1       0.94      0.83      0.88        35\n",
      "\n",
      "    accuracy                           0.89        73\n",
      "   macro avg       0.90      0.89      0.89        73\n",
      "weighted avg       0.89      0.89      0.89        73\n",
      "\n",
      "XGB  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        38\n",
      "           1       1.00      0.94      0.97        35\n",
      "\n",
      "    accuracy                           0.97        73\n",
      "   macro avg       0.97      0.97      0.97        73\n",
      "weighted avg       0.97      0.97      0.97        73\n",
      "\n",
      "LR  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.92      0.88        38\n",
      "           1       0.90      0.80      0.85        35\n",
      "\n",
      "    accuracy                           0.86        73\n",
      "   macro avg       0.87      0.86      0.86        73\n",
      "weighted avg       0.87      0.86      0.86        73\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.86      0.89        37\n",
      "           1       0.38      0.50      0.43         6\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.64      0.68      0.66        43\n",
      "weighted avg       0.84      0.81      0.82        43\n",
      "\n",
      "XGB  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94        37\n",
      "           1       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.91        43\n",
      "   macro avg       0.80      0.88      0.83        43\n",
      "weighted avg       0.92      0.91      0.91        43\n",
      "\n",
      "LR  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        37\n",
      "           1       0.33      0.33      0.33         6\n",
      "\n",
      "    accuracy                           0.81        43\n",
      "   macro avg       0.61      0.61      0.61        43\n",
      "weighted avg       0.81      0.81      0.81        43\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.97      0.89        34\n",
      "           1       0.96      0.77      0.86        31\n",
      "\n",
      "    accuracy                           0.88        65\n",
      "   macro avg       0.89      0.87      0.87        65\n",
      "weighted avg       0.89      0.88      0.88        65\n",
      "\n",
      "XGB  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00        65\n",
      "   macro avg       1.00      1.00      1.00        65\n",
      "weighted avg       1.00      1.00      1.00        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.97      0.88        34\n",
      "           1       0.96      0.74      0.84        31\n",
      "\n",
      "    accuracy                           0.86        65\n",
      "   macro avg       0.88      0.86      0.86        65\n",
      "weighted avg       0.88      0.86      0.86        65\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        50\n",
      "           1       0.94      1.00      0.97        49\n",
      "\n",
      "    accuracy                           0.97        99\n",
      "   macro avg       0.97      0.97      0.97        99\n",
      "weighted avg       0.97      0.97      0.97        99\n",
      "\n",
      "XGB  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00        49\n",
      "\n",
      "    accuracy                           1.00        99\n",
      "   macro avg       1.00      1.00      1.00        99\n",
      "weighted avg       1.00      1.00      1.00        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.86      0.92        50\n",
      "           1       0.88      1.00      0.93        49\n",
      "\n",
      "    accuracy                           0.93        99\n",
      "   macro avg       0.94      0.93      0.93        99\n",
      "weighted avg       0.94      0.93      0.93        99\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.96      0.95        51\n",
      "           1       0.94      0.91      0.93        34\n",
      "\n",
      "    accuracy                           0.94        85\n",
      "   macro avg       0.94      0.94      0.94        85\n",
      "weighted avg       0.94      0.94      0.94        85\n",
      "\n",
      "XGB  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           1.00        85\n",
      "   macro avg       1.00      1.00      1.00        85\n",
      "weighted avg       1.00      1.00      1.00        85\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.86        51\n",
      "           1       0.81      0.74      0.77        34\n",
      "\n",
      "    accuracy                           0.82        85\n",
      "   macro avg       0.82      0.81      0.81        85\n",
      "weighted avg       0.82      0.82      0.82        85\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84         8\n",
      "           1       1.00      0.40      0.57         5\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.86      0.70      0.71        13\n",
      "weighted avg       0.83      0.77      0.74        13\n",
      "\n",
      "XGB  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82         8\n",
      "           1       0.75      0.60      0.67         5\n",
      "\n",
      "    accuracy                           0.77        13\n",
      "   macro avg       0.76      0.74      0.75        13\n",
      "weighted avg       0.77      0.77      0.76        13\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.95      0.97       311\n",
      "\n",
      "    accuracy                           0.95       312\n",
      "   macro avg       0.50      0.47      0.49       312\n",
      "weighted avg       0.99      0.95      0.97       312\n",
      "\n",
      "XGB  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      1.00      0.11         1\n",
      "           1       1.00      0.95      0.97       311\n",
      "\n",
      "    accuracy                           0.95       312\n",
      "   macro avg       0.53      0.97      0.54       312\n",
      "weighted avg       1.00      0.95      0.97       312\n",
      "\n",
      "LR  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.80      0.89       311\n",
      "\n",
      "    accuracy                           0.79       312\n",
      "   macro avg       0.50      0.40      0.44       312\n",
      "weighted avg       0.99      0.79      0.88       312\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.17      0.04         6\n",
      "           1       0.98      0.82      0.89       276\n",
      "\n",
      "    accuracy                           0.80       282\n",
      "   macro avg       0.50      0.49      0.46       282\n",
      "weighted avg       0.96      0.80      0.87       282\n",
      "\n",
      "XGB  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.50      0.13         6\n",
      "           1       0.99      0.87      0.92       276\n",
      "\n",
      "    accuracy                           0.86       282\n",
      "   macro avg       0.53      0.68      0.53       282\n",
      "weighted avg       0.97      0.86      0.91       282\n",
      "\n",
      "LR  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.17      0.02         6\n",
      "           1       0.97      0.58      0.73       276\n",
      "\n",
      "    accuracy                           0.57       282\n",
      "   macro avg       0.49      0.37      0.37       282\n",
      "weighted avg       0.95      0.57      0.71       282\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22         7\n",
      "           1       0.94      0.99      0.97       104\n",
      "\n",
      "    accuracy                           0.94       111\n",
      "   macro avg       0.72      0.57      0.59       111\n",
      "weighted avg       0.92      0.94      0.92       111\n",
      "\n",
      "XGB  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00       104\n",
      "\n",
      "    accuracy                           1.00       111\n",
      "   macro avg       1.00      1.00      1.00       111\n",
      "weighted avg       1.00      1.00      1.00       111\n",
      "\n",
      "LR  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.94      0.97      0.95       104\n",
      "\n",
      "    accuracy                           0.91       111\n",
      "   macro avg       0.47      0.49      0.48       111\n",
      "weighted avg       0.88      0.91      0.89       111\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.50      0.13         4\n",
      "           1       0.99      0.86      0.92       177\n",
      "\n",
      "    accuracy                           0.86       181\n",
      "   macro avg       0.53      0.68      0.53       181\n",
      "weighted avg       0.97      0.86      0.90       181\n",
      "\n",
      "XGB  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         4\n",
      "           1       1.00      0.99      1.00       177\n",
      "\n",
      "    accuracy                           0.99       181\n",
      "   macro avg       0.90      1.00      0.94       181\n",
      "weighted avg       1.00      0.99      0.99       181\n",
      "\n",
      "LR  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.75      0.13         4\n",
      "           1       0.99      0.77      0.87       177\n",
      "\n",
      "    accuracy                           0.77       181\n",
      "   macro avg       0.53      0.76      0.50       181\n",
      "weighted avg       0.97      0.77      0.85       181\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.38      0.16        13\n",
      "           1       0.95      0.79      0.87       213\n",
      "\n",
      "    accuracy                           0.77       226\n",
      "   macro avg       0.53      0.59      0.51       226\n",
      "weighted avg       0.91      0.77      0.83       226\n",
      "\n",
      "XGB  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.85      0.52        13\n",
      "           1       0.99      0.92      0.95       213\n",
      "\n",
      "    accuracy                           0.91       226\n",
      "   macro avg       0.68      0.88      0.74       226\n",
      "weighted avg       0.95      0.91      0.93       226\n",
      "\n",
      "LR  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.46      0.16        13\n",
      "           1       0.96      0.74      0.84       213\n",
      "\n",
      "    accuracy                           0.73       226\n",
      "   macro avg       0.53      0.60      0.50       226\n",
      "weighted avg       0.91      0.73      0.80       226\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.85      0.92       243\n",
      "\n",
      "    accuracy                           0.84       244\n",
      "   macro avg       0.50      0.42      0.46       244\n",
      "weighted avg       0.99      0.84      0.91       244\n",
      "\n",
      "XGB  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40         1\n",
      "           1       1.00      0.99      0.99       243\n",
      "\n",
      "    accuracy                           0.99       244\n",
      "   macro avg       0.62      0.99      0.70       244\n",
      "weighted avg       1.00      0.99      0.99       244\n",
      "\n",
      "LR  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.99      0.72      0.83       243\n",
      "\n",
      "    accuracy                           0.71       244\n",
      "   macro avg       0.50      0.36      0.42       244\n",
      "weighted avg       0.99      0.71      0.83       244\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.50      0.03         2\n",
      "           1       1.00      0.79      0.88       266\n",
      "\n",
      "    accuracy                           0.78       268\n",
      "   macro avg       0.51      0.64      0.46       268\n",
      "weighted avg       0.99      0.78      0.87       268\n",
      "\n",
      "XGB  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      1.00      0.14         2\n",
      "           1       1.00      0.91      0.95       266\n",
      "\n",
      "    accuracy                           0.91       268\n",
      "   macro avg       0.54      0.95      0.55       268\n",
      "weighted avg       0.99      0.91      0.95       268\n",
      "\n",
      "LR  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      1.00      0.05         2\n",
      "           1       1.00      0.71      0.83       266\n",
      "\n",
      "    accuracy                           0.71       268\n",
      "   macro avg       0.51      0.86      0.44       268\n",
      "weighted avg       0.99      0.71      0.82       268\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.50      0.33        10\n",
      "           1       0.89      0.73      0.80        55\n",
      "\n",
      "    accuracy                           0.69        65\n",
      "   macro avg       0.57      0.61      0.57        65\n",
      "weighted avg       0.79      0.69      0.73        65\n",
      "\n",
      "XGB  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        10\n",
      "           1       1.00      0.89      0.94        55\n",
      "\n",
      "    accuracy                           0.91        65\n",
      "   macro avg       0.81      0.95      0.86        65\n",
      "weighted avg       0.94      0.91      0.92        65\n",
      "\n",
      "LR  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      0.40      0.33        10\n",
      "           1       0.88      0.82      0.85        55\n",
      "\n",
      "    accuracy                           0.75        65\n",
      "   macro avg       0.58      0.61      0.59        65\n",
      "weighted avg       0.79      0.75      0.77        65\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.40      0.08         5\n",
      "           1       0.99      0.86      0.92       287\n",
      "\n",
      "    accuracy                           0.85       292\n",
      "   macro avg       0.52      0.63      0.50       292\n",
      "weighted avg       0.97      0.85      0.90       292\n",
      "\n",
      "XGB  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       292\n",
      "   macro avg       1.00      1.00      1.00       292\n",
      "weighted avg       1.00      1.00      1.00       292\n",
      "\n",
      "LR  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.40      0.05         5\n",
      "           1       0.99      0.77      0.86       287\n",
      "\n",
      "    accuracy                           0.76       292\n",
      "   macro avg       0.51      0.59      0.46       292\n",
      "weighted avg       0.97      0.76      0.85       292\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      1.00      0.35         4\n",
      "           1       1.00      0.92      0.96       199\n",
      "\n",
      "    accuracy                           0.93       203\n",
      "   macro avg       0.61      0.96      0.65       203\n",
      "weighted avg       0.98      0.93      0.95       203\n",
      "\n",
      "XGB  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       199\n",
      "\n",
      "    accuracy                           1.00       203\n",
      "   macro avg       1.00      1.00      1.00       203\n",
      "weighted avg       1.00      1.00      1.00       203\n",
      "\n",
      "LR  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.75      0.25         4\n",
      "           1       0.99      0.91      0.95       199\n",
      "\n",
      "    accuracy                           0.91       203\n",
      "   macro avg       0.57      0.83      0.60       203\n",
      "weighted avg       0.98      0.91      0.94       203\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.75      0.17         4\n",
      "           1       0.99      0.71      0.82        95\n",
      "\n",
      "    accuracy                           0.71        99\n",
      "   macro avg       0.54      0.73      0.50        99\n",
      "weighted avg       0.95      0.71      0.80        99\n",
      "\n",
      "XGB  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.62         4\n",
      "           1       1.00      0.95      0.97        95\n",
      "\n",
      "    accuracy                           0.95        99\n",
      "   macro avg       0.72      0.97      0.79        99\n",
      "weighted avg       0.98      0.95      0.96        99\n",
      "\n",
      "LR  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.50      0.09         4\n",
      "           1       0.96      0.58      0.72        95\n",
      "\n",
      "    accuracy                           0.58        99\n",
      "   macro avg       0.51      0.54      0.41        99\n",
      "weighted avg       0.93      0.58      0.70        99\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.25      0.08         4\n",
      "           1       0.98      0.88      0.93       166\n",
      "\n",
      "    accuracy                           0.86       170\n",
      "   macro avg       0.51      0.56      0.50       170\n",
      "weighted avg       0.96      0.86      0.91       170\n",
      "\n",
      "XGB  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       166\n",
      "\n",
      "    accuracy                           1.00       170\n",
      "   macro avg       1.00      1.00      1.00       170\n",
      "weighted avg       1.00      1.00      1.00       170\n",
      "\n",
      "LR  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.25      0.05         4\n",
      "           1       0.98      0.81      0.88       166\n",
      "\n",
      "    accuracy                           0.79       170\n",
      "   macro avg       0.50      0.53      0.47       170\n",
      "weighted avg       0.96      0.79      0.86       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,\\\n",
    "f1_score,precision_score,recall_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "k=1\n",
    "\n",
    "f1=[]\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "roc_auc=[]\n",
    "model=[]\n",
    "\n",
    "testPersons=[['P31.csv','P19.csv'],\n",
    "            ['P20.csv','P24.csv'],\n",
    "            ['P13.csv','P30.csv'],#\n",
    "            ['P31.csv','P18.csv'],\n",
    "            ['P08.csv','P24.csv']#\n",
    "#             both\n",
    "            ]\n",
    "\n",
    "sm=SMOTE()\n",
    "for i in range(len(testPersons)):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # Scramble\n",
    "    random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "    only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "    only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "    both = [key for key, value in depression.items() if len(value) == 2]\n",
    "    # testPerson = ['08'] + ['24']#['16','08'] + ['24','30']\n",
    "#     testPerson = [random.choice(only0)] \\\n",
    "#     + [random.choice(only1)]\n",
    "#     print(testPerson)\n",
    "#     # testPerson = [13,17]\n",
    "#     allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "#     trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "#     testPerson = random.sample(only0,k) \\\n",
    "#     + random.sample(only1,k)\n",
    "    testPerson=testPersons[i]\n",
    "    # testPerson = [13,17]\n",
    "    allPerson = contestants\n",
    "    trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "\n",
    "#     # Merge train data and shuffle\n",
    "#     train_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in trainPerson]\n",
    "#     merged_train = pd.concat(train_list, ignore_index=True)\n",
    "#     shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "#     test_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in testPerson]\n",
    "#     merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_test = shuffled_test.drop([ 'img_name'], axis = 1)\n",
    "    for num in trainPerson:\n",
    "        train = pd.read_csv(f'{base_path}/{num}')\n",
    "        train=train.set_index('img_name')\n",
    "        duplicate_rows = train.index.duplicated()\n",
    "        train=train.loc[~duplicate_rows,:]\n",
    "        add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "        add_data=add_data.drop(['Unnamed: 0','level'],axis=1)\n",
    "        add_data=add_data.set_index('img_name')\n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        train_=pd.concat([train,add_data],axis=1)\n",
    "        train_=train_.reset_index()\n",
    "        train_=train_.dropna()\n",
    "        train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "        train_list.append(train)#train_ for addition data\n",
    "    \n",
    "    merged_train = pd.concat(train_list, ignore_index=True)\n",
    "    shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    try:\n",
    "        shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "    except:pass   \n",
    "\n",
    "    for num in testPerson:\n",
    "        test = pd.read_csv(f'{base_path}/{num}')\n",
    "        test=test.set_index('img_name')\n",
    "        duplicate_rows = test.index.duplicated()\n",
    "        test=test.loc[~duplicate_rows,:]\n",
    "        add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "        add_data=add_data.drop(['Unnamed: 0','level'],axis=1)\n",
    "        add_data=add_data.set_index('img_name')\n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        test_=pd.concat([test,add_data],axis=1)\n",
    "        test_=test_.reset_index()\n",
    "        test_=test_.dropna()\n",
    "        test_=test_.drop(['timestamp','ID'],axis=1)\n",
    "        test=test.reset_index(drop=False)\n",
    "        test_list.append(test)#test_ for addition data\n",
    "    merged_test = pd.concat(test_list, ignore_index=True)\n",
    "    shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    try:\n",
    "#         shuffled_test=shuffled_test.reset_index(drop=False)\n",
    "        shuffled_test['ts']=shuffled_test['img_name'].apply(lambda x :int(int(x.split('_')[-1][:-4])/1000))\n",
    "        shuffled_test['ts']=shuffled_test['ts'].apply(lambda x: datetime.datetime.fromtimestamp(x).date())\n",
    "        shuffled_test = shuffled_test.drop(['img_name'], axis = 1)\n",
    "        \n",
    "    except Exception as e:print('!!!')\n",
    "\n",
    "    for k in shuffled_test['ts'].unique():\n",
    "        add_train_from_test1,shuffled_test1=shuffled_test[shuffled_test['ts']<k],shuffled_test[shuffled_test['ts']==k]\n",
    "    #     add_train_from_test,shuffled_test=train_test_split(shuffled_test,test_size=0.5)\n",
    "        add_train_from_test1,shuffled_test1=add_train_from_test1.drop('ts',axis=1),shuffled_test1.drop('ts',axis=1)\n",
    "        shuffled_train=pd.concat([add_train_from_test1,shuffled_train],axis=0)\n",
    "\n",
    "\n",
    "        X_train, y_train = shuffled_train.drop('level', axis = 1), shuffled_train['level']\n",
    "#         print(X_train)\n",
    "        X_test, y_test = shuffled_test1.drop('level', axis = 1), shuffled_test1['level']\n",
    "        if shuffled_test1['level'].nunique()<2:\n",
    "            continue\n",
    "        y_train =y_train.astype('category')\n",
    "        y_test =y_test.astype('category')\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "#         print(X_train.isna().sum().sum())\n",
    "        X_train=pd.DataFrame(X_train,columns=X_train.columns)\n",
    "        X_test=X_test[X_train.columns]\n",
    "    \n",
    "        # y_train=pd.DataFrame(y_train,columns=y_test.columns)\n",
    "        # Print train test contestants\n",
    "        print(\"Train: \", trainPerson)\n",
    "        print(\"Test: \", testPerson)\n",
    "\n",
    "\n",
    "        # Logistic Regression\n",
    "        # log_reg = LogisticRegression(max_iter=10000)\n",
    "        # log_reg.fit(X_train, y_train)\n",
    "        # log_reg_pred = log_reg.predict(X_test)\n",
    "        # log_reg_acc = classification_report(y_test, log_reg_pred)\n",
    "        # print(f\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "\n",
    "        # K-Nearest Neighbors (KNN)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100)\n",
    "        knn.fit(X_train, y_train)\n",
    "        knn_pred = knn.predict(X_test)\n",
    "        knn_rp = classification_report(y_test, knn_pred)\n",
    "        accuracy.append(accuracy_score(y_test, knn_pred))\n",
    "        f1.append(f1_score(y_test, knn_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, knn_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, knn_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, knn_pred))\n",
    "        model.append('KNN')\n",
    "        print('knn ',i,'    ', k)\n",
    "        print(knn_rp)\n",
    "\n",
    "\n",
    "    #     # Support Vector Machine (SVM)\n",
    "        svm =  XGBClassifier(n_estimators=100)#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "        svm.fit(X_train, y_train)\n",
    "        svm_pred = svm.predict(X_test)\n",
    "        svm_rp = classification_report(y_test, svm_pred)\n",
    "        accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "        f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "        model.append('XGB')\n",
    "        print('XGB ',i,'    ', k)\n",
    "        print(svm_rp)\n",
    "\n",
    "        svm =  LogisticRegression()#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "        svm.fit(X_train, y_train)\n",
    "        svm_pred = svm.predict(X_test)\n",
    "        svm_rp = classification_report(y_test, svm_pred)\n",
    "        accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "        f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "        model.append('LR')\n",
    "        print('LR ',i,'    ', k)\n",
    "        print(svm_rp)\n",
    "\n",
    "    #     # Random Forest Classifier\n",
    "    #     rf = RandomForestClassifier(n_estimators=1000)\n",
    "    #     rf.fit(X_train, y_train)\n",
    "    #     rf_pred = rf.predict(X_test)\n",
    "    #     rf_acc = classification_report(y_test, rf_pred)\n",
    "    #     print('rf ',i)\n",
    "    #     print(rf_acc)\n",
    "\n",
    "    #     xgb = XGBClassifier(n_estimators=1000)\n",
    "    #     xgb.fit(X_train, y_train)\n",
    "    #     xgb_pred = xgb.predict(X_test)\n",
    "    #     xgb_acc = classification_report(y_test, xgb_pred)\n",
    "    #     print('xgb ',i)\n",
    "    #     print(xgb_acc)\n",
    "\n",
    "    #     # Neural Network (MLP Classifier)\n",
    "    #     mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000)\n",
    "    #     mlp.fit(X_train, y_train)\n",
    "    #     mlp_pred = mlp.predict(X_test)\n",
    "    #     mlp_acc = classification_report(y_test, mlp_pred)\n",
    "    #     print('MLP ',i)\n",
    "    #     print(mlp_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Input_Features       p_values\n",
      "13           AU09   0.000000e+00\n",
      "22           AU24   0.000000e+00\n",
      "21           AU23   0.000000e+00\n",
      "20           AU20   0.000000e+00\n",
      "18           AU15   0.000000e+00\n",
      "17           AU14   0.000000e+00\n",
      "16           AU12   0.000000e+00\n",
      "14           AU10   0.000000e+00\n",
      "12           AU07   0.000000e+00\n",
      "11           AU06   0.000000e+00\n",
      "26           AU43   0.000000e+00\n",
      "8            AU02   0.000000e+00\n",
      "7            AU01   0.000000e+00\n",
      "5        surprise   0.000000e+00\n",
      "4         sadness   0.000000e+00\n",
      "3       happiness   0.000000e+00\n",
      "2            fear   0.000000e+00\n",
      "10           AU05   0.000000e+00\n",
      "1         disgust  1.091137e-294\n",
      "23           AU25  2.232551e-271\n",
      "0           anger  2.854946e-204\n",
      "24           AU26  3.511564e-166\n",
      "25           AU28   5.249707e-88\n",
      "6         neutral   2.150164e-86\n",
      "9            AU04   2.130099e-36\n",
      "15           AU11   5.995356e-02\n",
      "19           AU17   2.759135e-01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "fs = SelectKBest(score_func=f_regression,k=15)\n",
    "# Applying feature selection\n",
    "fit = fs.fit(X_train,y_train)\n",
    "features_score1 = pd.DataFrame(fit.pvalues_)\n",
    "features1 = pd.DataFrame(X_train.columns)\n",
    "feature_score1 = pd.concat([features1,features_score1],axis=1)\n",
    "# Assigning column names\n",
    "feature_score1.columns = [\"Input_Features\",\"p_values\"]\n",
    "feature_score1=feature_score1.sort_values('p_values', ascending=True)\n",
    "print(feature_score1.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anger</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>happiness</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>neutral</th>\n",
       "      <th>AU01</th>\n",
       "      <th>AU02</th>\n",
       "      <th>AU04</th>\n",
       "      <th>...</th>\n",
       "      <th>AU14</th>\n",
       "      <th>AU15</th>\n",
       "      <th>AU17</th>\n",
       "      <th>AU20</th>\n",
       "      <th>AU23</th>\n",
       "      <th>AU24</th>\n",
       "      <th>AU25</th>\n",
       "      <th>AU26</th>\n",
       "      <th>AU28</th>\n",
       "      <th>AU43</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.032766</td>\n",
       "      <td>0.013211</td>\n",
       "      <td>0.064100</td>\n",
       "      <td>0.233276</td>\n",
       "      <td>0.046855</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.607292</td>\n",
       "      <td>0.443364</td>\n",
       "      <td>0.218667</td>\n",
       "      <td>0.289189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.372050</td>\n",
       "      <td>0.252212</td>\n",
       "      <td>0.319805</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.293043</td>\n",
       "      <td>0.061991</td>\n",
       "      <td>0.998946</td>\n",
       "      <td>0.349615</td>\n",
       "      <td>0.069145</td>\n",
       "      <td>0.175351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019888</td>\n",
       "      <td>0.012265</td>\n",
       "      <td>0.089376</td>\n",
       "      <td>0.131485</td>\n",
       "      <td>0.048085</td>\n",
       "      <td>0.007125</td>\n",
       "      <td>0.691777</td>\n",
       "      <td>0.456801</td>\n",
       "      <td>0.232307</td>\n",
       "      <td>0.138910</td>\n",
       "      <td>...</td>\n",
       "      <td>0.342788</td>\n",
       "      <td>0.127112</td>\n",
       "      <td>0.417551</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.713131</td>\n",
       "      <td>0.491846</td>\n",
       "      <td>0.264327</td>\n",
       "      <td>0.143741</td>\n",
       "      <td>0.224265</td>\n",
       "      <td>0.086255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.014963</td>\n",
       "      <td>0.004052</td>\n",
       "      <td>0.025901</td>\n",
       "      <td>0.276879</td>\n",
       "      <td>0.039396</td>\n",
       "      <td>0.001221</td>\n",
       "      <td>0.637588</td>\n",
       "      <td>0.467260</td>\n",
       "      <td>0.195741</td>\n",
       "      <td>0.204016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454676</td>\n",
       "      <td>0.488990</td>\n",
       "      <td>0.484938</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.099745</td>\n",
       "      <td>0.975566</td>\n",
       "      <td>0.456625</td>\n",
       "      <td>0.230307</td>\n",
       "      <td>0.611950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.013326</td>\n",
       "      <td>0.009135</td>\n",
       "      <td>0.200774</td>\n",
       "      <td>0.311167</td>\n",
       "      <td>0.078623</td>\n",
       "      <td>0.006795</td>\n",
       "      <td>0.380181</td>\n",
       "      <td>0.666445</td>\n",
       "      <td>0.405115</td>\n",
       "      <td>0.363413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161942</td>\n",
       "      <td>0.378741</td>\n",
       "      <td>0.334604</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.599387</td>\n",
       "      <td>0.060775</td>\n",
       "      <td>0.991776</td>\n",
       "      <td>0.578863</td>\n",
       "      <td>0.039744</td>\n",
       "      <td>0.316128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.025835</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>0.312836</td>\n",
       "      <td>0.069692</td>\n",
       "      <td>0.143381</td>\n",
       "      <td>0.025997</td>\n",
       "      <td>0.417178</td>\n",
       "      <td>0.581017</td>\n",
       "      <td>0.283933</td>\n",
       "      <td>0.176555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108471</td>\n",
       "      <td>0.058161</td>\n",
       "      <td>0.396856</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527980</td>\n",
       "      <td>0.142062</td>\n",
       "      <td>0.898858</td>\n",
       "      <td>0.302182</td>\n",
       "      <td>0.083846</td>\n",
       "      <td>0.069602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30283</th>\n",
       "      <td>0.016241</td>\n",
       "      <td>0.024998</td>\n",
       "      <td>0.040158</td>\n",
       "      <td>0.605264</td>\n",
       "      <td>0.033068</td>\n",
       "      <td>0.003788</td>\n",
       "      <td>0.276482</td>\n",
       "      <td>0.742105</td>\n",
       "      <td>0.474951</td>\n",
       "      <td>0.246416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661033</td>\n",
       "      <td>0.103063</td>\n",
       "      <td>0.224619</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.250759</td>\n",
       "      <td>0.073020</td>\n",
       "      <td>0.999553</td>\n",
       "      <td>0.171607</td>\n",
       "      <td>0.099269</td>\n",
       "      <td>0.071555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30284</th>\n",
       "      <td>0.013162</td>\n",
       "      <td>0.010487</td>\n",
       "      <td>0.176290</td>\n",
       "      <td>0.142475</td>\n",
       "      <td>0.044099</td>\n",
       "      <td>0.007531</td>\n",
       "      <td>0.605955</td>\n",
       "      <td>0.555857</td>\n",
       "      <td>0.251840</td>\n",
       "      <td>0.232915</td>\n",
       "      <td>...</td>\n",
       "      <td>0.422490</td>\n",
       "      <td>0.114565</td>\n",
       "      <td>0.432122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.707598</td>\n",
       "      <td>0.796577</td>\n",
       "      <td>0.493804</td>\n",
       "      <td>0.110874</td>\n",
       "      <td>0.100043</td>\n",
       "      <td>0.064350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30285</th>\n",
       "      <td>0.028272</td>\n",
       "      <td>0.003548</td>\n",
       "      <td>0.212114</td>\n",
       "      <td>0.143694</td>\n",
       "      <td>0.098697</td>\n",
       "      <td>0.119410</td>\n",
       "      <td>0.394266</td>\n",
       "      <td>0.626839</td>\n",
       "      <td>0.190283</td>\n",
       "      <td>0.424458</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188635</td>\n",
       "      <td>0.459225</td>\n",
       "      <td>0.575657</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.478711</td>\n",
       "      <td>0.208023</td>\n",
       "      <td>0.974462</td>\n",
       "      <td>0.309109</td>\n",
       "      <td>0.304893</td>\n",
       "      <td>0.257993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30286</th>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.266233</td>\n",
       "      <td>0.152811</td>\n",
       "      <td>0.056463</td>\n",
       "      <td>0.006581</td>\n",
       "      <td>0.489655</td>\n",
       "      <td>0.553512</td>\n",
       "      <td>0.393145</td>\n",
       "      <td>0.270438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379909</td>\n",
       "      <td>0.394120</td>\n",
       "      <td>0.357959</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.612222</td>\n",
       "      <td>0.088821</td>\n",
       "      <td>0.984578</td>\n",
       "      <td>0.429370</td>\n",
       "      <td>0.045454</td>\n",
       "      <td>0.245766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30287</th>\n",
       "      <td>0.025648</td>\n",
       "      <td>0.008127</td>\n",
       "      <td>0.152645</td>\n",
       "      <td>0.416426</td>\n",
       "      <td>0.035074</td>\n",
       "      <td>0.010273</td>\n",
       "      <td>0.351807</td>\n",
       "      <td>0.634055</td>\n",
       "      <td>0.436000</td>\n",
       "      <td>0.262895</td>\n",
       "      <td>...</td>\n",
       "      <td>0.395993</td>\n",
       "      <td>0.558623</td>\n",
       "      <td>0.342621</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.736951</td>\n",
       "      <td>0.038171</td>\n",
       "      <td>0.993475</td>\n",
       "      <td>0.604748</td>\n",
       "      <td>0.058973</td>\n",
       "      <td>0.636907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93749 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          anger   disgust      fear  happiness   sadness  surprise   neutral  \\\n",
       "0      0.032766  0.013211  0.064100   0.233276  0.046855  0.002500  0.607292   \n",
       "1      0.019888  0.012265  0.089376   0.131485  0.048085  0.007125  0.691777   \n",
       "2      0.014963  0.004052  0.025901   0.276879  0.039396  0.001221  0.637588   \n",
       "3      0.013326  0.009135  0.200774   0.311167  0.078623  0.006795  0.380181   \n",
       "5      0.025835  0.005082  0.312836   0.069692  0.143381  0.025997  0.417178   \n",
       "...         ...       ...       ...        ...       ...       ...       ...   \n",
       "30283  0.016241  0.024998  0.040158   0.605264  0.033068  0.003788  0.276482   \n",
       "30284  0.013162  0.010487  0.176290   0.142475  0.044099  0.007531  0.605955   \n",
       "30285  0.028272  0.003548  0.212114   0.143694  0.098697  0.119410  0.394266   \n",
       "30286  0.020716  0.007542  0.266233   0.152811  0.056463  0.006581  0.489655   \n",
       "30287  0.025648  0.008127  0.152645   0.416426  0.035074  0.010273  0.351807   \n",
       "\n",
       "           AU01      AU02      AU04  ...      AU14      AU15      AU17  AU20  \\\n",
       "0      0.443364  0.218667  0.289189  ...  0.372050  0.252212  0.319805   1.0   \n",
       "1      0.456801  0.232307  0.138910  ...  0.342788  0.127112  0.417551   0.0   \n",
       "2      0.467260  0.195741  0.204016  ...  0.454676  0.488990  0.484938   0.0   \n",
       "3      0.666445  0.405115  0.363413  ...  0.161942  0.378741  0.334604   1.0   \n",
       "5      0.581017  0.283933  0.176555  ...  0.108471  0.058161  0.396856   0.0   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   ...   \n",
       "30283  0.742105  0.474951  0.246416  ...  0.661033  0.103063  0.224619   1.0   \n",
       "30284  0.555857  0.251840  0.232915  ...  0.422490  0.114565  0.432122   0.0   \n",
       "30285  0.626839  0.190283  0.424458  ...  0.188635  0.459225  0.575657   0.0   \n",
       "30286  0.553512  0.393145  0.270438  ...  0.379909  0.394120  0.357959   1.0   \n",
       "30287  0.634055  0.436000  0.262895  ...  0.395993  0.558623  0.342621   1.0   \n",
       "\n",
       "           AU23      AU24      AU25      AU26      AU28      AU43  \n",
       "0      0.293043  0.061991  0.998946  0.349615  0.069145  0.175351  \n",
       "1      0.713131  0.491846  0.264327  0.143741  0.224265  0.086255  \n",
       "2      0.814000  0.099745  0.975566  0.456625  0.230307  0.611950  \n",
       "3      0.599387  0.060775  0.991776  0.578863  0.039744  0.316128  \n",
       "5      0.527980  0.142062  0.898858  0.302182  0.083846  0.069602  \n",
       "...         ...       ...       ...       ...       ...       ...  \n",
       "30283  0.250759  0.073020  0.999553  0.171607  0.099269  0.071555  \n",
       "30284  0.707598  0.796577  0.493804  0.110874  0.100043  0.064350  \n",
       "30285  0.478711  0.208023  0.974462  0.309109  0.304893  0.257993  \n",
       "30286  0.612222  0.088821  0.984578  0.429370  0.045454  0.245766  \n",
       "30287  0.736951  0.038171  0.993475  0.604748  0.058973  0.636907  \n",
       "\n",
       "[93749 rows x 27 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num in trainPerson:\n",
    "#     train = pd.read_csv(f'{base_path}/{num}')\n",
    "#     train=train.set_index('img_name')\n",
    "#     duplicate_rows = train.index.duplicated()\n",
    "#     train=train.loc[~duplicate_rows,:]\n",
    "#     add_data=train.copy()\n",
    "#     add_data=add_data.shift(1)\n",
    "#     add_data.columns=[i+'_prev' for i in add_data.columns]\n",
    "#     train_=pd.concat([train,add_data],axis=1)\n",
    "#     train_=train_.reset_index()\n",
    "#     train_=train_.dropna()\n",
    "# #     train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "#     break\n",
    "# train_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43'],\n",
      "      dtype='object')\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43', 'anger_time_lag', 'disgust_time_lag',\n",
      "       'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag',\n",
      "       'surprise_time_lag', 'neutral_time_lag', 'AU01_time_lag',\n",
      "       'AU02_time_lag', 'AU04_time_lag', 'AU05_time_lag', 'AU06_time_lag',\n",
      "       'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU11_time_lag',\n",
      "       'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU17_time_lag',\n",
      "       'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag',\n",
      "       'AU26_time_lag', 'AU28_time_lag', 'AU43_time_lag', 'anger_vel',\n",
      "       'disgust_vel', 'fear_vel', 'happiness_vel', 'sadness_vel',\n",
      "       'surprise_vel', 'neutral_vel', 'AU01_vel', 'AU02_vel', 'AU04_vel',\n",
      "       'AU05_vel', 'AU06_vel', 'AU07_vel', 'AU09_vel', 'AU10_vel', 'AU11_vel',\n",
      "       'AU12_vel', 'AU14_vel', 'AU15_vel', 'AU17_vel', 'AU20_vel', 'AU23_vel',\n",
      "       'AU24_vel', 'AU25_vel', 'AU26_vel', 'AU28_vel', 'AU43_vel'],\n",
      "      dtype='object')\n",
      "knn  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.84      0.87        63\n",
      "           1       0.73      0.82      0.77        33\n",
      "\n",
      "    accuracy                           0.83        96\n",
      "   macro avg       0.81      0.83      0.82        96\n",
      "weighted avg       0.84      0.83      0.84        96\n",
      "\n",
      "XGB_  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82        63\n",
      "           1       0.77      0.30      0.43        33\n",
      "\n",
      "    accuracy                           0.73        96\n",
      "   macro avg       0.75      0.63      0.63        96\n",
      "weighted avg       0.74      0.73      0.69        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        63\n",
      "           1       0.96      0.76      0.85        33\n",
      "\n",
      "    accuracy                           0.91        96\n",
      "   macro avg       0.92      0.87      0.89        96\n",
      "weighted avg       0.91      0.91      0.90        96\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90        39\n",
      "           1       0.93      0.88      0.90        42\n",
      "\n",
      "    accuracy                           0.90        81\n",
      "   macro avg       0.90      0.90      0.90        81\n",
      "weighted avg       0.90      0.90      0.90        81\n",
      "\n",
      "XGB_  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      1.00      0.86        39\n",
      "           1       1.00      0.69      0.82        42\n",
      "\n",
      "    accuracy                           0.84        81\n",
      "   macro avg       0.88      0.85      0.84        81\n",
      "weighted avg       0.88      0.84      0.84        81\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        39\n",
      "           1       0.97      0.93      0.95        42\n",
      "\n",
      "    accuracy                           0.95        81\n",
      "   macro avg       0.95      0.95      0.95        81\n",
      "weighted avg       0.95      0.95      0.95        81\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96        51\n",
      "           1       0.97      0.97      0.97        58\n",
      "\n",
      "    accuracy                           0.96       109\n",
      "   macro avg       0.96      0.96      0.96       109\n",
      "weighted avg       0.96      0.96      0.96       109\n",
      "\n",
      "XGB_  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        58\n",
      "\n",
      "    accuracy                           1.00       109\n",
      "   macro avg       1.00      1.00      1.00       109\n",
      "weighted avg       1.00      1.00      1.00       109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        51\n",
      "           1       1.00      0.98      0.99        58\n",
      "\n",
      "    accuracy                           0.99       109\n",
      "   macro avg       0.99      0.99      0.99       109\n",
      "weighted avg       0.99      0.99      0.99       109\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        50\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.90      0.99      0.94        54\n",
      "weighted avg       0.99      0.98      0.98        54\n",
      "\n",
      "XGB_  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        11\n",
      "           1       1.00      0.91      0.96        35\n",
      "\n",
      "    accuracy                           0.93        46\n",
      "   macro avg       0.89      0.96      0.92        46\n",
      "weighted avg       0.95      0.93      0.94        46\n",
      "\n",
      "XGB_  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        11\n",
      "           1       1.00      0.97      0.99        35\n",
      "\n",
      "    accuracy                           0.98        46\n",
      "   macro avg       0.96      0.99      0.97        46\n",
      "weighted avg       0.98      0.98      0.98        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        11\n",
      "           1       1.00      0.94      0.97        35\n",
      "\n",
      "    accuracy                           0.96        46\n",
      "   macro avg       0.92      0.97      0.94        46\n",
      "weighted avg       0.96      0.96      0.96        46\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        45\n",
      "           1       1.00      0.85      0.92        47\n",
      "\n",
      "    accuracy                           0.92        92\n",
      "   macro avg       0.93      0.93      0.92        92\n",
      "weighted avg       0.93      0.92      0.92        92\n",
      "\n",
      "XGB_  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           1.00        92\n",
      "   macro avg       1.00      1.00      1.00        92\n",
      "weighted avg       1.00      1.00      1.00        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        45\n",
      "           1       1.00      0.98      0.99        47\n",
      "\n",
      "    accuracy                           0.99        92\n",
      "   macro avg       0.99      0.99      0.99        92\n",
      "weighted avg       0.99      0.99      0.99        92\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.97        81\n",
      "           1       0.95      0.97      0.96        58\n",
      "\n",
      "    accuracy                           0.96       139\n",
      "   macro avg       0.96      0.96      0.96       139\n",
      "weighted avg       0.96      0.96      0.96       139\n",
      "\n",
      "XGB_  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        58\n",
      "\n",
      "    accuracy                           1.00       139\n",
      "   macro avg       1.00      1.00      1.00       139\n",
      "weighted avg       1.00      1.00      1.00       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        81\n",
      "           1       0.96      0.95      0.96        58\n",
      "\n",
      "    accuracy                           0.96       139\n",
      "   macro avg       0.96      0.96      0.96       139\n",
      "weighted avg       0.96      0.96      0.96       139\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        37\n",
      "           1       1.00      0.80      0.89        20\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.95      0.90      0.92        57\n",
      "weighted avg       0.94      0.93      0.93        57\n",
      "\n",
      "XGB_  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00        20\n",
      "\n",
      "    accuracy                           1.00        57\n",
      "   macro avg       1.00      1.00      1.00        57\n",
      "weighted avg       1.00      1.00      1.00        57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        37\n",
      "           1       1.00      0.80      0.89        20\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.95      0.90      0.92        57\n",
      "weighted avg       0.94      0.93      0.93        57\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         8\n",
      "           1       1.00      0.93      0.96        28\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.90      0.96      0.93        36\n",
      "weighted avg       0.96      0.94      0.95        36\n",
      "\n",
      "XGB_  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94         8\n",
      "           1       1.00      0.96      0.98        28\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.94      0.98      0.96        36\n",
      "weighted avg       0.98      0.97      0.97        36\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.92        33\n",
      "           1       0.94      0.96      0.95        47\n",
      "\n",
      "    accuracy                           0.94        80\n",
      "   macro avg       0.94      0.93      0.94        80\n",
      "weighted avg       0.94      0.94      0.94        80\n",
      "\n",
      "XGB_  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95        38\n",
      "           1       0.89      0.89      0.89        18\n",
      "\n",
      "    accuracy                           0.93        56\n",
      "   macro avg       0.92      0.92      0.92        56\n",
      "weighted avg       0.93      0.93      0.93        56\n",
      "\n",
      "XGB_  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       1.00      1.00      1.00        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       1.00      1.00      1.00        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        48\n",
      "           1       0.83      1.00      0.91         5\n",
      "\n",
      "    accuracy                           0.98        53\n",
      "   macro avg       0.92      0.99      0.95        53\n",
      "weighted avg       0.98      0.98      0.98        53\n",
      "\n",
      "XGB_  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        21\n",
      "           1       1.00      0.64      0.78        14\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.90      0.82      0.84        35\n",
      "weighted avg       0.88      0.86      0.85        35\n",
      "\n",
      "XGB_  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        21\n",
      "           1       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.97        35\n",
      "   macro avg       0.98      0.96      0.97        35\n",
      "weighted avg       0.97      0.97      0.97        35\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        18\n",
      "           1       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.97        37\n",
      "   macro avg       0.97      0.97      0.97        37\n",
      "weighted avg       0.97      0.97      0.97        37\n",
      "\n",
      "XGB_  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        37\n",
      "   macro avg       1.00      1.00      1.00        37\n",
      "weighted avg       1.00      1.00      1.00        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        37\n",
      "   macro avg       1.00      1.00      1.00        37\n",
      "weighted avg       1.00      1.00      1.00        37\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.75      0.67         4\n",
      "           1       0.96      0.92      0.94        25\n",
      "\n",
      "    accuracy                           0.90        29\n",
      "   macro avg       0.78      0.83      0.80        29\n",
      "weighted avg       0.91      0.90      0.90        29\n",
      "\n",
      "XGB_  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n",
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43', 'anger_time_lag', 'disgust_time_lag',\n",
      "       'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag',\n",
      "       'surprise_time_lag', 'neutral_time_lag', 'AU01_time_lag',\n",
      "       'AU02_time_lag', 'AU04_time_lag', 'AU05_time_lag', 'AU06_time_lag',\n",
      "       'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU11_time_lag',\n",
      "       'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU17_time_lag',\n",
      "       'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag',\n",
      "       'AU26_time_lag', 'AU28_time_lag', 'AU43_time_lag', 'anger_vel',\n",
      "       'disgust_vel', 'fear_vel', 'happiness_vel', 'sadness_vel',\n",
      "       'surprise_vel', 'neutral_vel', 'AU01_vel', 'AU02_vel', 'AU04_vel',\n",
      "       'AU05_vel', 'AU06_vel', 'AU07_vel', 'AU09_vel', 'AU10_vel', 'AU11_vel',\n",
      "       'AU12_vel', 'AU14_vel', 'AU15_vel', 'AU17_vel', 'AU20_vel', 'AU23_vel',\n",
      "       'AU24_vel', 'AU25_vel', 'AU26_vel', 'AU28_vel', 'AU43_vel'],\n",
      "      dtype='object')\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79        23\n",
      "           1       0.94      0.97      0.96       104\n",
      "\n",
      "    accuracy                           0.93       127\n",
      "   macro avg       0.90      0.86      0.87       127\n",
      "weighted avg       0.93      0.93      0.93       127\n",
      "\n",
      "XGB_  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      1.00      1.00       104\n",
      "\n",
      "    accuracy                           1.00       127\n",
      "   macro avg       1.00      1.00      1.00       127\n",
      "weighted avg       1.00      1.00      1.00       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.74      0.79        23\n",
      "           1       0.94      0.97      0.96       104\n",
      "\n",
      "    accuracy                           0.93       127\n",
      "   macro avg       0.90      0.86      0.87       127\n",
      "weighted avg       0.93      0.93      0.93       127\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.42      1.00      0.59        30\n",
      "           1       1.00      0.85      0.92       266\n",
      "\n",
      "    accuracy                           0.86       296\n",
      "   macro avg       0.71      0.92      0.76       296\n",
      "weighted avg       0.94      0.86      0.88       296\n",
      "\n",
      "XGB_  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98        30\n",
      "           1       1.00      1.00      1.00       266\n",
      "\n",
      "    accuracy                           1.00       296\n",
      "   macro avg       0.98      1.00      0.99       296\n",
      "weighted avg       1.00      1.00      1.00       296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.83      0.64        30\n",
      "           1       0.98      0.91      0.95       266\n",
      "\n",
      "    accuracy                           0.91       296\n",
      "   macro avg       0.75      0.87      0.79       296\n",
      "weighted avg       0.93      0.91      0.91       296\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.84        53\n",
      "           1       0.99      0.89      0.94       166\n",
      "\n",
      "    accuracy                           0.91       219\n",
      "   macro avg       0.86      0.93      0.89       219\n",
      "weighted avg       0.93      0.91      0.91       219\n",
      "\n",
      "XGB_  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00       166\n",
      "\n",
      "    accuracy                           1.00       219\n",
      "   macro avg       1.00      1.00      1.00       219\n",
      "weighted avg       1.00      1.00      1.00       219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.89      0.86        53\n",
      "           1       0.96      0.95      0.95       166\n",
      "\n",
      "    accuracy                           0.93       219\n",
      "   macro avg       0.90      0.92      0.91       219\n",
      "weighted avg       0.93      0.93      0.93       219\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.97      0.74        35\n",
      "           1       0.99      0.87      0.93       177\n",
      "\n",
      "    accuracy                           0.89       212\n",
      "   macro avg       0.80      0.92      0.83       212\n",
      "weighted avg       0.93      0.89      0.90       212\n",
      "\n",
      "XGB_  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       212\n",
      "   macro avg       1.00      1.00      1.00       212\n",
      "weighted avg       1.00      1.00      1.00       212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.97      0.80        35\n",
      "           1       0.99      0.91      0.95       177\n",
      "\n",
      "    accuracy                           0.92       212\n",
      "   macro avg       0.84      0.94      0.87       212\n",
      "weighted avg       0.94      0.92      0.93       212\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.86      0.38         7\n",
      "           1       0.99      0.88      0.94       163\n",
      "\n",
      "    accuracy                           0.88       170\n",
      "   macro avg       0.62      0.87      0.66       170\n",
      "weighted avg       0.96      0.88      0.91       170\n",
      "\n",
      "XGB_  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00       163\n",
      "\n",
      "    accuracy                           1.00       170\n",
      "   macro avg       1.00      1.00      1.00       170\n",
      "weighted avg       1.00      1.00      1.00       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.74         7\n",
      "           1       1.00      0.97      0.98       163\n",
      "\n",
      "    accuracy                           0.97       170\n",
      "   macro avg       0.79      0.98      0.86       170\n",
      "weighted avg       0.98      0.97      0.97       170\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.88      0.24         8\n",
      "           1       1.00      0.85      0.92       287\n",
      "\n",
      "    accuracy                           0.85       295\n",
      "   macro avg       0.57      0.86      0.58       295\n",
      "weighted avg       0.97      0.85      0.90       295\n",
      "\n",
      "XGB_  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       295\n",
      "   macro avg       1.00      1.00      1.00       295\n",
      "weighted avg       1.00      1.00      1.00       295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.88      0.39         8\n",
      "           1       1.00      0.93      0.96       287\n",
      "\n",
      "    accuracy                           0.93       295\n",
      "   macro avg       0.62      0.90      0.67       295\n",
      "weighted avg       0.98      0.93      0.94       295\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.87      0.68        15\n",
      "           1       0.99      0.95      0.97       199\n",
      "\n",
      "    accuracy                           0.94       214\n",
      "   macro avg       0.78      0.91      0.83       214\n",
      "weighted avg       0.96      0.94      0.95       214\n",
      "\n",
      "XGB_  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00       199\n",
      "\n",
      "    accuracy                           1.00       214\n",
      "   macro avg       1.00      1.00      1.00       214\n",
      "weighted avg       1.00      1.00      1.00       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.93      0.76        15\n",
      "           1       0.99      0.96      0.98       199\n",
      "\n",
      "    accuracy                           0.96       214\n",
      "   macro avg       0.82      0.95      0.87       214\n",
      "weighted avg       0.97      0.96      0.96       214\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53        21\n",
      "           1       1.00      0.84      0.92       243\n",
      "\n",
      "    accuracy                           0.86       264\n",
      "   macro avg       0.68      0.92      0.72       264\n",
      "weighted avg       0.95      0.86      0.88       264\n",
      "\n",
      "XGB_  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00       243\n",
      "\n",
      "    accuracy                           1.00       264\n",
      "   macro avg       1.00      1.00      1.00       264\n",
      "weighted avg       1.00      1.00      1.00       264\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78        21\n",
      "           1       1.00      0.95      0.97       243\n",
      "\n",
      "    accuracy                           0.95       264\n",
      "   macro avg       0.82      0.98      0.88       264\n",
      "weighted avg       0.97      0.95      0.96       264\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      1.00      0.36        13\n",
      "           1       1.00      0.83      0.91       276\n",
      "\n",
      "    accuracy                           0.84       289\n",
      "   macro avg       0.61      0.92      0.64       289\n",
      "weighted avg       0.96      0.84      0.88       289\n",
      "\n",
      "XGB_  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00       276\n",
      "\n",
      "    accuracy                           1.00       289\n",
      "   macro avg       1.00      1.00      1.00       289\n",
      "weighted avg       1.00      1.00      1.00       289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.92      0.43        13\n",
      "           1       1.00      0.89      0.94       276\n",
      "\n",
      "    accuracy                           0.89       289\n",
      "   macro avg       0.64      0.91      0.68       289\n",
      "weighted avg       0.96      0.89      0.92       289\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      1.00      0.65        25\n",
      "           1       1.00      0.87      0.93       213\n",
      "\n",
      "    accuracy                           0.89       238\n",
      "   macro avg       0.74      0.94      0.79       238\n",
      "weighted avg       0.95      0.89      0.90       238\n",
      "\n",
      "XGB_  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       1.00      1.00      1.00       213\n",
      "\n",
      "    accuracy                           1.00       238\n",
      "   macro avg       1.00      1.00      1.00       238\n",
      "weighted avg       1.00      1.00      1.00       238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.77        25\n",
      "           1       1.00      0.93      0.96       213\n",
      "\n",
      "    accuracy                           0.94       238\n",
      "   macro avg       0.81      0.96      0.87       238\n",
      "weighted avg       0.96      0.94      0.94       238\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.84      0.73        19\n",
      "           1       0.87      0.69      0.77        29\n",
      "\n",
      "    accuracy                           0.75        48\n",
      "   macro avg       0.75      0.77      0.75        48\n",
      "weighted avg       0.78      0.75      0.75        48\n",
      "\n",
      "XGB_  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        19\n",
      "           1       1.00      0.90      0.95        29\n",
      "\n",
      "    accuracy                           0.94        48\n",
      "   macro avg       0.93      0.95      0.94        48\n",
      "weighted avg       0.95      0.94      0.94        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70        19\n",
      "           1       0.80      0.83      0.81        29\n",
      "\n",
      "    accuracy                           0.77        48\n",
      "   macro avg       0.76      0.76      0.76        48\n",
      "weighted avg       0.77      0.77      0.77        48\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      1.00      0.38        10\n",
      "           1       1.00      0.89      0.94       311\n",
      "\n",
      "    accuracy                           0.90       321\n",
      "   macro avg       0.62      0.95      0.66       321\n",
      "weighted avg       0.98      0.90      0.93       321\n",
      "\n",
      "XGB_  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00       311\n",
      "\n",
      "    accuracy                           1.00       321\n",
      "   macro avg       1.00      1.00      1.00       321\n",
      "weighted avg       1.00      1.00      1.00       321\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.80      0.57        10\n",
      "           1       0.99      0.97      0.98       311\n",
      "\n",
      "    accuracy                           0.96       321\n",
      "   macro avg       0.72      0.88      0.78       321\n",
      "weighted avg       0.98      0.96      0.97       321\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.62        36\n",
      "           1       1.00      0.80      0.89       222\n",
      "\n",
      "    accuracy                           0.83       258\n",
      "   macro avg       0.72      0.90      0.75       258\n",
      "weighted avg       0.92      0.83      0.85       258\n",
      "\n",
      "XGB_  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        36\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       258\n",
      "   macro avg       1.00      1.00      1.00       258\n",
      "weighted avg       1.00      1.00      1.00       258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        36\n",
      "           1       1.00      0.92      0.96       222\n",
      "\n",
      "    accuracy                           0.93       258\n",
      "   macro avg       0.83      0.96      0.88       258\n",
      "weighted avg       0.95      0.93      0.94       258\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      1.00      0.62        14\n",
      "           1       1.00      0.71      0.83        59\n",
      "\n",
      "    accuracy                           0.77        73\n",
      "   macro avg       0.73      0.86      0.73        73\n",
      "weighted avg       0.89      0.77      0.79        73\n",
      "\n",
      "XGB_  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.76        14\n",
      "           1       0.98      0.88      0.93        59\n",
      "\n",
      "    accuracy                           0.89        73\n",
      "   macro avg       0.82      0.90      0.85        73\n",
      "weighted avg       0.92      0.89      0.90        73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.93      0.76        14\n",
      "           1       0.98      0.88      0.93        59\n",
      "\n",
      "    accuracy                           0.89        73\n",
      "   macro avg       0.82      0.90      0.85        73\n",
      "weighted avg       0.92      0.89      0.90        73\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      1.00      0.71        37\n",
      "           1       1.00      0.90      0.95       297\n",
      "\n",
      "    accuracy                           0.91       334\n",
      "   macro avg       0.78      0.95      0.83       334\n",
      "weighted avg       0.95      0.91      0.92       334\n",
      "\n",
      "XGB_  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00       297\n",
      "\n",
      "    accuracy                           1.00       334\n",
      "   macro avg       1.00      1.00      1.00       334\n",
      "weighted avg       1.00      1.00      1.00       334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.97      0.81        37\n",
      "           1       1.00      0.95      0.97       297\n",
      "\n",
      "    accuracy                           0.95       334\n",
      "   macro avg       0.84      0.96      0.89       334\n",
      "weighted avg       0.96      0.95      0.95       334\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.72        39\n",
      "           1       1.00      0.87      0.93       223\n",
      "\n",
      "    accuracy                           0.89       262\n",
      "   macro avg       0.78      0.93      0.83       262\n",
      "weighted avg       0.94      0.89      0.90       262\n",
      "\n",
      "XGB_  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       1.00      1.00      1.00       223\n",
      "\n",
      "    accuracy                           1.00       262\n",
      "   macro avg       1.00      1.00      1.00       262\n",
      "weighted avg       1.00      1.00      1.00       262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.87        39\n",
      "           1       1.00      0.95      0.97       223\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.88      0.97      0.92       262\n",
      "weighted avg       0.96      0.95      0.96       262\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.50      0.17         2\n",
      "           1       0.98      0.84      0.90        55\n",
      "\n",
      "    accuracy                           0.82        57\n",
      "   macro avg       0.54      0.67      0.53        57\n",
      "weighted avg       0.95      0.82      0.88        57\n",
      "\n",
      "XGB_  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00        55\n",
      "\n",
      "    accuracy                           1.00        57\n",
      "   macro avg       1.00      1.00      1.00        57\n",
      "weighted avg       1.00      1.00      1.00        57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.50      0.22         2\n",
      "           1       0.98      0.89      0.93        55\n",
      "\n",
      "    accuracy                           0.88        57\n",
      "   macro avg       0.56      0.70      0.58        57\n",
      "weighted avg       0.95      0.88      0.91        57\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      1.00      0.44         7\n",
      "           1       1.00      0.81      0.89        94\n",
      "\n",
      "    accuracy                           0.82       101\n",
      "   macro avg       0.64      0.90      0.67       101\n",
      "weighted avg       0.95      0.82      0.86       101\n",
      "\n",
      "XGB_  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00        94\n",
      "\n",
      "    accuracy                           1.00       101\n",
      "   macro avg       1.00      1.00      1.00       101\n",
      "weighted avg       1.00      1.00      1.00       101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.86      0.63         7\n",
      "           1       0.99      0.94      0.96        94\n",
      "\n",
      "    accuracy                           0.93       101\n",
      "   macro avg       0.74      0.90      0.80       101\n",
      "weighted avg       0.95      0.93      0.94       101\n",
      "\n",
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43', 'anger_time_lag', 'disgust_time_lag',\n",
      "       'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag',\n",
      "       'surprise_time_lag', 'neutral_time_lag', 'AU01_time_lag',\n",
      "       'AU02_time_lag', 'AU04_time_lag', 'AU05_time_lag', 'AU06_time_lag',\n",
      "       'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU11_time_lag',\n",
      "       'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU17_time_lag',\n",
      "       'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag',\n",
      "       'AU26_time_lag', 'AU28_time_lag', 'AU43_time_lag', 'anger_vel',\n",
      "       'disgust_vel', 'fear_vel', 'happiness_vel', 'sadness_vel',\n",
      "       'surprise_vel', 'neutral_vel', 'AU01_vel', 'AU02_vel', 'AU04_vel',\n",
      "       'AU05_vel', 'AU06_vel', 'AU07_vel', 'AU09_vel', 'AU10_vel', 'AU11_vel',\n",
      "       'AU12_vel', 'AU14_vel', 'AU15_vel', 'AU17_vel', 'AU20_vel', 'AU23_vel',\n",
      "       'AU24_vel', 'AU25_vel', 'AU26_vel', 'AU28_vel', 'AU43_vel'],\n",
      "      dtype='object')\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.97      0.71        74\n",
      "           1       0.98      0.68      0.80       177\n",
      "\n",
      "    accuracy                           0.76       251\n",
      "   macro avg       0.77      0.83      0.76       251\n",
      "weighted avg       0.86      0.76      0.78       251\n",
      "\n",
      "XGB_  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        74\n",
      "           1       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       251\n",
      "   macro avg       1.00      1.00      1.00       251\n",
      "weighted avg       1.00      1.00      1.00       251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      1.00      0.81        74\n",
      "           1       1.00      0.80      0.89       177\n",
      "\n",
      "    accuracy                           0.86       251\n",
      "   macro avg       0.84      0.90      0.85       251\n",
      "weighted avg       0.91      0.86      0.87       251\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        95\n",
      "           1       1.00      0.77      0.87       115\n",
      "\n",
      "    accuracy                           0.88       210\n",
      "   macro avg       0.89      0.89      0.88       210\n",
      "weighted avg       0.90      0.88      0.88       210\n",
      "\n",
      "XGB_  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        95\n",
      "           1       1.00      1.00      1.00       115\n",
      "\n",
      "    accuracy                           1.00       210\n",
      "   macro avg       1.00      1.00      1.00       210\n",
      "weighted avg       1.00      1.00      1.00       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.99      0.90        95\n",
      "           1       0.99      0.82      0.90       115\n",
      "\n",
      "    accuracy                           0.90       210\n",
      "   macro avg       0.90      0.90      0.90       210\n",
      "weighted avg       0.91      0.90      0.90       210\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.98      0.72        55\n",
      "           1       0.99      0.73      0.84       151\n",
      "\n",
      "    accuracy                           0.80       206\n",
      "   macro avg       0.78      0.86      0.78       206\n",
      "weighted avg       0.88      0.80      0.81       206\n",
      "\n",
      "XGB_  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        55\n",
      "           1       1.00      1.00      1.00       151\n",
      "\n",
      "    accuracy                           1.00       206\n",
      "   macro avg       1.00      1.00      1.00       206\n",
      "weighted avg       1.00      1.00      1.00       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        55\n",
      "           1       1.00      0.86      0.93       151\n",
      "\n",
      "    accuracy                           0.90       206\n",
      "   macro avg       0.86      0.93      0.88       206\n",
      "weighted avg       0.93      0.90      0.90       206\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      1.00      0.73        34\n",
      "           1       1.00      0.81      0.89       131\n",
      "\n",
      "    accuracy                           0.85       165\n",
      "   macro avg       0.79      0.90      0.81       165\n",
      "weighted avg       0.91      0.85      0.86       165\n",
      "\n",
      "XGB_  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       1.00      1.00      1.00       131\n",
      "\n",
      "    accuracy                           1.00       165\n",
      "   macro avg       1.00      1.00      1.00       165\n",
      "weighted avg       1.00      1.00      1.00       165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        34\n",
      "           1       1.00      0.87      0.93       131\n",
      "\n",
      "    accuracy                           0.90       165\n",
      "   macro avg       0.83      0.94      0.87       165\n",
      "weighted avg       0.93      0.90      0.90       165\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.99      0.73        77\n",
      "           1       0.99      0.57      0.72       129\n",
      "\n",
      "    accuracy                           0.72       206\n",
      "   macro avg       0.78      0.78      0.72       206\n",
      "weighted avg       0.83      0.72      0.72       206\n",
      "\n",
      "XGB_  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        77\n",
      "           1       1.00      1.00      1.00       129\n",
      "\n",
      "    accuracy                           1.00       206\n",
      "   macro avg       1.00      1.00      1.00       206\n",
      "weighted avg       1.00      1.00      1.00       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.89        77\n",
      "           1       1.00      0.84      0.92       129\n",
      "\n",
      "    accuracy                           0.90       206\n",
      "   macro avg       0.90      0.92      0.90       206\n",
      "weighted avg       0.92      0.90      0.90       206\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.96      0.80        68\n",
      "           1       0.98      0.84      0.91       182\n",
      "\n",
      "    accuracy                           0.87       250\n",
      "   macro avg       0.84      0.90      0.85       250\n",
      "weighted avg       0.90      0.87      0.88       250\n",
      "\n",
      "XGB_  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        68\n",
      "           1       1.00      1.00      1.00       182\n",
      "\n",
      "    accuracy                           1.00       250\n",
      "   macro avg       1.00      1.00      1.00       250\n",
      "weighted avg       1.00      1.00      1.00       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      1.00      0.86        68\n",
      "           1       1.00      0.88      0.94       182\n",
      "\n",
      "    accuracy                           0.91       250\n",
      "   macro avg       0.88      0.94      0.90       250\n",
      "weighted avg       0.93      0.91      0.92       250\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      1.00      0.75        58\n",
      "           1       1.00      0.73      0.84       145\n",
      "\n",
      "    accuracy                           0.81       203\n",
      "   macro avg       0.80      0.87      0.80       203\n",
      "weighted avg       0.89      0.81      0.82       203\n",
      "\n",
      "XGB_  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "           1       1.00      1.00      1.00       145\n",
      "\n",
      "    accuracy                           1.00       203\n",
      "   macro avg       1.00      1.00      1.00       203\n",
      "weighted avg       1.00      1.00      1.00       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        58\n",
      "           1       1.00      0.85      0.92       145\n",
      "\n",
      "    accuracy                           0.89       203\n",
      "   macro avg       0.86      0.92      0.88       203\n",
      "weighted avg       0.92      0.89      0.90       203\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.98      0.83        66\n",
      "           1       0.99      0.82      0.90       142\n",
      "\n",
      "    accuracy                           0.87       208\n",
      "   macro avg       0.85      0.90      0.86       208\n",
      "weighted avg       0.90      0.87      0.87       208\n",
      "\n",
      "XGB_  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        66\n",
      "           1       1.00      1.00      1.00       142\n",
      "\n",
      "    accuracy                           1.00       208\n",
      "   macro avg       1.00      1.00      1.00       208\n",
      "weighted avg       1.00      1.00      1.00       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.98      0.87        66\n",
      "           1       0.99      0.87      0.93       142\n",
      "\n",
      "    accuracy                           0.91       208\n",
      "   macro avg       0.89      0.93      0.90       208\n",
      "weighted avg       0.93      0.91      0.91       208\n",
      "\n",
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43', 'anger_time_lag', 'disgust_time_lag',\n",
      "       'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag',\n",
      "       'surprise_time_lag', 'neutral_time_lag', 'AU01_time_lag',\n",
      "       'AU02_time_lag', 'AU04_time_lag', 'AU05_time_lag', 'AU06_time_lag',\n",
      "       'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU11_time_lag',\n",
      "       'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU17_time_lag',\n",
      "       'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag',\n",
      "       'AU26_time_lag', 'AU28_time_lag', 'AU43_time_lag', 'anger_vel',\n",
      "       'disgust_vel', 'fear_vel', 'happiness_vel', 'sadness_vel',\n",
      "       'surprise_vel', 'neutral_vel', 'AU01_vel', 'AU02_vel', 'AU04_vel',\n",
      "       'AU05_vel', 'AU06_vel', 'AU07_vel', 'AU09_vel', 'AU10_vel', 'AU11_vel',\n",
      "       'AU12_vel', 'AU14_vel', 'AU15_vel', 'AU17_vel', 'AU20_vel', 'AU23_vel',\n",
      "       'AU24_vel', 'AU25_vel', 'AU26_vel', 'AU28_vel', 'AU43_vel'],\n",
      "      dtype='object')\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.91      0.80        33\n",
      "           1       0.86      0.61      0.72        31\n",
      "\n",
      "    accuracy                           0.77        64\n",
      "   macro avg       0.79      0.76      0.76        64\n",
      "weighted avg       0.79      0.77      0.76        64\n",
      "\n",
      "XGB_  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        33\n",
      "           1       1.00      0.71      0.83        31\n",
      "\n",
      "    accuracy                           0.86        64\n",
      "   macro avg       0.89      0.85      0.86        64\n",
      "weighted avg       0.89      0.86      0.86        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      1.00      0.93        33\n",
      "           1       1.00      0.84      0.91        31\n",
      "\n",
      "    accuracy                           0.92        64\n",
      "   macro avg       0.93      0.92      0.92        64\n",
      "weighted avg       0.93      0.92      0.92        64\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.98      0.84        45\n",
      "           1       0.98      0.72      0.83        58\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.86      0.85      0.83       103\n",
      "weighted avg       0.87      0.83      0.83       103\n",
      "\n",
      "XGB_  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.96      0.83        45\n",
      "           1       0.96      0.74      0.83        58\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.85      0.85      0.83       103\n",
      "weighted avg       0.86      0.83      0.83       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        45\n",
      "           1       1.00      0.79      0.88        58\n",
      "\n",
      "    accuracy                           0.88       103\n",
      "   macro avg       0.89      0.90      0.88       103\n",
      "weighted avg       0.91      0.88      0.88       103\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.98      0.93        50\n",
      "           1       0.98      0.88      0.92        49\n",
      "\n",
      "    accuracy                           0.93        99\n",
      "   macro avg       0.93      0.93      0.93        99\n",
      "weighted avg       0.93      0.93      0.93        99\n",
      "\n",
      "XGB_  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00        49\n",
      "\n",
      "    accuracy                           1.00        99\n",
      "   macro avg       1.00      1.00      1.00        99\n",
      "weighted avg       1.00      1.00      1.00        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        50\n",
      "           1       1.00      0.98      0.99        49\n",
      "\n",
      "    accuracy                           0.99        99\n",
      "   macro avg       0.99      0.99      0.99        99\n",
      "weighted avg       0.99      0.99      0.99        99\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.72        39\n",
      "           1       0.95      0.81      0.88       113\n",
      "\n",
      "    accuracy                           0.83       152\n",
      "   macro avg       0.78      0.84      0.80       152\n",
      "weighted avg       0.86      0.83      0.84       152\n",
      "\n",
      "XGB_  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        39\n",
      "           1       1.00      0.99      1.00       113\n",
      "\n",
      "    accuracy                           0.99       152\n",
      "   macro avg       0.99      1.00      0.99       152\n",
      "weighted avg       0.99      0.99      0.99       152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.97      0.82        39\n",
      "           1       0.99      0.86      0.92       113\n",
      "\n",
      "    accuracy                           0.89       152\n",
      "   macro avg       0.85      0.92      0.87       152\n",
      "weighted avg       0.92      0.89      0.89       152\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.95      0.61        21\n",
      "           1       0.98      0.70      0.82        83\n",
      "\n",
      "    accuracy                           0.75       104\n",
      "   macro avg       0.71      0.83      0.71       104\n",
      "weighted avg       0.87      0.75      0.77       104\n",
      "\n",
      "XGB_  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93        21\n",
      "           1       1.00      0.96      0.98        83\n",
      "\n",
      "    accuracy                           0.97       104\n",
      "   macro avg       0.94      0.98      0.96       104\n",
      "weighted avg       0.97      0.97      0.97       104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79        21\n",
      "           1       1.00      0.87      0.93        83\n",
      "\n",
      "    accuracy                           0.89       104\n",
      "   macro avg       0.83      0.93      0.86       104\n",
      "weighted avg       0.93      0.89      0.90       104\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.98      0.88        46\n",
      "           1       0.98      0.82      0.89        61\n",
      "\n",
      "    accuracy                           0.89       107\n",
      "   macro avg       0.89      0.90      0.89       107\n",
      "weighted avg       0.90      0.89      0.89       107\n",
      "\n",
      "XGB_  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        46\n",
      "           1       1.00      1.00      1.00        61\n",
      "\n",
      "    accuracy                           1.00       107\n",
      "   macro avg       1.00      1.00      1.00       107\n",
      "weighted avg       1.00      1.00      1.00       107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        46\n",
      "           1       1.00      0.85      0.92        61\n",
      "\n",
      "    accuracy                           0.92       107\n",
      "   macro avg       0.92      0.93      0.92       107\n",
      "weighted avg       0.93      0.92      0.92       107\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98        70\n",
      "           1       0.95      0.91      0.93        23\n",
      "\n",
      "    accuracy                           0.97        93\n",
      "   macro avg       0.96      0.95      0.96        93\n",
      "weighted avg       0.97      0.97      0.97        93\n",
      "\n",
      "XGB_  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        70\n",
      "           1       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00        93\n",
      "   macro avg       1.00      1.00      1.00        93\n",
      "weighted avg       1.00      1.00      1.00        93\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99        70\n",
      "           1       0.92      1.00      0.96        23\n",
      "\n",
      "    accuracy                           0.98        93\n",
      "   macro avg       0.96      0.99      0.97        93\n",
      "weighted avg       0.98      0.98      0.98        93\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        48\n",
      "           1       1.00      0.96      0.98       106\n",
      "\n",
      "    accuracy                           0.97       154\n",
      "   macro avg       0.96      0.98      0.97       154\n",
      "weighted avg       0.98      0.97      0.97       154\n",
      "\n",
      "XGB_  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00       106\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.91        48\n",
      "           1       1.00      0.91      0.95       106\n",
      "\n",
      "    accuracy                           0.94       154\n",
      "   macro avg       0.91      0.95      0.93       154\n",
      "weighted avg       0.95      0.94      0.94       154\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96        81\n",
      "           1       0.98      0.91      0.95        58\n",
      "\n",
      "    accuracy                           0.96       139\n",
      "   macro avg       0.96      0.95      0.96       139\n",
      "weighted avg       0.96      0.96      0.96       139\n",
      "\n",
      "XGB_  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        58\n",
      "\n",
      "    accuracy                           1.00       139\n",
      "   macro avg       1.00      1.00      1.00       139\n",
      "weighted avg       1.00      1.00      1.00       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        81\n",
      "           1       0.98      0.90      0.94        58\n",
      "\n",
      "    accuracy                           0.95       139\n",
      "   macro avg       0.96      0.94      0.95       139\n",
      "weighted avg       0.95      0.95      0.95       139\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        63\n",
      "           1       0.86      0.80      0.83        15\n",
      "\n",
      "    accuracy                           0.94        78\n",
      "   macro avg       0.91      0.88      0.89        78\n",
      "weighted avg       0.93      0.94      0.94        78\n",
      "\n",
      "XGB_  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        63\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        78\n",
      "   macro avg       1.00      1.00      1.00        78\n",
      "weighted avg       1.00      1.00      1.00        78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.98        63\n",
      "           1       0.93      0.87      0.90        15\n",
      "\n",
      "    accuracy                           0.96        78\n",
      "   macro avg       0.95      0.93      0.94        78\n",
      "weighted avg       0.96      0.96      0.96        78\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      1.00      0.94        51\n",
      "           1       1.00      0.82      0.90        34\n",
      "\n",
      "    accuracy                           0.93        85\n",
      "   macro avg       0.95      0.91      0.92        85\n",
      "weighted avg       0.94      0.93      0.93        85\n",
      "\n",
      "XGB_  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           1.00        85\n",
      "   macro avg       1.00      1.00      1.00        85\n",
      "weighted avg       1.00      1.00      1.00        85\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        51\n",
      "           1       1.00      0.85      0.92        34\n",
      "\n",
      "    accuracy                           0.94        85\n",
      "   macro avg       0.96      0.93      0.94        85\n",
      "weighted avg       0.95      0.94      0.94        85\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.97      0.90        38\n",
      "           1       0.97      0.80      0.88        35\n",
      "\n",
      "    accuracy                           0.89        73\n",
      "   macro avg       0.90      0.89      0.89        73\n",
      "weighted avg       0.90      0.89      0.89        73\n",
      "\n",
      "XGB_  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97        38\n",
      "           1       1.00      0.94      0.97        35\n",
      "\n",
      "    accuracy                           0.97        73\n",
      "   macro avg       0.97      0.97      0.97        73\n",
      "weighted avg       0.97      0.97      0.97        73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.93        38\n",
      "           1       1.00      0.83      0.91        35\n",
      "\n",
      "    accuracy                           0.92        73\n",
      "   macro avg       0.93      0.91      0.92        73\n",
      "weighted avg       0.93      0.92      0.92        73\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.27      1.00      0.42         4\n",
      "           1       1.00      0.81      0.90        59\n",
      "\n",
      "    accuracy                           0.83        63\n",
      "   macro avg       0.63      0.91      0.66        63\n",
      "weighted avg       0.95      0.83      0.87        63\n",
      "\n",
      "XGB_  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         4\n",
      "           1       1.00      0.98      0.99        59\n",
      "\n",
      "    accuracy                           0.98        63\n",
      "   macro avg       0.90      0.99      0.94        63\n",
      "weighted avg       0.99      0.98      0.98        63\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         4\n",
      "           1       1.00      0.98      0.99        59\n",
      "\n",
      "    accuracy                           0.98        63\n",
      "   macro avg       0.90      0.99      0.94        63\n",
      "weighted avg       0.99      0.98      0.98        63\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n",
      "XGB_  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         8\n",
      "           1       1.00      0.60      0.75         5\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.90      0.80      0.82        13\n",
      "weighted avg       0.88      0.85      0.84        13\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        37\n",
      "           1       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.95        43\n",
      "   macro avg       0.90      0.90      0.90        43\n",
      "weighted avg       0.95      0.95      0.95        43\n",
      "\n",
      "XGB_  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        37\n",
      "           1       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           1.00        43\n",
      "   macro avg       1.00      1.00      1.00        43\n",
      "weighted avg       1.00      1.00      1.00        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        37\n",
      "           1       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.93        43\n",
      "   macro avg       0.96      0.75      0.81        43\n",
      "weighted avg       0.94      0.93      0.92        43\n",
      "\n",
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43', 'anger_time_lag', 'disgust_time_lag',\n",
      "       'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag',\n",
      "       'surprise_time_lag', 'neutral_time_lag', 'AU01_time_lag',\n",
      "       'AU02_time_lag', 'AU04_time_lag', 'AU05_time_lag', 'AU06_time_lag',\n",
      "       'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU11_time_lag',\n",
      "       'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU17_time_lag',\n",
      "       'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag',\n",
      "       'AU26_time_lag', 'AU28_time_lag', 'AU43_time_lag', 'anger_vel',\n",
      "       'disgust_vel', 'fear_vel', 'happiness_vel', 'sadness_vel',\n",
      "       'surprise_vel', 'neutral_vel', 'AU01_vel', 'AU02_vel', 'AU04_vel',\n",
      "       'AU05_vel', 'AU06_vel', 'AU07_vel', 'AU09_vel', 'AU10_vel', 'AU11_vel',\n",
      "       'AU12_vel', 'AU14_vel', 'AU15_vel', 'AU17_vel', 'AU20_vel', 'AU23_vel',\n",
      "       'AU24_vel', 'AU25_vel', 'AU26_vel', 'AU28_vel', 'AU43_vel'],\n",
      "      dtype='object')\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.25      0.10         4\n",
      "           1       0.98      0.92      0.95       199\n",
      "\n",
      "    accuracy                           0.91       203\n",
      "   macro avg       0.52      0.58      0.52       203\n",
      "weighted avg       0.97      0.91      0.93       203\n",
      "\n",
      "XGB_  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.75      0.07         4\n",
      "           1       0.99      0.58      0.73       199\n",
      "\n",
      "    accuracy                           0.58       203\n",
      "   macro avg       0.51      0.66      0.40       203\n",
      "weighted avg       0.97      0.58      0.72       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      1.00      0.10         4\n",
      "           1       1.00      0.63      0.77       199\n",
      "\n",
      "    accuracy                           0.64       203\n",
      "   macro avg       0.53      0.81      0.43       203\n",
      "weighted avg       0.98      0.64      0.76       203\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.33      0.07         6\n",
      "           1       0.98      0.83      0.90       276\n",
      "\n",
      "    accuracy                           0.82       282\n",
      "   macro avg       0.51      0.58      0.49       282\n",
      "weighted avg       0.96      0.82      0.88       282\n",
      "\n",
      "XGB_  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.67      0.07         6\n",
      "           1       0.99      0.62      0.76       276\n",
      "\n",
      "    accuracy                           0.62       282\n",
      "   macro avg       0.51      0.64      0.42       282\n",
      "weighted avg       0.97      0.62      0.75       282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.33      0.03         6\n",
      "           1       0.98      0.61      0.75       276\n",
      "\n",
      "    accuracy                           0.60       282\n",
      "   macro avg       0.50      0.47      0.39       282\n",
      "weighted avg       0.96      0.60      0.73       282\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.67      0.36        12\n",
      "           1       0.98      0.88      0.93       213\n",
      "\n",
      "    accuracy                           0.87       225\n",
      "   macro avg       0.61      0.77      0.64       225\n",
      "weighted avg       0.94      0.87      0.90       225\n",
      "\n",
      "XGB_  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       1.00      1.00      1.00       213\n",
      "\n",
      "    accuracy                           1.00       225\n",
      "   macro avg       0.96      1.00      0.98       225\n",
      "weighted avg       1.00      1.00      1.00       225\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.08      0.17      0.11        12\n",
      "           1       0.95      0.90      0.92       213\n",
      "\n",
      "    accuracy                           0.86       225\n",
      "   macro avg       0.52      0.53      0.52       225\n",
      "weighted avg       0.90      0.86      0.88       225\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      1.00      0.07         2\n",
      "           1       1.00      0.80      0.89       266\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.52      0.90      0.48       268\n",
      "weighted avg       0.99      0.80      0.88       268\n",
      "\n",
      "XGB_  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80         2\n",
      "           1       1.00      1.00      1.00       266\n",
      "\n",
      "    accuracy                           1.00       268\n",
      "   macro avg       0.83      1.00      0.90       268\n",
      "weighted avg       1.00      1.00      1.00       268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.50      0.06         2\n",
      "           1       1.00      0.89      0.94       266\n",
      "\n",
      "    accuracy                           0.89       268\n",
      "   macro avg       0.51      0.70      0.50       268\n",
      "weighted avg       0.99      0.89      0.93       268\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.25      0.08         4\n",
      "           1       0.98      0.87      0.92       166\n",
      "\n",
      "    accuracy                           0.86       170\n",
      "   macro avg       0.51      0.56      0.50       170\n",
      "weighted avg       0.96      0.86      0.90       170\n",
      "\n",
      "XGB_  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       166\n",
      "\n",
      "    accuracy                           1.00       170\n",
      "   macro avg       1.00      1.00      1.00       170\n",
      "weighted avg       1.00      1.00      1.00       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.97      0.90      0.94       166\n",
      "\n",
      "    accuracy                           0.88       170\n",
      "   macro avg       0.49      0.45      0.47       170\n",
      "weighted avg       0.95      0.88      0.92       170\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.75      0.22         4\n",
      "           1       0.99      0.79      0.88        94\n",
      "\n",
      "    accuracy                           0.79        98\n",
      "   macro avg       0.56      0.77      0.55        98\n",
      "weighted avg       0.95      0.79      0.85        98\n",
      "\n",
      "XGB_  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        94\n",
      "\n",
      "    accuracy                           1.00        98\n",
      "   macro avg       1.00      1.00      1.00        98\n",
      "weighted avg       1.00      1.00      1.00        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.75      0.38         4\n",
      "           1       0.99      0.90      0.94        94\n",
      "\n",
      "    accuracy                           0.90        98\n",
      "   macro avg       0.62      0.83      0.66        98\n",
      "weighted avg       0.96      0.90      0.92        98\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      1.00      0.05         1\n",
      "           1       1.00      0.87      0.93       311\n",
      "\n",
      "    accuracy                           0.88       312\n",
      "   macro avg       0.51      0.94      0.49       312\n",
      "weighted avg       1.00      0.88      0.93       312\n",
      "\n",
      "XGB_  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00       311\n",
      "\n",
      "    accuracy                           1.00       312\n",
      "   macro avg       1.00      1.00      1.00       312\n",
      "weighted avg       1.00      1.00      1.00       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.95      0.97       311\n",
      "\n",
      "    accuracy                           0.95       312\n",
      "   macro avg       0.50      0.48      0.49       312\n",
      "weighted avg       0.99      0.95      0.97       312\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.07      0.50      0.13         4\n",
      "           1       0.99      0.86      0.92       177\n",
      "\n",
      "    accuracy                           0.85       181\n",
      "   macro avg       0.53      0.68      0.52       181\n",
      "weighted avg       0.97      0.85      0.90       181\n",
      "\n",
      "XGB_  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       181\n",
      "   macro avg       1.00      1.00      1.00       181\n",
      "weighted avg       1.00      1.00      1.00       181\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.50      0.16         4\n",
      "           1       0.99      0.89      0.94       177\n",
      "\n",
      "    accuracy                           0.88       181\n",
      "   macro avg       0.54      0.70      0.55       181\n",
      "weighted avg       0.97      0.88      0.92       181\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.60      0.10         5\n",
      "           1       0.99      0.81      0.89       287\n",
      "\n",
      "    accuracy                           0.80       292\n",
      "   macro avg       0.52      0.70      0.49       292\n",
      "weighted avg       0.98      0.80      0.88       292\n",
      "\n",
      "XGB_  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       292\n",
      "   macro avg       1.00      1.00      1.00       292\n",
      "weighted avg       1.00      1.00      1.00       292\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.40      0.09         5\n",
      "           1       0.99      0.87      0.92       287\n",
      "\n",
      "    accuracy                           0.86       292\n",
      "   macro avg       0.52      0.63      0.51       292\n",
      "weighted avg       0.97      0.86      0.91       292\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.99      0.80      0.89       243\n",
      "\n",
      "    accuracy                           0.80       244\n",
      "   macro avg       0.50      0.40      0.44       244\n",
      "weighted avg       0.99      0.80      0.88       244\n",
      "\n",
      "XGB_  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00       243\n",
      "\n",
      "    accuracy                           1.00       244\n",
      "   macro avg       1.00      1.00      1.00       244\n",
      "weighted avg       1.00      1.00      1.00       244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.89      0.94       243\n",
      "\n",
      "    accuracy                           0.89       244\n",
      "   macro avg       0.50      0.45      0.47       244\n",
      "weighted avg       0.99      0.89      0.94       244\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.86      0.50         7\n",
      "           1       0.99      0.89      0.94       104\n",
      "\n",
      "    accuracy                           0.89       111\n",
      "   macro avg       0.67      0.88      0.72       111\n",
      "weighted avg       0.95      0.89      0.91       111\n",
      "\n",
      "XGB_  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00       104\n",
      "\n",
      "    accuracy                           1.00       111\n",
      "   macro avg       1.00      1.00      1.00       111\n",
      "weighted avg       1.00      1.00      1.00       111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.29      0.36         7\n",
      "           1       0.95      0.98      0.97       104\n",
      "\n",
      "    accuracy                           0.94       111\n",
      "   macro avg       0.73      0.63      0.67       111\n",
      "weighted avg       0.92      0.94      0.93       111\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.90      0.60        10\n",
      "           1       0.98      0.80      0.88        55\n",
      "\n",
      "    accuracy                           0.82        65\n",
      "   macro avg       0.71      0.85      0.74        65\n",
      "weighted avg       0.90      0.82      0.84        65\n",
      "\n",
      "XGB_  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00        55\n",
      "\n",
      "    accuracy                           1.00        65\n",
      "   macro avg       1.00      1.00      1.00        65\n",
      "weighted avg       1.00      1.00      1.00        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.40      0.42        10\n",
      "           1       0.89      0.91      0.90        55\n",
      "\n",
      "    accuracy                           0.83        65\n",
      "   macro avg       0.67      0.65      0.66        65\n",
      "weighted avg       0.82      0.83      0.83        65\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,\\\n",
    "f1_score,precision_score,recall_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "k=1\n",
    "\n",
    "# f1=[]\n",
    "# accuracy=[]\n",
    "# precision=[]\n",
    "# recall=[]\n",
    "# roc_auc=[]\n",
    "# model=[]\n",
    "# testPersons=[['P31.csv','P19.csv'],\n",
    "#             ['P14.csv','P24.csv'],\n",
    "#             ['P13.csv','P30.csv'],\n",
    "#             ['P31.csv','P18.csv'],\n",
    "#             ['P08.csv','P24.csv']]\n",
    "sm=SMOTE()\n",
    "j=True\n",
    "for i in range(len(testPersons)):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # Scramble\n",
    "    random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "    only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "    only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "    both = [key for key, value in depression.items() if len(value) == 2]\n",
    "    # testPerson = ['08'] + ['24']#['16','08'] + ['24','30']\n",
    "#     testPerson = [str(random.choice(only0).split('.')[0].split('P')[1])] \\\n",
    "#     + [str(random.choice(only1).split('.')[0].split('P')[1])]\n",
    "#     # testPerson = [13,17]\n",
    "#     allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "#     trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "#     testPerson = random.sample(only0,k) \\\n",
    "#     + random.sample(only1,k)\n",
    "    testPerson=testPersons[i]\n",
    "    # testPerson = [13,17]\n",
    "    allPerson = contestants\n",
    "    trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "\n",
    "#     # Merge train data and shuffle\n",
    "#     train_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in trainPerson]\n",
    "#     merged_train = pd.concat(train_list, ignore_index=True)\n",
    "#     shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "#     test_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in testPerson]\n",
    "#     merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_test = shuffled_test.drop([ 'img_name'], axis = 1)\n",
    "    for num in trainPerson:\n",
    "        train = pd.read_csv(f'{base_path}/{num}')\n",
    "        train=train.set_index('img_name')\n",
    "        duplicate_rows = train.index.duplicated()\n",
    "        train=train.loc[~duplicate_rows,:]\n",
    "        train_addata=train.copy()\n",
    "        train=train.drop('level',axis=1)\n",
    "        add_data=train.copy()\n",
    "        \n",
    "        add_data=add_data.shift(1)\n",
    "        add_data.columns=[i.split('_')[0]+'_time_lag' for i in train.columns]\n",
    "        \n",
    "#         add_data2=add_data.shift(2)\n",
    "#         add_data2.columns=[i+'_prev2' for i in add_data.columns]\n",
    "\n",
    "        add_vel=add_data.diff(1)\n",
    "        add_vel.columns=[i+'_vel' for i in train.columns]\n",
    "        \n",
    "#         duplicate_rows = add_data.index.duplicated()\n",
    "        train_=pd.concat([train_addata,add_data,add_vel],axis=1)\n",
    "        train_=train_.reset_index()\n",
    "        train_=train_.dropna()\n",
    "#         train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "        train_list.append(train_)#train_ for addition data\n",
    "    \n",
    "    merged_train = pd.concat(train_list, ignore_index=True)\n",
    "    shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    try:\n",
    "        shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "    except:pass   \n",
    "\n",
    "    for num in testPerson:\n",
    "        test = pd.read_csv(f'{base_path}/{num}')\n",
    "        test=test.set_index('img_name')\n",
    "        \n",
    "        \n",
    "        duplicate_rows = test.index.duplicated()\n",
    "        test=test.loc[~duplicate_rows,:]\n",
    "        test_add=test.copy()\n",
    "        test=test.drop('level',axis=1)\n",
    "        add_data=test.copy()\n",
    "        \n",
    "        add_data=add_data.shift(1)\n",
    "        add_data.columns=[i.split('_')[0]+'_time_lag' for i in test.columns]\n",
    "\n",
    "        add_vel=add_data.diff(1)\n",
    "        add_vel.columns=[i+'_vel' for i in test.columns]\n",
    "        \n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        test_=pd.concat([test_add,add_data,add_vel],axis=1)\n",
    "        test_=test_.reset_index()\n",
    "        test_=test_.dropna()\n",
    "#         test_=test_.reset_index(drop=False)\n",
    "        test_list.append(test_)#test_ for addition data\n",
    "    merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     print(merged_test)\n",
    "    shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    try:\n",
    "#         shuffled_test=shuffled_test.reset_index(drop=False)\n",
    "        shuffled_test['ts']=shuffled_test['img_name'].apply(lambda x :int(int(x.split('_')[-1][:-4])/1000))\n",
    "        shuffled_test['ts']=shuffled_test['ts'].apply(lambda x: datetime.datetime.fromtimestamp(x).date())\n",
    "        shuffled_test = shuffled_test.drop(['img_name'], axis = 1)\n",
    "        \n",
    "    except Exception as e:print(e)\n",
    "    print(X_train.columns)\n",
    "    for k in shuffled_test['ts'].unique():\n",
    "        add_train_from_test1,shuffled_test1=shuffled_test[shuffled_test['ts']<k],shuffled_test[shuffled_test['ts']==k]\n",
    "    #     add_train_from_test,shuffled_test=train_test_split(shuffled_test,test_size=0.5)\n",
    "        add_train_from_test1,shuffled_test1=add_train_from_test1.drop('ts',axis=1),shuffled_test1.drop('ts',axis=1)\n",
    "        shuffled_train=pd.concat([add_train_from_test1,shuffled_train],axis=0)\n",
    "\n",
    "        X_train, y_train = shuffled_train.drop('level', axis = 1), shuffled_train['level']\n",
    "        \n",
    "        X_test, y_test = shuffled_test1.drop('level', axis = 1), shuffled_test1['level']\n",
    "        y_train =y_train.astype('category')\n",
    "        y_test =y_test.astype('category')\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        X_train=pd.DataFrame(X_train,columns=X_train.columns)\n",
    "        X_test=X_test[X_train.columns]\n",
    "        if shuffled_test1['level'].nunique()<2:\n",
    "            continue\n",
    "        # y_train=pd.DataFrame(y_train,columns=y_test.columns)\n",
    "        # Print train test contestants\n",
    "        print(\"Train: \", trainPerson)\n",
    "        print(\"Test: \", testPerson)\n",
    "        if j:\n",
    "            print(X_train.columns.T)\n",
    "            j=False\n",
    "\n",
    "        # Logistic Regression\n",
    "        # log_reg = LogisticRegression(max_iter=10000)\n",
    "        # log_reg.fit(X_train, y_train)\n",
    "        # log_reg_pred = log_reg.predict(X_test)\n",
    "        # log_reg_acc = classification_report(y_test, log_reg_pred)\n",
    "        # print(f\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "\n",
    "        # K-Nearest Neighbors (KNN)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, leaf_size=70)\n",
    "        knn.fit(X_train, y_train)\n",
    "        knn_pred = knn.predict(X_test)\n",
    "        knn_rp = classification_report(y_test, knn_pred)\n",
    "        accuracy.append(accuracy_score(y_test, knn_pred))\n",
    "        f1.append(f1_score(y_test, knn_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, knn_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, knn_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, knn_pred))\n",
    "        model.append('KNN_tlsd')\n",
    "        print('knn ',i,'    ', k)\n",
    "        print(knn_rp)\n",
    "\n",
    "\n",
    "    #     # Support Vector Machine (SVM)\n",
    "        svm =  XGBClassifier(n_estimators=100)#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "        svm.fit(X_train, y_train)\n",
    "        svm_pred = svm.predict(X_test)\n",
    "        svm_rp = classification_report(y_test, svm_pred)\n",
    "        accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "        f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "        model.append('XGB_tlsd')\n",
    "        print('XGB_ ',i,'    ', k)\n",
    "        print(svm_rp)\n",
    "\n",
    "\n",
    "        svm =  LogisticRegression()#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "        svm.fit(X_train, y_train)\n",
    "        svm_pred = svm.predict(X_test)\n",
    "        svm_rp = classification_report(y_test, svm_pred)\n",
    "        accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "        f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "        model.append('LR_tlsd')\n",
    "        print('LR_ ',i,'    ', k)\n",
    "        print(svm_rp)\n",
    "\n",
    "#     # Random Forest Classifier\n",
    "#     rf = RandomForestClassifier(n_estimators=1000)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     rf_pred = rf.predict(X_test)\n",
    "#     rf_acc = classification_report(y_test, rf_pred)\n",
    "#     print('rf ',i)\n",
    "#     print(rf_acc)\n",
    "\n",
    "#     xgb = XGBClassifier(n_estimators=1000)\n",
    "#     xgb.fit(X_train, y_train)\n",
    "#     xgb_pred = xgb.predict(X_test)\n",
    "#     xgb_acc = classification_report(y_test, xgb_pred)\n",
    "#     print('xgb ',i)\n",
    "#     print(xgb_acc)\n",
    "\n",
    "#     # Neural Network (MLP Classifier)\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000)\n",
    "#     mlp.fit(X_train, y_train)\n",
    "#     mlp_pred = mlp.predict(X_test)\n",
    "#     mlp_acc = classification_report(y_test, mlp_pred)\n",
    "#     print('MLP ',i)\n",
    "#     print(mlp_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "Index(['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise',\n",
      "       'neutral', 'AU01', 'AU02', 'AU04', 'AU05', 'AU06', 'AU07', 'AU09',\n",
      "       'AU10', 'AU11', 'AU12', 'AU14', 'AU15', 'AU17', 'AU20', 'AU23', 'AU24',\n",
      "       'AU25', 'AU26', 'AU28', 'AU43', 'anger_time_lag', 'disgust_time_lag',\n",
      "       'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag',\n",
      "       'surprise_time_lag', 'neutral_time_lag', 'AU01_time_lag',\n",
      "       'AU02_time_lag', 'AU04_time_lag', 'AU05_time_lag', 'AU06_time_lag',\n",
      "       'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU11_time_lag',\n",
      "       'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU17_time_lag',\n",
      "       'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag',\n",
      "       'AU26_time_lag', 'AU28_time_lag', 'AU43_time_lag'],\n",
      "      dtype='object')\n",
      "knn  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94        81\n",
      "           1       0.89      0.97      0.93        58\n",
      "\n",
      "    accuracy                           0.94       139\n",
      "   macro avg       0.93      0.94      0.93       139\n",
      "weighted avg       0.94      0.94      0.94       139\n",
      "\n",
      "XGB_  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.95      0.82        81\n",
      "           1       0.88      0.48      0.62        58\n",
      "\n",
      "    accuracy                           0.76       139\n",
      "   macro avg       0.80      0.72      0.72       139\n",
      "weighted avg       0.78      0.76      0.74       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.94      0.90        81\n",
      "           1       0.90      0.81      0.85        58\n",
      "\n",
      "    accuracy                           0.88       139\n",
      "   macro avg       0.89      0.87      0.88       139\n",
      "weighted avg       0.89      0.88      0.88       139\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n",
      "XGB_  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00        28\n",
      "\n",
      "    accuracy                           1.00        36\n",
      "   macro avg       1.00      1.00      1.00        36\n",
      "weighted avg       1.00      1.00      1.00        36\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         8\n",
      "           1       1.00      0.93      0.96        28\n",
      "\n",
      "    accuracy                           0.94        36\n",
      "   macro avg       0.90      0.96      0.93        36\n",
      "weighted avg       0.96      0.94      0.95        36\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.94      0.95        33\n",
      "           1       0.96      0.98      0.97        47\n",
      "\n",
      "    accuracy                           0.96        80\n",
      "   macro avg       0.96      0.96      0.96        80\n",
      "weighted avg       0.96      0.96      0.96        80\n",
      "\n",
      "XGB_  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           1.00        80\n",
      "   macro avg       1.00      1.00      1.00        80\n",
      "weighted avg       1.00      1.00      1.00        80\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.97      0.94        33\n",
      "           1       0.98      0.94      0.96        47\n",
      "\n",
      "    accuracy                           0.95        80\n",
      "   macro avg       0.95      0.95      0.95        80\n",
      "weighted avg       0.95      0.95      0.95        80\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        37\n",
      "           1       1.00      0.60      0.75        20\n",
      "\n",
      "    accuracy                           0.86        57\n",
      "   macro avg       0.91      0.80      0.83        57\n",
      "weighted avg       0.88      0.86      0.85        57\n",
      "\n",
      "XGB_  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        37\n",
      "           1       1.00      0.95      0.97        20\n",
      "\n",
      "    accuracy                           0.98        57\n",
      "   macro avg       0.99      0.97      0.98        57\n",
      "weighted avg       0.98      0.98      0.98        57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        37\n",
      "           1       1.00      0.80      0.89        20\n",
      "\n",
      "    accuracy                           0.93        57\n",
      "   macro avg       0.95      0.90      0.92        57\n",
      "weighted avg       0.94      0.93      0.93        57\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        45\n",
      "           1       1.00      0.89      0.94        47\n",
      "\n",
      "    accuracy                           0.95        92\n",
      "   macro avg       0.95      0.95      0.95        92\n",
      "weighted avg       0.95      0.95      0.95        92\n",
      "\n",
      "XGB_  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        45\n",
      "           1       1.00      1.00      1.00        47\n",
      "\n",
      "    accuracy                           1.00        92\n",
      "   macro avg       1.00      1.00      1.00        92\n",
      "weighted avg       1.00      1.00      1.00        92\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.96      0.93        45\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.93        92\n",
      "   macro avg       0.94      0.94      0.93        92\n",
      "weighted avg       0.94      0.93      0.93        92\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.85        11\n",
      "           1       1.00      0.89      0.94        35\n",
      "\n",
      "    accuracy                           0.91        46\n",
      "   macro avg       0.87      0.94      0.89        46\n",
      "weighted avg       0.94      0.91      0.92        46\n",
      "\n",
      "XGB_  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      1.00      0.88        11\n",
      "           1       1.00      0.91      0.96        35\n",
      "\n",
      "    accuracy                           0.93        46\n",
      "   macro avg       0.89      0.96      0.92        46\n",
      "weighted avg       0.95      0.93      0.94        46\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-25\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      1.00      0.81        11\n",
      "           1       1.00      0.86      0.92        35\n",
      "\n",
      "    accuracy                           0.89        46\n",
      "   macro avg       0.84      0.93      0.87        46\n",
      "weighted avg       0.93      0.89      0.90        46\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        38\n",
      "           1       1.00      0.94      0.97        18\n",
      "\n",
      "    accuracy                           0.98        56\n",
      "   macro avg       0.99      0.97      0.98        56\n",
      "weighted avg       0.98      0.98      0.98        56\n",
      "\n",
      "XGB_  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       1.00      1.00      1.00        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        38\n",
      "           1       1.00      1.00      1.00        18\n",
      "\n",
      "    accuracy                           1.00        56\n",
      "   macro avg       1.00      1.00      1.00        56\n",
      "weighted avg       1.00      1.00      1.00        56\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89         4\n",
      "           1       1.00      0.96      0.98        25\n",
      "\n",
      "    accuracy                           0.97        29\n",
      "   macro avg       0.90      0.98      0.93        29\n",
      "weighted avg       0.97      0.97      0.97        29\n",
      "\n",
      "XGB_  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        25\n",
      "\n",
      "    accuracy                           1.00        29\n",
      "   macro avg       1.00      1.00      1.00        29\n",
      "weighted avg       1.00      1.00      1.00        29\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n",
      "XGB_  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        53\n",
      "   macro avg       1.00      1.00      1.00        53\n",
      "weighted avg       1.00      1.00      1.00        53\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        58\n",
      "\n",
      "    accuracy                           1.00       109\n",
      "   macro avg       1.00      1.00      1.00       109\n",
      "weighted avg       1.00      1.00      1.00       109\n",
      "\n",
      "XGB_  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        58\n",
      "\n",
      "    accuracy                           1.00       109\n",
      "   macro avg       1.00      1.00      1.00       109\n",
      "weighted avg       1.00      1.00      1.00       109\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        51\n",
      "           1       1.00      0.98      0.99        58\n",
      "\n",
      "    accuracy                           0.99       109\n",
      "   macro avg       0.99      0.99      0.99       109\n",
      "weighted avg       0.99      0.99      0.99       109\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.94      0.97        18\n",
      "           1       0.95      1.00      0.97        19\n",
      "\n",
      "    accuracy                           0.97        37\n",
      "   macro avg       0.97      0.97      0.97        37\n",
      "weighted avg       0.97      0.97      0.97        37\n",
      "\n",
      "XGB_  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        37\n",
      "   macro avg       1.00      1.00      1.00        37\n",
      "weighted avg       1.00      1.00      1.00        37\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        37\n",
      "   macro avg       1.00      1.00      1.00        37\n",
      "weighted avg       1.00      1.00      1.00        37\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        63\n",
      "           1       1.00      0.79      0.88        33\n",
      "\n",
      "    accuracy                           0.93        96\n",
      "   macro avg       0.95      0.89      0.91        96\n",
      "weighted avg       0.93      0.93      0.92        96\n",
      "\n",
      "XGB_  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        63\n",
      "           1       1.00      1.00      1.00        33\n",
      "\n",
      "    accuracy                           1.00        96\n",
      "   macro avg       1.00      1.00      1.00        96\n",
      "weighted avg       1.00      1.00      1.00        96\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98        63\n",
      "           1       1.00      0.91      0.95        33\n",
      "\n",
      "    accuracy                           0.97        96\n",
      "   macro avg       0.98      0.95      0.96        96\n",
      "weighted avg       0.97      0.97      0.97        96\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        21\n",
      "           1       1.00      0.64      0.78        14\n",
      "\n",
      "    accuracy                           0.86        35\n",
      "   macro avg       0.90      0.82      0.84        35\n",
      "weighted avg       0.88      0.86      0.85        35\n",
      "\n",
      "XGB_  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        21\n",
      "           1       1.00      1.00      1.00        14\n",
      "\n",
      "    accuracy                           1.00        35\n",
      "   macro avg       1.00      1.00      1.00        35\n",
      "weighted avg       1.00      1.00      1.00        35\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95        21\n",
      "           1       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.94        35\n",
      "   macro avg       0.96      0.93      0.94        35\n",
      "weighted avg       0.95      0.94      0.94        35\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        50\n",
      "           1       1.00      0.75      0.86         4\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.99      0.88      0.92        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n",
      "XGB_  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        54\n",
      "   macro avg       1.00      1.00      1.00        54\n",
      "weighted avg       1.00      1.00      1.00        54\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        50\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.90      0.99      0.94        54\n",
      "weighted avg       0.99      0.98      0.98        54\n",
      "\n",
      "Train:  ['P25.csv', 'P24.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P19.csv']\n",
      "knn  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        39\n",
      "           1       0.97      0.90      0.94        42\n",
      "\n",
      "    accuracy                           0.94        81\n",
      "   macro avg       0.94      0.94      0.94        81\n",
      "weighted avg       0.94      0.94      0.94        81\n",
      "\n",
      "XGB_  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        39\n",
      "           1       1.00      1.00      1.00        42\n",
      "\n",
      "    accuracy                           1.00        81\n",
      "   macro avg       1.00      1.00      1.00        81\n",
      "weighted avg       1.00      1.00      1.00        81\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  0      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        39\n",
      "           1       0.98      0.95      0.96        42\n",
      "\n",
      "    accuracy                           0.96        81\n",
      "   macro avg       0.96      0.96      0.96        81\n",
      "weighted avg       0.96      0.96      0.96        81\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.39      0.47        23\n",
      "           1       0.88      0.94      0.91       104\n",
      "\n",
      "    accuracy                           0.84       127\n",
      "   macro avg       0.74      0.67      0.69       127\n",
      "weighted avg       0.83      0.84      0.83       127\n",
      "\n",
      "XGB_  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.74      0.55        23\n",
      "           1       0.93      0.79      0.85       104\n",
      "\n",
      "    accuracy                           0.78       127\n",
      "   macro avg       0.68      0.76      0.70       127\n",
      "weighted avg       0.84      0.78      0.80       127\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.52      0.40        23\n",
      "           1       0.88      0.76      0.81       104\n",
      "\n",
      "    accuracy                           0.72       127\n",
      "   macro avg       0.60      0.64      0.61       127\n",
      "weighted avg       0.78      0.72      0.74       127\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.56      0.43        25\n",
      "           1       0.94      0.88      0.91       213\n",
      "\n",
      "    accuracy                           0.84       238\n",
      "   macro avg       0.65      0.72      0.67       238\n",
      "weighted avg       0.88      0.84      0.86       238\n",
      "\n",
      "XGB_  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.88      0.53        25\n",
      "           1       0.98      0.83      0.90       213\n",
      "\n",
      "    accuracy                           0.84       238\n",
      "   macro avg       0.68      0.86      0.72       238\n",
      "weighted avg       0.92      0.84      0.86       238\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.84      0.42        25\n",
      "           1       0.98      0.75      0.85       213\n",
      "\n",
      "    accuracy                           0.76       238\n",
      "   macro avg       0.63      0.79      0.63       238\n",
      "weighted avg       0.90      0.76      0.80       238\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.77      0.47        22\n",
      "           1       0.98      0.86      0.92       243\n",
      "\n",
      "    accuracy                           0.86       265\n",
      "   macro avg       0.66      0.82      0.69       265\n",
      "weighted avg       0.92      0.86      0.88       265\n",
      "\n",
      "XGB_  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        22\n",
      "           1       1.00      0.96      0.98       243\n",
      "\n",
      "    accuracy                           0.97       265\n",
      "   macro avg       0.85      0.98      0.91       265\n",
      "weighted avg       0.98      0.97      0.97       265\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.82      0.39        22\n",
      "           1       0.98      0.79      0.87       243\n",
      "\n",
      "    accuracy                           0.79       265\n",
      "   macro avg       0.62      0.80      0.63       265\n",
      "weighted avg       0.92      0.79      0.83       265\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77        37\n",
      "           1       0.98      0.96      0.97       297\n",
      "\n",
      "    accuracy                           0.95       334\n",
      "   macro avg       0.85      0.89      0.87       334\n",
      "weighted avg       0.95      0.95      0.95       334\n",
      "\n",
      "XGB_  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        37\n",
      "           1       1.00      1.00      1.00       297\n",
      "\n",
      "    accuracy                           1.00       334\n",
      "   macro avg       0.99      1.00      0.99       334\n",
      "weighted avg       1.00      1.00      1.00       334\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.92      0.64        37\n",
      "           1       0.99      0.88      0.93       297\n",
      "\n",
      "    accuracy                           0.88       334\n",
      "   macro avg       0.74      0.90      0.78       334\n",
      "weighted avg       0.93      0.88      0.90       334\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.29      1.00      0.45        10\n",
      "           1       1.00      0.92      0.96       311\n",
      "\n",
      "    accuracy                           0.93       321\n",
      "   macro avg       0.65      0.96      0.71       321\n",
      "weighted avg       0.98      0.93      0.94       321\n",
      "\n",
      "XGB_  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        10\n",
      "           1       1.00      1.00      1.00       311\n",
      "\n",
      "    accuracy                           1.00       321\n",
      "   macro avg       1.00      1.00      1.00       321\n",
      "weighted avg       1.00      1.00      1.00       321\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.20      0.70      0.31        10\n",
      "           1       0.99      0.91      0.95       311\n",
      "\n",
      "    accuracy                           0.90       321\n",
      "   macro avg       0.59      0.80      0.63       321\n",
      "weighted avg       0.96      0.90      0.93       321\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.86      0.55         7\n",
      "           1       0.99      0.95      0.97       164\n",
      "\n",
      "    accuracy                           0.94       171\n",
      "   macro avg       0.70      0.90      0.76       171\n",
      "weighted avg       0.97      0.94      0.95       171\n",
      "\n",
      "XGB_  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00       164\n",
      "\n",
      "    accuracy                           1.00       171\n",
      "   macro avg       1.00      1.00      1.00       171\n",
      "weighted avg       1.00      1.00      1.00       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50         7\n",
      "           1       1.00      0.91      0.96       164\n",
      "\n",
      "    accuracy                           0.92       171\n",
      "   macro avg       0.67      0.96      0.73       171\n",
      "weighted avg       0.97      0.92      0.94       171\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.97      0.55        30\n",
      "           1       1.00      0.82      0.90       266\n",
      "\n",
      "    accuracy                           0.84       296\n",
      "   macro avg       0.69      0.89      0.72       296\n",
      "weighted avg       0.93      0.84      0.87       296\n",
      "\n",
      "XGB_  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.79        30\n",
      "           1       1.00      0.95      0.97       266\n",
      "\n",
      "    accuracy                           0.95       296\n",
      "   macro avg       0.84      0.96      0.88       296\n",
      "weighted avg       0.96      0.95      0.95       296\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.87      0.57        30\n",
      "           1       0.98      0.87      0.92       266\n",
      "\n",
      "    accuracy                           0.87       296\n",
      "   macro avg       0.70      0.87      0.75       296\n",
      "weighted avg       0.93      0.87      0.89       296\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84        53\n",
      "           1       0.99      0.90      0.94       166\n",
      "\n",
      "    accuracy                           0.91       219\n",
      "   macro avg       0.87      0.93      0.89       219\n",
      "weighted avg       0.93      0.91      0.92       219\n",
      "\n",
      "XGB_  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        53\n",
      "           1       1.00      1.00      1.00       166\n",
      "\n",
      "    accuracy                           1.00       219\n",
      "   macro avg       1.00      1.00      1.00       219\n",
      "weighted avg       1.00      1.00      1.00       219\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.91      0.81        53\n",
      "           1       0.97      0.89      0.93       166\n",
      "\n",
      "    accuracy                           0.89       219\n",
      "   macro avg       0.85      0.90      0.87       219\n",
      "weighted avg       0.91      0.89      0.90       219\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.93      0.70        15\n",
      "           1       0.99      0.94      0.97       199\n",
      "\n",
      "    accuracy                           0.94       214\n",
      "   macro avg       0.78      0.94      0.83       214\n",
      "weighted avg       0.96      0.94      0.95       214\n",
      "\n",
      "XGB_  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        15\n",
      "           1       1.00      1.00      1.00       199\n",
      "\n",
      "    accuracy                           1.00       214\n",
      "   macro avg       1.00      1.00      1.00       214\n",
      "weighted avg       1.00      1.00      1.00       214\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79        15\n",
      "           1       1.00      0.96      0.98       199\n",
      "\n",
      "    accuracy                           0.96       214\n",
      "   macro avg       0.83      0.98      0.88       214\n",
      "weighted avg       0.98      0.96      0.97       214\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.97      0.79        35\n",
      "           1       0.99      0.90      0.95       177\n",
      "\n",
      "    accuracy                           0.92       212\n",
      "   macro avg       0.83      0.94      0.87       212\n",
      "weighted avg       0.94      0.92      0.92       212\n",
      "\n",
      "XGB_  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        35\n",
      "           1       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       212\n",
      "   macro avg       1.00      1.00      1.00       212\n",
      "weighted avg       1.00      1.00      1.00       212\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.94      0.78        35\n",
      "           1       0.99      0.90      0.94       177\n",
      "\n",
      "    accuracy                           0.91       212\n",
      "   macro avg       0.82      0.92      0.86       212\n",
      "weighted avg       0.93      0.91      0.92       212\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.41        13\n",
      "           1       1.00      0.86      0.93       276\n",
      "\n",
      "    accuracy                           0.87       289\n",
      "   macro avg       0.63      0.93      0.67       289\n",
      "weighted avg       0.97      0.87      0.90       289\n",
      "\n",
      "XGB_  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        13\n",
      "           1       1.00      1.00      1.00       276\n",
      "\n",
      "    accuracy                           1.00       289\n",
      "   macro avg       1.00      1.00      1.00       289\n",
      "weighted avg       1.00      1.00      1.00       289\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.18      0.85      0.29        13\n",
      "           1       0.99      0.82      0.89       276\n",
      "\n",
      "    accuracy                           0.82       289\n",
      "   macro avg       0.58      0.83      0.59       289\n",
      "weighted avg       0.95      0.82      0.87       289\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.97      0.67        36\n",
      "           1       0.99      0.85      0.92       222\n",
      "\n",
      "    accuracy                           0.87       258\n",
      "   macro avg       0.75      0.91      0.80       258\n",
      "weighted avg       0.93      0.87      0.88       258\n",
      "\n",
      "XGB_  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        36\n",
      "           1       1.00      1.00      1.00       222\n",
      "\n",
      "    accuracy                           1.00       258\n",
      "   macro avg       0.99      1.00      0.99       258\n",
      "weighted avg       1.00      1.00      1.00       258\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.92      0.62        36\n",
      "           1       0.98      0.83      0.90       222\n",
      "\n",
      "    accuracy                           0.84       258\n",
      "   macro avg       0.73      0.88      0.76       258\n",
      "weighted avg       0.91      0.84      0.86       258\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.86      0.35         7\n",
      "           1       0.99      0.78      0.87        94\n",
      "\n",
      "    accuracy                           0.78       101\n",
      "   macro avg       0.60      0.82      0.61       101\n",
      "weighted avg       0.93      0.78      0.83       101\n",
      "\n",
      "XGB_  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      1.00      0.93         7\n",
      "           1       1.00      0.99      0.99        94\n",
      "\n",
      "    accuracy                           0.99       101\n",
      "   macro avg       0.94      0.99      0.96       101\n",
      "weighted avg       0.99      0.99      0.99       101\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.71      0.33         7\n",
      "           1       0.97      0.81      0.88        94\n",
      "\n",
      "    accuracy                           0.80       101\n",
      "   macro avg       0.60      0.76      0.61       101\n",
      "weighted avg       0.92      0.80      0.85       101\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        39\n",
      "           1       1.00      0.88      0.94       223\n",
      "\n",
      "    accuracy                           0.90       262\n",
      "   macro avg       0.80      0.94      0.84       262\n",
      "weighted avg       0.94      0.90      0.91       262\n",
      "\n",
      "XGB_  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        39\n",
      "           1       1.00      0.99      0.99       223\n",
      "\n",
      "    accuracy                           0.99       262\n",
      "   macro avg       0.96      0.99      0.98       262\n",
      "weighted avg       0.99      0.99      0.99       262\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85        39\n",
      "           1       1.00      0.94      0.97       223\n",
      "\n",
      "    accuracy                           0.95       262\n",
      "   macro avg       0.87      0.97      0.91       262\n",
      "weighted avg       0.96      0.95      0.95       262\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      1.00      0.37         8\n",
      "           1       1.00      0.91      0.95       287\n",
      "\n",
      "    accuracy                           0.91       295\n",
      "   macro avg       0.61      0.95      0.66       295\n",
      "weighted avg       0.98      0.91      0.93       295\n",
      "\n",
      "XGB_  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       295\n",
      "   macro avg       1.00      1.00      1.00       295\n",
      "weighted avg       1.00      1.00      1.00       295\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40         8\n",
      "           1       1.00      0.92      0.96       287\n",
      "\n",
      "    accuracy                           0.92       295\n",
      "   macro avg       0.62      0.96      0.68       295\n",
      "weighted avg       0.98      0.92      0.94       295\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.61        14\n",
      "           1       1.00      0.69      0.82        59\n",
      "\n",
      "    accuracy                           0.75        73\n",
      "   macro avg       0.72      0.85      0.71        73\n",
      "weighted avg       0.89      0.75      0.78        73\n",
      "\n",
      "XGB_  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.79      0.59        14\n",
      "           1       0.94      0.80      0.86        59\n",
      "\n",
      "    accuracy                           0.79        73\n",
      "   macro avg       0.71      0.79      0.73        73\n",
      "weighted avg       0.85      0.79      0.81        73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-29\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.86      0.69        14\n",
      "           1       0.96      0.85      0.90        59\n",
      "\n",
      "    accuracy                           0.85        73\n",
      "   macro avg       0.77      0.85      0.79        73\n",
      "weighted avg       0.89      0.85      0.86        73\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        19\n",
      "           1       0.79      0.79      0.79        29\n",
      "\n",
      "    accuracy                           0.75        48\n",
      "   macro avg       0.74      0.74      0.74        48\n",
      "weighted avg       0.75      0.75      0.75        48\n",
      "\n",
      "XGB_  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95        19\n",
      "           1       1.00      0.93      0.96        29\n",
      "\n",
      "    accuracy                           0.96        48\n",
      "   macro avg       0.95      0.97      0.96        48\n",
      "weighted avg       0.96      0.96      0.96        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-26\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.63      0.67        19\n",
      "           1       0.77      0.83      0.80        29\n",
      "\n",
      "    accuracy                           0.75        48\n",
      "   macro avg       0.74      0.73      0.73        48\n",
      "weighted avg       0.75      0.75      0.75        48\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P20.csv', 'P24.csv']\n",
      "knn  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      1.00      0.40         2\n",
      "           1       1.00      0.89      0.94        55\n",
      "\n",
      "    accuracy                           0.89        57\n",
      "   macro avg       0.62      0.95      0.67        57\n",
      "weighted avg       0.97      0.89      0.92        57\n",
      "\n",
      "XGB_  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00        55\n",
      "\n",
      "    accuracy                           1.00        57\n",
      "   macro avg       1.00      1.00      1.00        57\n",
      "weighted avg       1.00      1.00      1.00        57\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  1      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.50      0.20         2\n",
      "           1       0.98      0.87      0.92        55\n",
      "\n",
      "    accuracy                           0.86        57\n",
      "   macro avg       0.55      0.69      0.56        57\n",
      "weighted avg       0.95      0.86      0.90        57\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.84      0.62        77\n",
      "           1       0.83      0.47      0.60       129\n",
      "\n",
      "    accuracy                           0.61       206\n",
      "   macro avg       0.66      0.65      0.61       206\n",
      "weighted avg       0.70      0.61      0.60       206\n",
      "\n",
      "XGB_  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      1.00      0.69        77\n",
      "           1       1.00      0.47      0.64       129\n",
      "\n",
      "    accuracy                           0.67       206\n",
      "   macro avg       0.77      0.74      0.67       206\n",
      "weighted avg       0.82      0.67      0.66       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.95      0.63        77\n",
      "           1       0.92      0.38      0.54       129\n",
      "\n",
      "    accuracy                           0.59       206\n",
      "   macro avg       0.70      0.66      0.59       206\n",
      "weighted avg       0.76      0.59      0.57       206\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.96      0.74        55\n",
      "           1       0.98      0.76      0.86       151\n",
      "\n",
      "    accuracy                           0.82       206\n",
      "   macro avg       0.79      0.86      0.80       206\n",
      "weighted avg       0.88      0.82      0.83       206\n",
      "\n",
      "XGB_  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99        55\n",
      "           1       1.00      0.99      1.00       151\n",
      "\n",
      "    accuracy                           1.00       206\n",
      "   macro avg       0.99      1.00      0.99       206\n",
      "weighted avg       1.00      1.00      1.00       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-07\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.98      0.71        55\n",
      "           1       0.99      0.71      0.83       151\n",
      "\n",
      "    accuracy                           0.78       206\n",
      "   macro avg       0.77      0.85      0.77       206\n",
      "weighted avg       0.87      0.78      0.79       206\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.95      0.80        66\n",
      "           1       0.97      0.80      0.88       142\n",
      "\n",
      "    accuracy                           0.85       208\n",
      "   macro avg       0.83      0.88      0.84       208\n",
      "weighted avg       0.88      0.85      0.85       208\n",
      "\n",
      "XGB_  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        66\n",
      "           1       1.00      1.00      1.00       142\n",
      "\n",
      "    accuracy                           1.00       208\n",
      "   macro avg       1.00      1.00      1.00       208\n",
      "weighted avg       1.00      1.00      1.00       208\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.97      0.75        66\n",
      "           1       0.98      0.72      0.83       142\n",
      "\n",
      "    accuracy                           0.80       208\n",
      "   macro avg       0.80      0.84      0.79       208\n",
      "weighted avg       0.86      0.80      0.81       208\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.94      0.83        68\n",
      "           1       0.98      0.87      0.92       182\n",
      "\n",
      "    accuracy                           0.89       250\n",
      "   macro avg       0.86      0.91      0.87       250\n",
      "weighted avg       0.91      0.89      0.90       250\n",
      "\n",
      "XGB_  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        68\n",
      "           1       1.00      1.00      1.00       182\n",
      "\n",
      "    accuracy                           1.00       250\n",
      "   macro avg       1.00      1.00      1.00       250\n",
      "weighted avg       1.00      1.00      1.00       250\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.94      0.76        68\n",
      "           1       0.97      0.80      0.88       182\n",
      "\n",
      "    accuracy                           0.84       250\n",
      "   macro avg       0.81      0.87      0.82       250\n",
      "weighted avg       0.88      0.84      0.85       250\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.98      0.78        58\n",
      "           1       0.99      0.79      0.88       145\n",
      "\n",
      "    accuracy                           0.84       203\n",
      "   macro avg       0.82      0.88      0.83       203\n",
      "weighted avg       0.89      0.84      0.85       203\n",
      "\n",
      "XGB_  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "           1       1.00      1.00      1.00       145\n",
      "\n",
      "    accuracy                           1.00       203\n",
      "   macro avg       1.00      1.00      1.00       203\n",
      "weighted avg       1.00      1.00      1.00       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      1.00      0.73        58\n",
      "           1       1.00      0.70      0.83       145\n",
      "\n",
      "    accuracy                           0.79       203\n",
      "   macro avg       0.79      0.85      0.78       203\n",
      "weighted avg       0.88      0.79      0.80       203\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.99      0.85        74\n",
      "           1       0.99      0.86      0.92       177\n",
      "\n",
      "    accuracy                           0.90       251\n",
      "   macro avg       0.87      0.92      0.89       251\n",
      "weighted avg       0.92      0.90      0.90       251\n",
      "\n",
      "XGB_  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        74\n",
      "           1       1.00      1.00      1.00       177\n",
      "\n",
      "    accuracy                           1.00       251\n",
      "   macro avg       1.00      1.00      1.00       251\n",
      "weighted avg       1.00      1.00      1.00       251\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        74\n",
      "           1       1.00      0.83      0.91       177\n",
      "\n",
      "    accuracy                           0.88       251\n",
      "   macro avg       0.86      0.92      0.87       251\n",
      "weighted avg       0.91      0.88      0.89       251\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        95\n",
      "           1       0.99      0.89      0.94       115\n",
      "\n",
      "    accuracy                           0.93       210\n",
      "   macro avg       0.93      0.94      0.93       210\n",
      "weighted avg       0.94      0.93      0.93       210\n",
      "\n",
      "XGB_  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        95\n",
      "           1       1.00      1.00      1.00       115\n",
      "\n",
      "    accuracy                           1.00       210\n",
      "   macro avg       1.00      1.00      1.00       210\n",
      "weighted avg       1.00      1.00      1.00       210\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        95\n",
      "           1       1.00      0.86      0.93       115\n",
      "\n",
      "    accuracy                           0.92       210\n",
      "   macro avg       0.93      0.93      0.92       210\n",
      "weighted avg       0.93      0.92      0.92       210\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P24.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P13.csv', 'P30.csv']\n",
      "knn  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87        34\n",
      "           1       1.00      0.92      0.96       131\n",
      "\n",
      "    accuracy                           0.94       165\n",
      "   macro avg       0.89      0.96      0.92       165\n",
      "weighted avg       0.95      0.94      0.94       165\n",
      "\n",
      "XGB_  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        34\n",
      "           1       1.00      1.00      1.00       131\n",
      "\n",
      "    accuracy                           1.00       165\n",
      "   macro avg       1.00      1.00      1.00       165\n",
      "weighted avg       1.00      1.00      1.00       165\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  2      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      1.00      0.83        34\n",
      "           1       1.00      0.89      0.94       131\n",
      "\n",
      "    accuracy                           0.92       165\n",
      "   macro avg       0.85      0.95      0.89       165\n",
      "weighted avg       0.94      0.92      0.92       165\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.90      0.62        39\n",
      "           1       0.95      0.65      0.77       113\n",
      "\n",
      "    accuracy                           0.72       152\n",
      "   macro avg       0.71      0.78      0.70       152\n",
      "weighted avg       0.83      0.72      0.73       152\n",
      "\n",
      "XGB_  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.97      0.60        39\n",
      "           1       0.98      0.57      0.72       113\n",
      "\n",
      "    accuracy                           0.67       152\n",
      "   macro avg       0.71      0.77      0.66       152\n",
      "weighted avg       0.84      0.67      0.69       152\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.95      0.70        39\n",
      "           1       0.98      0.73      0.84       113\n",
      "\n",
      "    accuracy                           0.79       152\n",
      "   macro avg       0.76      0.84      0.77       152\n",
      "weighted avg       0.87      0.79      0.80       152\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.96      0.83        45\n",
      "           1       0.95      0.72      0.82        58\n",
      "\n",
      "    accuracy                           0.83       103\n",
      "   macro avg       0.84      0.84      0.83       103\n",
      "weighted avg       0.86      0.83      0.83       103\n",
      "\n",
      "XGB_  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.96      0.82        45\n",
      "           1       0.95      0.71      0.81        58\n",
      "\n",
      "    accuracy                           0.82       103\n",
      "   macro avg       0.84      0.83      0.82       103\n",
      "weighted avg       0.85      0.82      0.82       103\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-20\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.96      0.84        45\n",
      "           1       0.96      0.76      0.85        58\n",
      "\n",
      "    accuracy                           0.84       103\n",
      "   macro avg       0.86      0.86      0.84       103\n",
      "weighted avg       0.87      0.84      0.84       103\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96        37\n",
      "           1       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.93        43\n",
      "   macro avg       0.87      0.82      0.84        43\n",
      "weighted avg       0.93      0.93      0.93        43\n",
      "\n",
      "XGB_  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        37\n",
      "           1       0.67      0.33      0.44         6\n",
      "\n",
      "    accuracy                           0.88        43\n",
      "   macro avg       0.78      0.65      0.69        43\n",
      "weighted avg       0.87      0.88      0.87        43\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-21\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        37\n",
      "           1       1.00      0.50      0.67         6\n",
      "\n",
      "    accuracy                           0.93        43\n",
      "   macro avg       0.96      0.75      0.81        43\n",
      "weighted avg       0.94      0.93      0.92        43\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        48\n",
      "           1       1.00      0.92      0.96       106\n",
      "\n",
      "    accuracy                           0.94       154\n",
      "   macro avg       0.92      0.96      0.93       154\n",
      "weighted avg       0.95      0.94      0.94       154\n",
      "\n",
      "XGB_  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        48\n",
      "           1       1.00      1.00      1.00       106\n",
      "\n",
      "    accuracy                           1.00       154\n",
      "   macro avg       1.00      1.00      1.00       154\n",
      "weighted avg       1.00      1.00      1.00       154\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        48\n",
      "           1       1.00      0.89      0.94       106\n",
      "\n",
      "    accuracy                           0.92       154\n",
      "   macro avg       0.90      0.94      0.91       154\n",
      "weighted avg       0.94      0.92      0.92       154\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.95      0.63        21\n",
      "           1       0.98      0.73      0.84        83\n",
      "\n",
      "    accuracy                           0.78       104\n",
      "   macro avg       0.73      0.84      0.74       104\n",
      "weighted avg       0.88      0.78      0.80       104\n",
      "\n",
      "XGB_  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.95      0.89        21\n",
      "           1       0.99      0.95      0.97        83\n",
      "\n",
      "    accuracy                           0.95       104\n",
      "   macro avg       0.91      0.95      0.93       104\n",
      "weighted avg       0.96      0.95      0.95       104\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      1.00      0.78        21\n",
      "           1       1.00      0.86      0.92        83\n",
      "\n",
      "    accuracy                           0.88       104\n",
      "   macro avg       0.82      0.93      0.85       104\n",
      "weighted avg       0.93      0.88      0.89       104\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95        63\n",
      "           1       0.83      0.67      0.74        15\n",
      "\n",
      "    accuracy                           0.91        78\n",
      "   macro avg       0.88      0.82      0.84        78\n",
      "weighted avg       0.91      0.91      0.91        78\n",
      "\n",
      "XGB_  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        63\n",
      "           1       1.00      1.00      1.00        15\n",
      "\n",
      "    accuracy                           1.00        78\n",
      "   macro avg       1.00      1.00      1.00        78\n",
      "weighted avg       1.00      1.00      1.00        78\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-09\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        63\n",
      "           1       0.87      0.87      0.87        15\n",
      "\n",
      "    accuracy                           0.95        78\n",
      "   macro avg       0.92      0.92      0.92        78\n",
      "weighted avg       0.95      0.95      0.95        78\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97        71\n",
      "           1       0.91      0.91      0.91        23\n",
      "\n",
      "    accuracy                           0.96        94\n",
      "   macro avg       0.94      0.94      0.94        94\n",
      "weighted avg       0.96      0.96      0.96        94\n",
      "\n",
      "XGB_  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        71\n",
      "           1       1.00      1.00      1.00        23\n",
      "\n",
      "    accuracy                           1.00        94\n",
      "   macro avg       1.00      1.00      1.00        94\n",
      "weighted avg       1.00      1.00      1.00        94\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99        71\n",
      "           1       0.96      0.96      0.96        23\n",
      "\n",
      "    accuracy                           0.98        94\n",
      "   macro avg       0.97      0.97      0.97        94\n",
      "weighted avg       0.98      0.98      0.98        94\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      1.00      0.62         4\n",
      "           1       1.00      0.92      0.96        59\n",
      "\n",
      "    accuracy                           0.92        63\n",
      "   macro avg       0.72      0.96      0.79        63\n",
      "weighted avg       0.96      0.92      0.93        63\n",
      "\n",
      "XGB_  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.23      0.75      0.35         4\n",
      "           1       0.98      0.83      0.90        59\n",
      "\n",
      "    accuracy                           0.83        63\n",
      "   macro avg       0.61      0.79      0.63        63\n",
      "weighted avg       0.93      0.83      0.86        63\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-22\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      1.00      0.53         4\n",
      "           1       1.00      0.88      0.94        59\n",
      "\n",
      "    accuracy                           0.89        63\n",
      "   macro avg       0.68      0.94      0.74        63\n",
      "weighted avg       0.96      0.89      0.91        63\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        81\n",
      "           1       0.96      0.90      0.93        58\n",
      "\n",
      "    accuracy                           0.94       139\n",
      "   macro avg       0.95      0.94      0.94       139\n",
      "weighted avg       0.94      0.94      0.94       139\n",
      "\n",
      "XGB_  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        81\n",
      "           1       1.00      1.00      1.00        58\n",
      "\n",
      "    accuracy                           1.00       139\n",
      "   macro avg       1.00      1.00      1.00       139\n",
      "weighted avg       1.00      1.00      1.00       139\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        81\n",
      "           1       0.96      0.86      0.91        58\n",
      "\n",
      "    accuracy                           0.93       139\n",
      "   macro avg       0.93      0.92      0.92       139\n",
      "weighted avg       0.93      0.93      0.93       139\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93        38\n",
      "           1       0.97      0.86      0.91        35\n",
      "\n",
      "    accuracy                           0.92        73\n",
      "   macro avg       0.92      0.92      0.92        73\n",
      "weighted avg       0.92      0.92      0.92        73\n",
      "\n",
      "XGB_  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99        38\n",
      "           1       1.00      0.97      0.99        35\n",
      "\n",
      "    accuracy                           0.99        73\n",
      "   macro avg       0.99      0.99      0.99        73\n",
      "weighted avg       0.99      0.99      0.99        73\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      1.00      0.90        38\n",
      "           1       1.00      0.77      0.87        35\n",
      "\n",
      "    accuracy                           0.89        73\n",
      "   macro avg       0.91      0.89      0.89        73\n",
      "weighted avg       0.91      0.89      0.89        73\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        51\n",
      "           1       1.00      0.74      0.85        34\n",
      "\n",
      "    accuracy                           0.89        85\n",
      "   macro avg       0.93      0.87      0.88        85\n",
      "weighted avg       0.91      0.89      0.89        85\n",
      "\n",
      "XGB_  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        51\n",
      "           1       1.00      1.00      1.00        34\n",
      "\n",
      "    accuracy                           1.00        85\n",
      "   macro avg       1.00      1.00      1.00        85\n",
      "weighted avg       1.00      1.00      1.00        85\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-03\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.93        51\n",
      "           1       0.96      0.79      0.87        34\n",
      "\n",
      "    accuracy                           0.91        85\n",
      "   macro avg       0.92      0.89      0.90        85\n",
      "weighted avg       0.91      0.91      0.90        85\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        33\n",
      "           1       1.00      0.81      0.89        31\n",
      "\n",
      "    accuracy                           0.91        64\n",
      "   macro avg       0.92      0.90      0.90        64\n",
      "weighted avg       0.92      0.91      0.91        64\n",
      "\n",
      "XGB_  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        33\n",
      "           1       1.00      1.00      1.00        31\n",
      "\n",
      "    accuracy                           1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93        33\n",
      "           1       0.96      0.87      0.92        31\n",
      "\n",
      "    accuracy                           0.92        64\n",
      "   macro avg       0.93      0.92      0.92        64\n",
      "weighted avg       0.93      0.92      0.92        64\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96        50\n",
      "           1       1.00      0.92      0.96        49\n",
      "\n",
      "    accuracy                           0.96        99\n",
      "   macro avg       0.96      0.96      0.96        99\n",
      "weighted avg       0.96      0.96      0.96        99\n",
      "\n",
      "XGB_  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        50\n",
      "           1       1.00      1.00      1.00        49\n",
      "\n",
      "    accuracy                           1.00        99\n",
      "   macro avg       1.00      1.00      1.00        99\n",
      "weighted avg       1.00      1.00      1.00        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97        50\n",
      "           1       0.98      0.96      0.97        49\n",
      "\n",
      "    accuracy                           0.97        99\n",
      "   macro avg       0.97      0.97      0.97        99\n",
      "weighted avg       0.97      0.97      0.97        99\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      1.00      0.84        46\n",
      "           1       1.00      0.70      0.83        61\n",
      "\n",
      "    accuracy                           0.83       107\n",
      "   macro avg       0.86      0.85      0.83       107\n",
      "weighted avg       0.88      0.83      0.83       107\n",
      "\n",
      "XGB_  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        46\n",
      "           1       1.00      1.00      1.00        61\n",
      "\n",
      "    accuracy                           1.00       107\n",
      "   macro avg       1.00      1.00      1.00       107\n",
      "weighted avg       1.00      1.00      1.00       107\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      1.00      0.90        46\n",
      "           1       1.00      0.84      0.91        61\n",
      "\n",
      "    accuracy                           0.91       107\n",
      "   macro avg       0.91      0.92      0.91       107\n",
      "weighted avg       0.92      0.91      0.91       107\n",
      "\n",
      "Train:  ['P19.csv', 'P25.csv', 'P24.csv', 'P30.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P08.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P31.csv', 'P18.csv']\n",
      "knn  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n",
      "XGB_  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         5\n",
      "\n",
      "    accuracy                           1.00        13\n",
      "   macro avg       1.00      1.00      1.00        13\n",
      "weighted avg       1.00      1.00      1.00        13\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  3      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.88      0.88         8\n",
      "           1       0.80      0.80      0.80         5\n",
      "\n",
      "    accuracy                           0.85        13\n",
      "   macro avg       0.84      0.84      0.84        13\n",
      "weighted avg       0.85      0.85      0.85        13\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         4\n",
      "           1       0.98      0.95      0.96       199\n",
      "\n",
      "    accuracy                           0.93       203\n",
      "   macro avg       0.49      0.47      0.48       203\n",
      "weighted avg       0.96      0.93      0.95       203\n",
      "\n",
      "XGB_  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.75      0.46         4\n",
      "           1       0.99      0.97      0.98       199\n",
      "\n",
      "    accuracy                           0.97       203\n",
      "   macro avg       0.66      0.86      0.72       203\n",
      "weighted avg       0.98      0.97      0.97       203\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-07-31\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.50      0.11         4\n",
      "           1       0.99      0.84      0.91       199\n",
      "\n",
      "    accuracy                           0.83       203\n",
      "   macro avg       0.52      0.67      0.51       203\n",
      "weighted avg       0.97      0.83      0.89       203\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.33      0.08         6\n",
      "           1       0.98      0.84      0.91       276\n",
      "\n",
      "    accuracy                           0.83       282\n",
      "   macro avg       0.51      0.59      0.49       282\n",
      "weighted avg       0.96      0.83      0.89       282\n",
      "\n",
      "XGB_  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.67      0.32         6\n",
      "           1       0.99      0.95      0.97       276\n",
      "\n",
      "    accuracy                           0.94       282\n",
      "   macro avg       0.60      0.81      0.64       282\n",
      "weighted avg       0.98      0.94      0.95       282\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-04\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.17      0.02         6\n",
      "           1       0.97      0.71      0.82       276\n",
      "\n",
      "    accuracy                           0.70       282\n",
      "   macro avg       0.49      0.44      0.42       282\n",
      "weighted avg       0.95      0.70      0.80       282\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.06      0.25      0.10         4\n",
      "           1       0.98      0.91      0.94       177\n",
      "\n",
      "    accuracy                           0.90       181\n",
      "   macro avg       0.52      0.58      0.52       181\n",
      "weighted avg       0.96      0.90      0.93       181\n",
      "\n",
      "XGB_  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.75      0.50         4\n",
      "           1       0.99      0.97      0.98       177\n",
      "\n",
      "    accuracy                           0.97       181\n",
      "   macro avg       0.68      0.86      0.74       181\n",
      "weighted avg       0.98      0.97      0.97       181\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-08\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.03      0.25      0.06         4\n",
      "           1       0.98      0.82      0.90       177\n",
      "\n",
      "    accuracy                           0.81       181\n",
      "   macro avg       0.51      0.54      0.48       181\n",
      "weighted avg       0.96      0.81      0.88       181\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.92      0.96       311\n",
      "\n",
      "    accuracy                           0.92       312\n",
      "   macro avg       0.50      0.46      0.48       312\n",
      "weighted avg       0.99      0.92      0.96       312\n",
      "\n",
      "XGB_  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00       311\n",
      "\n",
      "    accuracy                           1.00       312\n",
      "   macro avg       1.00      1.00      1.00       312\n",
      "weighted avg       1.00      1.00      1.00       312\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-02\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.86      0.92       311\n",
      "\n",
      "    accuracy                           0.86       312\n",
      "   macro avg       0.50      0.43      0.46       312\n",
      "weighted avg       0.99      0.86      0.92       312\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.19      0.54      0.28        13\n",
      "           1       0.97      0.86      0.91       213\n",
      "\n",
      "    accuracy                           0.84       226\n",
      "   macro avg       0.58      0.70      0.60       226\n",
      "weighted avg       0.92      0.84      0.87       226\n",
      "\n",
      "XGB_  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.69      0.62        13\n",
      "           1       0.98      0.97      0.97       213\n",
      "\n",
      "    accuracy                           0.95       226\n",
      "   macro avg       0.77      0.83      0.80       226\n",
      "weighted avg       0.96      0.95      0.95       226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.31      0.15        13\n",
      "           1       0.95      0.83      0.88       213\n",
      "\n",
      "    accuracy                           0.80       226\n",
      "   macro avg       0.52      0.57      0.52       226\n",
      "weighted avg       0.90      0.80      0.84       226\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.84      0.91       243\n",
      "\n",
      "    accuracy                           0.84       244\n",
      "   macro avg       0.50      0.42      0.46       244\n",
      "weighted avg       0.99      0.84      0.91       244\n",
      "\n",
      "XGB_  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00       243\n",
      "\n",
      "    accuracy                           1.00       244\n",
      "   macro avg       1.00      1.00      1.00       244\n",
      "weighted avg       1.00      1.00      1.00       244\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-06\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.83      0.91       243\n",
      "\n",
      "    accuracy                           0.83       244\n",
      "   macro avg       0.50      0.42      0.45       244\n",
      "weighted avg       0.99      0.83      0.90       244\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.05      0.25      0.08         4\n",
      "           1       0.98      0.89      0.93       166\n",
      "\n",
      "    accuracy                           0.87       170\n",
      "   macro avg       0.52      0.57      0.51       170\n",
      "weighted avg       0.96      0.87      0.91       170\n",
      "\n",
      "XGB_  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00       166\n",
      "\n",
      "    accuracy                           1.00       170\n",
      "   macro avg       1.00      1.00      1.00       170\n",
      "weighted avg       1.00      1.00      1.00       170\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-07-30\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.25      0.07         4\n",
      "           1       0.98      0.86      0.91       166\n",
      "\n",
      "    accuracy                           0.84       170\n",
      "   macro avg       0.51      0.55      0.49       170\n",
      "weighted avg       0.96      0.84      0.89       170\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.70      0.56        10\n",
      "           1       0.94      0.85      0.90        55\n",
      "\n",
      "    accuracy                           0.83        65\n",
      "   macro avg       0.70      0.78      0.73        65\n",
      "weighted avg       0.87      0.83      0.84        65\n",
      "\n",
      "XGB_  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      1.00      0.80        10\n",
      "           1       1.00      0.91      0.95        55\n",
      "\n",
      "    accuracy                           0.92        65\n",
      "   macro avg       0.83      0.95      0.88        65\n",
      "weighted avg       0.95      0.92      0.93        65\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.20      0.18        10\n",
      "           1       0.85      0.82      0.83        55\n",
      "\n",
      "    accuracy                           0.72        65\n",
      "   macro avg       0.51      0.51      0.51        65\n",
      "weighted avg       0.74      0.72      0.73        65\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.09      0.80      0.16         5\n",
      "           1       1.00      0.86      0.92       287\n",
      "\n",
      "    accuracy                           0.86       292\n",
      "   macro avg       0.54      0.83      0.54       292\n",
      "weighted avg       0.98      0.86      0.91       292\n",
      "\n",
      "XGB_  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         5\n",
      "           1       1.00      1.00      1.00       287\n",
      "\n",
      "    accuracy                           1.00       292\n",
      "   macro avg       1.00      1.00      1.00       292\n",
      "weighted avg       1.00      1.00      1.00       292\n",
      "\n",
      "LR_  4      2022-08-05\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.20      0.04         5\n",
      "           1       0.98      0.85      0.91       287\n",
      "\n",
      "    accuracy                           0.84       292\n",
      "   macro avg       0.50      0.53      0.48       292\n",
      "weighted avg       0.97      0.84      0.90       292\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.50      0.04         2\n",
      "           1       1.00      0.80      0.89       266\n",
      "\n",
      "    accuracy                           0.80       268\n",
      "   macro avg       0.51      0.65      0.46       268\n",
      "weighted avg       0.99      0.80      0.88       268\n",
      "\n",
      "XGB_  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         2\n",
      "           1       1.00      0.99      1.00       266\n",
      "\n",
      "    accuracy                           0.99       268\n",
      "   macro avg       0.75      1.00      0.83       268\n",
      "weighted avg       1.00      0.99      0.99       268\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      1.00      0.08         2\n",
      "           1       1.00      0.82      0.90       266\n",
      "\n",
      "    accuracy                           0.82       268\n",
      "   macro avg       0.52      0.91      0.49       268\n",
      "weighted avg       0.99      0.82      0.89       268\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.71      0.71         7\n",
      "           1       0.98      0.98      0.98       104\n",
      "\n",
      "    accuracy                           0.96       111\n",
      "   macro avg       0.85      0.85      0.85       111\n",
      "weighted avg       0.96      0.96      0.96       111\n",
      "\n",
      "XGB_  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00       104\n",
      "\n",
      "    accuracy                           1.00       111\n",
      "   macro avg       1.00      1.00      1.00       111\n",
      "weighted avg       1.00      1.00      1.00       111\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-01\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.29      0.36         7\n",
      "           1       0.95      0.98      0.97       104\n",
      "\n",
      "    accuracy                           0.94       111\n",
      "   macro avg       0.73      0.63      0.67       111\n",
      "weighted avg       0.92      0.94      0.93       111\n",
      "\n",
      "Train:  ['P19.csv', 'P31.csv', 'P25.csv', 'P30.csv', 'P18.csv', 'P33.csv', 'P27.csv', 'P23.csv', 'P36.csv', 'P34.csv', 'P20.csv', 'P21.csv', 'P35.csv', 'P38.csv', 'P10.csv', 'P13.csv', 'P12.csv', 'P16.csv', 'P17.csv', 'P15.csv', 'P29.csv', 'P28.csv', 'P14.csv']\n",
      "Test:  ['P08.csv', 'P24.csv']\n",
      "knn  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.75      0.23         4\n",
      "           1       0.99      0.80      0.88        94\n",
      "\n",
      "    accuracy                           0.80        98\n",
      "   macro avg       0.56      0.77      0.56        98\n",
      "weighted avg       0.95      0.80      0.86        98\n",
      "\n",
      "XGB_  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         4\n",
      "           1       1.00      1.00      1.00        94\n",
      "\n",
      "    accuracy                           1.00        98\n",
      "   macro avg       1.00      1.00      1.00        98\n",
      "weighted avg       1.00      1.00      1.00        98\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/khangphan/anaconda3/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR_  4      2022-08-11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.11      0.75      0.19         4\n",
      "           1       0.99      0.74      0.85        94\n",
      "\n",
      "    accuracy                           0.74        98\n",
      "   macro avg       0.55      0.75      0.52        98\n",
      "weighted avg       0.95      0.74      0.82        98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,\\\n",
    "f1_score,precision_score,recall_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "k=1\n",
    "\n",
    "# f1=[]\n",
    "# accuracy=[]\n",
    "# precision=[]\n",
    "# recall=[]\n",
    "# roc_auc=[]\n",
    "# model=[]\n",
    "# testPersons=[['P31.csv','P19.csv'],\n",
    "#             ['P14.csv','P24.csv'],\n",
    "#             ['P13.csv','P30.csv'],\n",
    "#             ['P31.csv','P18.csv'],\n",
    "#             ['P08.csv','P24.csv']]\n",
    "sm=SMOTE()\n",
    "j=True\n",
    "for i in range(len(testPersons)):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # Scramble\n",
    "    random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "    only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "    only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "    both = [key for key, value in depression.items() if len(value) == 2]\n",
    "    # testPerson = ['08'] + ['24']#['16','08'] + ['24','30']\n",
    "#     testPerson = [str(random.choice(only0).split('.')[0].split('P')[1])] \\\n",
    "#     + [str(random.choice(only1).split('.')[0].split('P')[1])]\n",
    "#     # testPerson = [13,17]\n",
    "#     allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "#     trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "#     testPerson = random.sample(only0,k) \\\n",
    "#     + random.sample(only1,k)\n",
    "    testPerson=testPersons[i]\n",
    "    # testPerson = [13,17]\n",
    "    allPerson = contestants\n",
    "    trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "\n",
    "#     # Merge train data and shuffle\n",
    "#     train_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in trainPerson]\n",
    "#     merged_train = pd.concat(train_list, ignore_index=True)\n",
    "#     shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "#     test_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in testPerson]\n",
    "#     merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_test = shuffled_test.drop([ 'img_name'], axis = 1)\n",
    "    for num in trainPerson:\n",
    "        train = pd.read_csv(f'{base_path}/{num}')\n",
    "        train=train.set_index('img_name')\n",
    "        duplicate_rows = train.index.duplicated()\n",
    "        train=train.loc[~duplicate_rows,:]\n",
    "        train_addata=train.copy()\n",
    "        train=train.drop('level',axis=1)\n",
    "        add_data=train.copy()\n",
    "        \n",
    "        add_data=add_data.shift(1)\n",
    "        add_data.columns=[i.split('_')[0]+'_time_lag' for i in train.columns]\n",
    "        \n",
    "#         add_data2=add_data.shift(2)\n",
    "#         add_data2.columns=[i+'_prev2' for i in add_data.columns]\n",
    "\n",
    "        add_vel=add_data.diff(1)\n",
    "        add_vel.columns=[i+'_vel' for i in train.columns]\n",
    "        \n",
    "#         duplicate_rows = add_data.index.duplicated()\n",
    "        train_=pd.concat([train_addata,add_data],axis=1)\n",
    "        train_=train_.reset_index()\n",
    "        train_=train_.dropna()\n",
    "#         train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "        train_list.append(train_)#train_ for addition data\n",
    "    \n",
    "    merged_train = pd.concat(train_list, ignore_index=True)\n",
    "    shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    try:\n",
    "        shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "    except:pass   \n",
    "\n",
    "    for num in testPerson:\n",
    "        test = pd.read_csv(f'{base_path}/{num}')\n",
    "        test=test.set_index('img_name')\n",
    "        \n",
    "        \n",
    "        duplicate_rows = test.index.duplicated()\n",
    "        test=test.loc[~duplicate_rows,:]\n",
    "        test_add=test.copy()\n",
    "        test=test.drop('level',axis=1)\n",
    "        add_data=test.copy()\n",
    "        \n",
    "        add_data=add_data.shift(1)\n",
    "        add_data.columns=[i.split('_')[0]+'_time_lag' for i in test.columns]\n",
    "\n",
    "        add_vel=add_data.diff(1)\n",
    "        add_vel.columns=[i+'_vel' for i in test.columns]\n",
    "        \n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        test_=pd.concat([test_add,add_data],axis=1)\n",
    "        test_=test_.reset_index()\n",
    "        test_=test_.dropna()\n",
    "\n",
    "        test_list.append(test_)#test_ for addition data\n",
    "    merged_test = pd.concat(test_list, ignore_index=True)\n",
    "    shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    try:\n",
    "#         shuffled_test=shuffled_test.reset_index(drop=False)\n",
    "        shuffled_test['ts']=shuffled_test['img_name'].apply(lambda x :int(int(x.split('_')[-1][:-4])/1000))\n",
    "        shuffled_test['ts']=shuffled_test['ts'].apply(lambda x: datetime.datetime.fromtimestamp(x).date())\n",
    "        shuffled_test = shuffled_test.drop(['img_name'], axis = 1)\n",
    "        \n",
    "    except Exception as e:print(e)\n",
    "    for k in shuffled_test['ts'].unique():\n",
    "        add_train_from_test1,shuffled_test1=shuffled_test[shuffled_test['ts']<k],shuffled_test[shuffled_test['ts']==k]\n",
    "    #     add_train_from_test,shuffled_test=train_test_split(shuffled_test,test_size=0.5)\n",
    "        add_train_from_test1,shuffled_test1=add_train_from_test1.drop('ts',axis=1),shuffled_test1.drop('ts',axis=1)\n",
    "        shuffled_train=pd.concat([add_train_from_test1,shuffled_train],axis=0)\n",
    "\n",
    "        X_train, y_train = shuffled_train.drop('level', axis = 1), shuffled_train['level']\n",
    "\n",
    "        X_test, y_test = shuffled_test1.drop('level', axis = 1), shuffled_test1['level']\n",
    "        y_train =y_train.astype('category')\n",
    "        y_test =y_test.astype('category')\n",
    "        X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "        X_train=pd.DataFrame(X_train,columns=X_train.columns)\n",
    "        X_test=X_test[X_train.columns]\n",
    "        if shuffled_test1['level'].nunique()<2:\n",
    "            continue\n",
    "        # y_train=pd.DataFrame(y_train,columns=y_test.columns)\n",
    "        # Print train test contestants\n",
    "        print(\"Train: \", trainPerson)\n",
    "        print(\"Test: \", testPerson)\n",
    "        if j:\n",
    "            print(X_train.columns.T)\n",
    "            j=False\n",
    "\n",
    "        # Logistic Regression\n",
    "        # log_reg = LogisticRegression(max_iter=10000)\n",
    "        # log_reg.fit(X_train, y_train)\n",
    "        # log_reg_pred = log_reg.predict(X_test)\n",
    "        # log_reg_acc = classification_report(y_test, log_reg_pred)\n",
    "        # print(f\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "\n",
    "        # K-Nearest Neighbors (KNN)\n",
    "        knn = KNeighborsClassifier(n_neighbors=100, leaf_size=70)\n",
    "        knn.fit(X_train, y_train)\n",
    "        knn_pred = knn.predict(X_test)\n",
    "        knn_rp = classification_report(y_test, knn_pred)\n",
    "        accuracy.append(accuracy_score(y_test, knn_pred))\n",
    "        f1.append(f1_score(y_test, knn_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, knn_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, knn_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, knn_pred))\n",
    "        model.append('KNN_TL')\n",
    "        print('knn ',i,'    ', k)\n",
    "        print(knn_rp)\n",
    "\n",
    "\n",
    "    #     # Support Vector Machine (SVM)\n",
    "        svm =  XGBClassifier(n_estimators=100)#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "        svm.fit(X_train, y_train)\n",
    "        svm_pred = svm.predict(X_test)\n",
    "        svm_rp = classification_report(y_test, svm_pred)\n",
    "        accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "        f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "        model.append('XGB_TL')\n",
    "        print('XGB_ ',i,'    ', k)\n",
    "        print(svm_rp)\n",
    "\n",
    "\n",
    "        svm =  LogisticRegression()#SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "        svm.fit(X_train, y_train)\n",
    "        svm_pred = svm.predict(X_test)\n",
    "        svm_rp = classification_report(y_test, svm_pred)\n",
    "        accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "        f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "        precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "        recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "        roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "        model.append('LR_TL')\n",
    "        print('LR_ ',i,'    ', k)\n",
    "        print(svm_rp)\n",
    "\n",
    "    #     # Random Forest Classifier\n",
    "    #     rf = RandomForestClassifier(n_estimators=1000)\n",
    "    #     rf.fit(X_train, y_train)\n",
    "    #     rf_pred = rf.predict(X_test)\n",
    "    #     rf_acc = classification_report(y_test, rf_pred)\n",
    "    #     print('rf ',i)\n",
    "    #     print(rf_acc)\n",
    "\n",
    "    #     xgb = XGBClassifier(n_estimators=1000)\n",
    "    #     xgb.fit(X_train, y_train)\n",
    "    #     xgb_pred = xgb.predict(X_test)\n",
    "    #     xgb_acc = classification_report(y_test, xgb_pred)\n",
    "    #     print('xgb ',i)\n",
    "    #     print(xgb_acc)\n",
    "\n",
    "    #     # Neural Network (MLP Classifier)\n",
    "    #     mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000)\n",
    "    #     mlp.fit(X_train, y_train)\n",
    "    #     mlp_pred = mlp.predict(X_test)\n",
    "    #     mlp_acc = classification_report(y_test, mlp_pred)\n",
    "    #     print('MLP ',i)\n",
    "    #     print(mlp_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>KNN</th>\n",
       "      <th>KNN_TL</th>\n",
       "      <th>KNN_tlsd</th>\n",
       "      <th>LR</th>\n",
       "      <th>LR_TL</th>\n",
       "      <th>LR_tlsd</th>\n",
       "      <th>XGB</th>\n",
       "      <th>XGB_TL</th>\n",
       "      <th>XGB_tlsd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">f1</th>\n",
       "      <th>count</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.760260</td>\n",
       "      <td>0.792078</td>\n",
       "      <td>0.780998</td>\n",
       "      <td>0.724727</td>\n",
       "      <td>0.777192</td>\n",
       "      <td>0.828430</td>\n",
       "      <td>0.894146</td>\n",
       "      <td>0.932621</td>\n",
       "      <td>0.962547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.168753</td>\n",
       "      <td>0.155672</td>\n",
       "      <td>0.151586</td>\n",
       "      <td>0.177382</td>\n",
       "      <td>0.173184</td>\n",
       "      <td>0.165084</td>\n",
       "      <td>0.153602</td>\n",
       "      <td>0.116087</td>\n",
       "      <td>0.113739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.455742</td>\n",
       "      <td>0.456570</td>\n",
       "      <td>0.444191</td>\n",
       "      <td>0.370942</td>\n",
       "      <td>0.421028</td>\n",
       "      <td>0.392241</td>\n",
       "      <td>0.451138</td>\n",
       "      <td>0.626012</td>\n",
       "      <td>0.398046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.620241</td>\n",
       "      <td>0.693606</td>\n",
       "      <td>0.700063</td>\n",
       "      <td>0.588783</td>\n",
       "      <td>0.631192</td>\n",
       "      <td>0.788942</td>\n",
       "      <td>0.837862</td>\n",
       "      <td>0.914624</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.813767</td>\n",
       "      <td>0.835627</td>\n",
       "      <td>0.816495</td>\n",
       "      <td>0.767885</td>\n",
       "      <td>0.829106</td>\n",
       "      <td>0.880863</td>\n",
       "      <td>0.976823</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.896747</td>\n",
       "      <td>0.918689</td>\n",
       "      <td>0.906768</td>\n",
       "      <td>0.871678</td>\n",
       "      <td>0.919451</td>\n",
       "      <td>0.937757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">acccuracy</th>\n",
       "      <th>count</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.862852</td>\n",
       "      <td>0.889976</td>\n",
       "      <td>0.875658</td>\n",
       "      <td>0.823108</td>\n",
       "      <td>0.876076</td>\n",
       "      <td>0.918152</td>\n",
       "      <td>0.939201</td>\n",
       "      <td>0.962740</td>\n",
       "      <td>0.973247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.095136</td>\n",
       "      <td>0.073860</td>\n",
       "      <td>0.065836</td>\n",
       "      <td>0.113099</td>\n",
       "      <td>0.083616</td>\n",
       "      <td>0.069944</td>\n",
       "      <td>0.105713</td>\n",
       "      <td>0.077784</td>\n",
       "      <td>0.080582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.606796</td>\n",
       "      <td>0.723301</td>\n",
       "      <td>0.442424</td>\n",
       "      <td>0.592233</td>\n",
       "      <td>0.602837</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.669903</td>\n",
       "      <td>0.581281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.804585</td>\n",
       "      <td>0.842481</td>\n",
       "      <td>0.825535</td>\n",
       "      <td>0.758698</td>\n",
       "      <td>0.825193</td>\n",
       "      <td>0.891322</td>\n",
       "      <td>0.935462</td>\n",
       "      <td>0.965908</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.883866</td>\n",
       "      <td>0.907362</td>\n",
       "      <td>0.879272</td>\n",
       "      <td>0.834445</td>\n",
       "      <td>0.889650</td>\n",
       "      <td>0.929479</td>\n",
       "      <td>0.990473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.935061</td>\n",
       "      <td>0.941530</td>\n",
       "      <td>0.929323</td>\n",
       "      <td>0.901942</td>\n",
       "      <td>0.935321</td>\n",
       "      <td>0.958843</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">precision</th>\n",
       "      <th>count</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.767223</td>\n",
       "      <td>0.790194</td>\n",
       "      <td>0.776272</td>\n",
       "      <td>0.737663</td>\n",
       "      <td>0.777989</td>\n",
       "      <td>0.824631</td>\n",
       "      <td>0.889617</td>\n",
       "      <td>0.928865</td>\n",
       "      <td>0.965770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.162495</td>\n",
       "      <td>0.157330</td>\n",
       "      <td>0.149928</td>\n",
       "      <td>0.163139</td>\n",
       "      <td>0.166952</td>\n",
       "      <td>0.158977</td>\n",
       "      <td>0.151609</td>\n",
       "      <td>0.118517</td>\n",
       "      <td>0.094182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.497585</td>\n",
       "      <td>0.489637</td>\n",
       "      <td>0.497449</td>\n",
       "      <td>0.467593</td>\n",
       "      <td>0.493598</td>\n",
       "      <td>0.487013</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.601461</td>\n",
       "      <td>0.512568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.625218</td>\n",
       "      <td>0.658996</td>\n",
       "      <td>0.663364</td>\n",
       "      <td>0.592590</td>\n",
       "      <td>0.623329</td>\n",
       "      <td>0.748848</td>\n",
       "      <td>0.797379</td>\n",
       "      <td>0.883353</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.812029</td>\n",
       "      <td>0.835954</td>\n",
       "      <td>0.785727</td>\n",
       "      <td>0.757231</td>\n",
       "      <td>0.821004</td>\n",
       "      <td>0.880065</td>\n",
       "      <td>0.976862</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.895507</td>\n",
       "      <td>0.924510</td>\n",
       "      <td>0.903168</td>\n",
       "      <td>0.872659</td>\n",
       "      <td>0.922201</td>\n",
       "      <td>0.949224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">recall</th>\n",
       "      <th>count</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.819939</td>\n",
       "      <td>0.850760</td>\n",
       "      <td>0.865336</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.836758</td>\n",
       "      <td>0.872970</td>\n",
       "      <td>0.937527</td>\n",
       "      <td>0.955452</td>\n",
       "      <td>0.974362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.147311</td>\n",
       "      <td>0.135861</td>\n",
       "      <td>0.110987</td>\n",
       "      <td>0.157476</td>\n",
       "      <td>0.154991</td>\n",
       "      <td>0.145789</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.078735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.423868</td>\n",
       "      <td>0.421811</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.446502</td>\n",
       "      <td>0.622881</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>0.627706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.704812</td>\n",
       "      <td>0.817313</td>\n",
       "      <td>0.840983</td>\n",
       "      <td>0.742327</td>\n",
       "      <td>0.785279</td>\n",
       "      <td>0.866924</td>\n",
       "      <td>0.945202</td>\n",
       "      <td>0.963424</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.894463</td>\n",
       "      <td>0.899483</td>\n",
       "      <td>0.838511</td>\n",
       "      <td>0.892934</td>\n",
       "      <td>0.924767</td>\n",
       "      <td>0.993465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.936962</td>\n",
       "      <td>0.942542</td>\n",
       "      <td>0.929765</td>\n",
       "      <td>0.902310</td>\n",
       "      <td>0.944188</td>\n",
       "      <td>0.964411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">roc_auc</th>\n",
       "      <th>count</th>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.819939</td>\n",
       "      <td>0.850760</td>\n",
       "      <td>0.865336</td>\n",
       "      <td>0.794684</td>\n",
       "      <td>0.836758</td>\n",
       "      <td>0.872970</td>\n",
       "      <td>0.937527</td>\n",
       "      <td>0.955452</td>\n",
       "      <td>0.974362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.147311</td>\n",
       "      <td>0.135861</td>\n",
       "      <td>0.110987</td>\n",
       "      <td>0.157476</td>\n",
       "      <td>0.154991</td>\n",
       "      <td>0.145789</td>\n",
       "      <td>0.106054</td>\n",
       "      <td>0.086096</td>\n",
       "      <td>0.078735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.423868</td>\n",
       "      <td>0.421811</td>\n",
       "      <td>0.401235</td>\n",
       "      <td>0.358025</td>\n",
       "      <td>0.415638</td>\n",
       "      <td>0.446502</td>\n",
       "      <td>0.622881</td>\n",
       "      <td>0.653153</td>\n",
       "      <td>0.627706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.704812</td>\n",
       "      <td>0.817313</td>\n",
       "      <td>0.840983</td>\n",
       "      <td>0.742327</td>\n",
       "      <td>0.785279</td>\n",
       "      <td>0.866924</td>\n",
       "      <td>0.945202</td>\n",
       "      <td>0.963424</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.863597</td>\n",
       "      <td>0.894463</td>\n",
       "      <td>0.899483</td>\n",
       "      <td>0.838511</td>\n",
       "      <td>0.892934</td>\n",
       "      <td>0.924767</td>\n",
       "      <td>0.993465</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.936962</td>\n",
       "      <td>0.942542</td>\n",
       "      <td>0.929765</td>\n",
       "      <td>0.902310</td>\n",
       "      <td>0.944188</td>\n",
       "      <td>0.964411</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "model                  KNN     KNN_TL   KNN_tlsd         LR      LR_TL  \\\n",
       "f1        count  68.000000  68.000000  68.000000  68.000000  68.000000   \n",
       "          mean    0.760260   0.792078   0.780998   0.724727   0.777192   \n",
       "          std     0.168753   0.155672   0.151586   0.177382   0.173184   \n",
       "          min     0.455742   0.456570   0.444191   0.370942   0.421028   \n",
       "          25%     0.620241   0.693606   0.700063   0.588783   0.631192   \n",
       "          50%     0.813767   0.835627   0.816495   0.767885   0.829106   \n",
       "          75%     0.896747   0.918689   0.906768   0.871678   0.919451   \n",
       "          max     1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "acccuracy count  68.000000  68.000000  68.000000  68.000000  68.000000   \n",
       "          mean    0.862852   0.889976   0.875658   0.823108   0.876076   \n",
       "          std     0.095136   0.073860   0.065836   0.113099   0.083616   \n",
       "          min     0.533333   0.606796   0.723301   0.442424   0.592233   \n",
       "          25%     0.804585   0.842481   0.825535   0.758698   0.825193   \n",
       "          50%     0.883866   0.907362   0.879272   0.834445   0.889650   \n",
       "          75%     0.935061   0.941530   0.929323   0.901942   0.935321   \n",
       "          max     1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "precision count  68.000000  68.000000  68.000000  68.000000  68.000000   \n",
       "          mean    0.767223   0.790194   0.776272   0.737663   0.777989   \n",
       "          std     0.162495   0.157330   0.149928   0.163139   0.166952   \n",
       "          min     0.497585   0.489637   0.497449   0.467593   0.493598   \n",
       "          25%     0.625218   0.658996   0.663364   0.592590   0.623329   \n",
       "          50%     0.812029   0.835954   0.785727   0.757231   0.821004   \n",
       "          75%     0.895507   0.924510   0.903168   0.872659   0.922201   \n",
       "          max     1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "recall    count  68.000000  68.000000  68.000000  68.000000  68.000000   \n",
       "          mean    0.819939   0.850760   0.865336   0.794684   0.836758   \n",
       "          std     0.147311   0.135861   0.110987   0.157476   0.154991   \n",
       "          min     0.423868   0.421811   0.401235   0.358025   0.415638   \n",
       "          25%     0.704812   0.817313   0.840983   0.742327   0.785279   \n",
       "          50%     0.863597   0.894463   0.899483   0.838511   0.892934   \n",
       "          75%     0.936962   0.942542   0.929765   0.902310   0.944188   \n",
       "          max     1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "roc_auc   count  68.000000  68.000000  68.000000  68.000000  68.000000   \n",
       "          mean    0.819939   0.850760   0.865336   0.794684   0.836758   \n",
       "          std     0.147311   0.135861   0.110987   0.157476   0.154991   \n",
       "          min     0.423868   0.421811   0.401235   0.358025   0.415638   \n",
       "          25%     0.704812   0.817313   0.840983   0.742327   0.785279   \n",
       "          50%     0.863597   0.894463   0.899483   0.838511   0.892934   \n",
       "          75%     0.936962   0.942542   0.929765   0.902310   0.944188   \n",
       "          max     1.000000   1.000000   1.000000   1.000000   1.000000   \n",
       "\n",
       "model              LR_tlsd        XGB     XGB_TL   XGB_tlsd  \n",
       "f1        count  68.000000  68.000000  68.000000  68.000000  \n",
       "          mean    0.828430   0.894146   0.932621   0.962547  \n",
       "          std     0.165084   0.153602   0.116087   0.113739  \n",
       "          min     0.392241   0.451138   0.626012   0.398046  \n",
       "          25%     0.788942   0.837862   0.914624   1.000000  \n",
       "          50%     0.880863   0.976823   1.000000   1.000000  \n",
       "          75%     0.937757   1.000000   1.000000   1.000000  \n",
       "          max     1.000000   1.000000   1.000000   1.000000  \n",
       "acccuracy count  68.000000  68.000000  68.000000  68.000000  \n",
       "          mean    0.918152   0.939201   0.962740   0.973247  \n",
       "          std     0.069944   0.105713   0.077784   0.080582  \n",
       "          min     0.602837   0.454545   0.669903   0.581281  \n",
       "          25%     0.891322   0.935462   0.965908   1.000000  \n",
       "          50%     0.929479   0.990473   1.000000   1.000000  \n",
       "          75%     0.958843   1.000000   1.000000   1.000000  \n",
       "          max     1.000000   1.000000   1.000000   1.000000  \n",
       "precision count  68.000000  68.000000  68.000000  68.000000  \n",
       "          mean    0.824631   0.889617   0.928865   0.965770  \n",
       "          std     0.158977   0.151609   0.118517   0.094182  \n",
       "          min     0.487013   0.527778   0.601461   0.512568  \n",
       "          25%     0.748848   0.797379   0.883353   1.000000  \n",
       "          50%     0.880065   0.976862   1.000000   1.000000  \n",
       "          75%     0.949224   1.000000   1.000000   1.000000  \n",
       "          max     1.000000   1.000000   1.000000   1.000000  \n",
       "recall    count  68.000000  68.000000  68.000000  68.000000  \n",
       "          mean    0.872970   0.937527   0.955452   0.974362  \n",
       "          std     0.145789   0.106054   0.086096   0.078735  \n",
       "          min     0.446502   0.622881   0.653153   0.627706  \n",
       "          25%     0.866924   0.945202   0.963424   1.000000  \n",
       "          50%     0.924767   0.993465   1.000000   1.000000  \n",
       "          75%     0.964411   1.000000   1.000000   1.000000  \n",
       "          max     1.000000   1.000000   1.000000   1.000000  \n",
       "roc_auc   count  68.000000  68.000000  68.000000  68.000000  \n",
       "          mean    0.872970   0.937527   0.955452   0.974362  \n",
       "          std     0.145789   0.106054   0.086096   0.078735  \n",
       "          min     0.446502   0.622881   0.653153   0.627706  \n",
       "          25%     0.866924   0.945202   0.963424   1.000000  \n",
       "          50%     0.924767   0.993465   1.000000   1.000000  \n",
       "          75%     0.964411   1.000000   1.000000   1.000000  \n",
       "          max     1.000000   1.000000   1.000000   1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df_result=pd.DataFrame(np.array([f1,accuracy,precision,recall,roc_auc,model]).T,\n",
    "                       columns=['f1','acccuracy','precision','recall','roc_auc','model'])\n",
    "df_result2=df_result.iloc[:,:-1].astype(float)\n",
    "df_result2['model']=df_result['model']\n",
    "df_result2.groupby('model').describe().T.to_csv('./result.csv')\n",
    "df_result2.groupby('model').describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Input_Features       p_values\n",
      "0                anger   0.000000e+00\n",
      "28    disgust_time_lag   0.000000e+00\n",
      "29       fear_time_lag   0.000000e+00\n",
      "30  happiness_time_lag   0.000000e+00\n",
      "31    sadness_time_lag   0.000000e+00\n",
      "32   surprise_time_lag   0.000000e+00\n",
      "34       AU01_time_lag   0.000000e+00\n",
      "35       AU02_time_lag   0.000000e+00\n",
      "37       AU05_time_lag   0.000000e+00\n",
      "38       AU06_time_lag   0.000000e+00\n",
      "39       AU07_time_lag   0.000000e+00\n",
      "40       AU09_time_lag   0.000000e+00\n",
      "41       AU10_time_lag   0.000000e+00\n",
      "43       AU12_time_lag   0.000000e+00\n",
      "44       AU14_time_lag   0.000000e+00\n",
      "45       AU15_time_lag   0.000000e+00\n",
      "47       AU20_time_lag   0.000000e+00\n",
      "48       AU23_time_lag   0.000000e+00\n",
      "49       AU24_time_lag   0.000000e+00\n",
      "50       AU25_time_lag   0.000000e+00\n",
      "23                AU25   0.000000e+00\n",
      "22                AU24   0.000000e+00\n",
      "26                AU43   0.000000e+00\n",
      "20                AU20   0.000000e+00\n",
      "1              disgust   0.000000e+00\n",
      "2                 fear   0.000000e+00\n",
      "3            happiness   0.000000e+00\n",
      "4              sadness   0.000000e+00\n",
      "5             surprise   0.000000e+00\n",
      "7                 AU01   0.000000e+00\n",
      "8                 AU02   0.000000e+00\n",
      "10                AU05   0.000000e+00\n",
      "21                AU23   0.000000e+00\n",
      "12                AU07   0.000000e+00\n",
      "13                AU09   0.000000e+00\n",
      "11                AU06   0.000000e+00\n",
      "53       AU43_time_lag   0.000000e+00\n",
      "16                AU12   0.000000e+00\n",
      "17                AU14   0.000000e+00\n",
      "14                AU10   0.000000e+00\n",
      "18                AU15   0.000000e+00\n",
      "24                AU26  1.529133e-320\n",
      "51       AU26_time_lag  1.662114e-303\n",
      "27      anger_time_lag  4.582707e-297\n",
      "6              neutral  1.228863e-175\n",
      "33    neutral_time_lag  1.952978e-130\n",
      "25                AU28  4.810358e-124\n",
      "52       AU28_time_lag  4.850212e-110\n",
      "9                 AU04   5.746487e-37\n",
      "36       AU04_time_lag   5.646746e-30\n",
      "42       AU11_time_lag   3.644592e-11\n",
      "15                AU11   7.778804e-03\n",
      "46       AU17_time_lag   1.758212e-01\n",
      "19                AU17   4.542587e-01\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest,f_regression\n",
    "fs = SelectKBest(score_func=f_regression,k=15)\n",
    "# Applying feature selection\n",
    "fit = fs.fit(X_train,y_train)\n",
    "features_score = pd.DataFrame(fit.pvalues_)\n",
    "features = pd.DataFrame(X_train.columns)\n",
    "feature_score = pd.concat([features,features_score],axis=1)\n",
    "# Assigning column names\n",
    "feature_score.columns = [\"Input_Features\",\"p_values\"]\n",
    "feature_score=feature_score.sort_values('p_values', ascending=True)\n",
    "print(feature_score.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_group(x):\n",
    "    if 'lag' in x :\n",
    "        return \"Time Lag\"\n",
    "    if 'vel' in x:\n",
    "        return \"Succesive Different\"\n",
    "    if 'AU' in x:\n",
    "        return \"AU\"\n",
    "    if x in ['fear','neutral','happiness','surprise','sadness','anger','disgust']:\n",
    "        return \"Emotion\"\n",
    "    return \"Facial Characteristic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Input_Features       p_values Feature Type\n",
      "0                anger   0.000000e+00      Emotion\n",
      "28    disgust_time_lag   0.000000e+00     Time Lag\n",
      "29       fear_time_lag   0.000000e+00     Time Lag\n",
      "30  happiness_time_lag   0.000000e+00     Time Lag\n",
      "31    sadness_time_lag   0.000000e+00     Time Lag\n",
      "32   surprise_time_lag   0.000000e+00     Time Lag\n",
      "34       AU01_time_lag   0.000000e+00     Time Lag\n",
      "35       AU02_time_lag   0.000000e+00     Time Lag\n",
      "37       AU05_time_lag   0.000000e+00     Time Lag\n",
      "38       AU06_time_lag   0.000000e+00     Time Lag\n",
      "39       AU07_time_lag   0.000000e+00     Time Lag\n",
      "40       AU09_time_lag   0.000000e+00     Time Lag\n",
      "41       AU10_time_lag   0.000000e+00     Time Lag\n",
      "43       AU12_time_lag   0.000000e+00     Time Lag\n",
      "44       AU14_time_lag   0.000000e+00     Time Lag\n",
      "45       AU15_time_lag   0.000000e+00     Time Lag\n",
      "47       AU20_time_lag   0.000000e+00     Time Lag\n",
      "48       AU23_time_lag   0.000000e+00     Time Lag\n",
      "49       AU24_time_lag   0.000000e+00     Time Lag\n",
      "50       AU25_time_lag   0.000000e+00     Time Lag\n",
      "23                AU25   0.000000e+00           AU\n",
      "22                AU24   0.000000e+00           AU\n",
      "26                AU43   0.000000e+00           AU\n",
      "20                AU20   0.000000e+00           AU\n",
      "1              disgust   0.000000e+00      Emotion\n",
      "2                 fear   0.000000e+00      Emotion\n",
      "3            happiness   0.000000e+00      Emotion\n",
      "4              sadness   0.000000e+00      Emotion\n",
      "5             surprise   0.000000e+00      Emotion\n",
      "7                 AU01   0.000000e+00           AU\n",
      "8                 AU02   0.000000e+00           AU\n",
      "10                AU05   0.000000e+00           AU\n",
      "21                AU23   0.000000e+00           AU\n",
      "12                AU07   0.000000e+00           AU\n",
      "13                AU09   0.000000e+00           AU\n",
      "11                AU06   0.000000e+00           AU\n",
      "53       AU43_time_lag   0.000000e+00     Time Lag\n",
      "16                AU12   0.000000e+00           AU\n",
      "17                AU14   0.000000e+00           AU\n",
      "14                AU10   0.000000e+00           AU\n",
      "18                AU15   0.000000e+00           AU\n",
      "24                AU26  1.529133e-320           AU\n",
      "51       AU26_time_lag  1.662114e-303     Time Lag\n",
      "27      anger_time_lag  4.582707e-297     Time Lag\n",
      "6              neutral  1.228863e-175      Emotion\n",
      "33    neutral_time_lag  1.952978e-130     Time Lag\n",
      "25                AU28  4.810358e-124           AU\n",
      "52       AU28_time_lag  4.850212e-110     Time Lag\n",
      "9                 AU04   5.746487e-37           AU\n",
      "36       AU04_time_lag   5.646746e-30     Time Lag\n",
      "42       AU11_time_lag   3.644592e-11     Time Lag\n",
      "15                AU11   7.778804e-03           AU\n",
      "46       AU17_time_lag   1.758212e-01     Time Lag\n",
      "19                AU17   4.542587e-01           AU\n",
      "13                AU09   0.000000e+00           AU\n",
      "22                AU24   0.000000e+00           AU\n",
      "21                AU23   0.000000e+00           AU\n",
      "20                AU20   0.000000e+00           AU\n",
      "18                AU15   0.000000e+00           AU\n",
      "17                AU14   0.000000e+00           AU\n",
      "16                AU12   0.000000e+00           AU\n",
      "14                AU10   0.000000e+00           AU\n",
      "12                AU07   0.000000e+00           AU\n",
      "11                AU06   0.000000e+00           AU\n",
      "26                AU43   0.000000e+00           AU\n",
      "8                 AU02   0.000000e+00           AU\n",
      "7                 AU01   0.000000e+00           AU\n",
      "5             surprise   0.000000e+00      Emotion\n",
      "4              sadness   0.000000e+00      Emotion\n",
      "3            happiness   0.000000e+00      Emotion\n",
      "2                 fear   0.000000e+00      Emotion\n",
      "10                AU05   0.000000e+00           AU\n",
      "1              disgust  1.091137e-294      Emotion\n",
      "23                AU25  2.232551e-271           AU\n",
      "0                anger  2.854946e-204      Emotion\n",
      "24                AU26  3.511564e-166           AU\n",
      "25                AU28   5.249707e-88           AU\n",
      "6              neutral   2.150164e-86      Emotion\n",
      "9                 AU04   2.130099e-36           AU\n",
      "15                AU11   5.995356e-02           AU\n",
      "19                AU17   2.759135e-01           AU\n"
     ]
    }
   ],
   "source": [
    "feature_score_all=pd.concat([feature_score,feature_score1],axis=0)\n",
    "# feature_score_all=feature_score_all.drop_duplicates()\n",
    "feature_score_all['Feature Type']=feature_score_all['Input_Features'].apply(to_group)\n",
    "print(feature_score_all.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(feature_score_all,y='Feature Type',x='p_values',hue='Feature Type')\n",
    "plt.savefig('./image_paper/p_value.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shap\n",
    "# # Create the explainer\n",
    "# explainer1 = shap.Explainer(xgb,X_train)#model_smotesvm\n",
    "\n",
    "# shap_values = explainer1(X_train, check_additivity=False)\n",
    "# print(\"Variable Importance Plot - Global Interpretation\")\n",
    "# # figure = plt.figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap.plots.beeswarm(shap_values,max_display=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat=feature_score['Input_Features'].to_list()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for num in ['P19.csv']:\n",
    "#     train = pd.read_csv(f'{base_path}/{num}')\n",
    "#     train=train.set_index('img_name')\n",
    "#     duplicate_rows = train.index.duplicated()\n",
    "#     train=train.loc[~duplicate_rows,:]\n",
    "#     add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "#     add_data=add_data.drop('Unnamed: 0',axis=1)\n",
    "#     add_data=add_data.set_index('img_name')\n",
    "#     duplicate_rows = add_data.index.duplicated()\n",
    "#     add_data=add_data.loc[~duplicate_rows,:]\n",
    "#     train_=pd.concat([add_data,train],axis=1)\n",
    "#     train_=train_.reset_index()\n",
    "#     train_=train_.dropna()\n",
    "#     train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['disgust_time_lag', 'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag', 'surprise_time_lag', 'AU01_time_lag', 'AU02_time_lag', 'AU05_time_lag', 'AU06_time_lag', 'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 98\u001b[0m\n\u001b[1;32m     96\u001b[0m y_train \u001b[38;5;241m=\u001b[39my_train\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     97\u001b[0m y_test \u001b[38;5;241m=\u001b[39my_test\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategory\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 98\u001b[0m X_train\u001b[38;5;241m=\u001b[39m\u001b[43mX_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfeat\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     99\u001b[0m X_test\u001b[38;5;241m=\u001b[39mX_test[feat]\n\u001b[1;32m    100\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[1;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[0;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[1;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[0;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[1;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[1;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/pandas/core/indexes/base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[0;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['disgust_time_lag', 'fear_time_lag', 'happiness_time_lag', 'sadness_time_lag', 'surprise_time_lag', 'AU01_time_lag', 'AU02_time_lag', 'AU05_time_lag', 'AU06_time_lag', 'AU07_time_lag', 'AU09_time_lag', 'AU10_time_lag', 'AU12_time_lag', 'AU14_time_lag', 'AU15_time_lag', 'AU20_time_lag', 'AU23_time_lag', 'AU24_time_lag', 'AU25_time_lag'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsTransformer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,\\\n",
    "f1_score,precision_score,recall_score,roc_auc_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "k=1\n",
    "\n",
    "# f1=[]\n",
    "# accuracy=[]\n",
    "# precision=[]\n",
    "# recall=[]\n",
    "# roc_auc=[]\n",
    "# model=[]\n",
    "sm=SMOTE()\n",
    "for i in range(5):\n",
    "    train_list=[]\n",
    "    test_list=[]\n",
    "    # Scramble\n",
    "    random.seed(int.from_bytes(os.urandom(4), 'big'))\n",
    "    only1 = [key for key, value in depression.items() if value[0] == 1 and len(value) == 1]\n",
    "    only0 = [key for key, value in depression.items() if value[0] == 0 and len(value) == 1]\n",
    "    both = [key for key, value in depression.items() if len(value) == 2]\n",
    "    # testPerson = ['08'] + ['24']#['16','08'] + ['24','30']\n",
    "#     testPerson = [str(random.choice(only0).split('.')[0].split('P')[1])] \\\n",
    "#     + [str(random.choice(only1).split('.')[0].split('P')[1])]\n",
    "#     # testPerson = [13,17]\n",
    "#     allPerson = [int(a.split('.')[0].split('P')[1]) for a in contestants]\n",
    "#     trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "    testPerson = random.sample(only0,k) \\\n",
    "    + random.sample(only1,k)\n",
    "    # testPerson = [13,17]\n",
    "    allPerson = contestants\n",
    "    trainPerson = [a for a in allPerson if str(a) not in testPerson]\n",
    "\n",
    "#     # Merge train data and shuffle\n",
    "#     train_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in trainPerson]\n",
    "#     merged_train = pd.concat(train_list, ignore_index=True)\n",
    "#     shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "#     test_list = [pd.read_csv(f'{base_path}/P{str(num).zfill(2)}.csv') for num in testPerson]\n",
    "#     merged_test = pd.concat(test_list, ignore_index=True)\n",
    "#     shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "#     shuffled_test = shuffled_test.drop([ 'img_name'], axis = 1)\n",
    "    for num in trainPerson:\n",
    "        train = pd.read_csv(f'{base_path}/{num}')\n",
    "        train=train.set_index('img_name')\n",
    "        duplicate_rows = train.index.duplicated()\n",
    "        train=train.loc[~duplicate_rows,:]\n",
    "        add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "        add_data=add_data.drop(['Unnamed: 0','level'],axis=1)\n",
    "        add_data=add_data.set_index('img_name')\n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        train_=pd.concat([train,add_data],axis=1)\n",
    "        train_=train_.reset_index()\n",
    "        train_=train_.dropna()\n",
    "        train_=train_.drop(['timestamp','ID'],axis=1)\n",
    "        train_list.append(train_)\n",
    "    \n",
    "    merged_train = pd.concat(train_list, ignore_index=True)\n",
    "    shuffled_train = merged_train.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    shuffled_train = shuffled_train.drop([ 'img_name'], axis = 1)\n",
    "\n",
    "    for num in testPerson:\n",
    "        test = pd.read_csv(f'{base_path}/{num}')\n",
    "        test=test.set_index('img_name')\n",
    "        duplicate_rows = test.index.duplicated()\n",
    "        test=test.loc[~duplicate_rows,:]\n",
    "        add_data=pd.read_csv(f'{add_data_path}/{num}')\n",
    "        add_data=add_data.drop(['Unnamed: 0','level'],axis=1)\n",
    "        add_data=add_data.set_index('img_name')\n",
    "        duplicate_rows = add_data.index.duplicated()\n",
    "        add_data=add_data.loc[~duplicate_rows,:]\n",
    "        test_=pd.concat([test,add_data],axis=1)\n",
    "        test_=test_.reset_index()\n",
    "        test_=test_.dropna()\n",
    "        test_=test_.drop(['timestamp','ID'],axis=1)\n",
    "        test_list.append(test_)\n",
    "    merged_test = pd.concat(test_list, ignore_index=True)\n",
    "    shuffled_test = merged_test.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    shuffled_test = shuffled_test.drop(['img_name'], axis = 1)\n",
    "\n",
    "    X_train, y_train = shuffled_train.drop('level', axis = 1), shuffled_train['level']\n",
    "\n",
    "    X_test, y_test = shuffled_test.drop('level', axis = 1), shuffled_test['level']\n",
    "    y_train =y_train.astype('category')\n",
    "    y_test =y_test.astype('category')\n",
    "    X_train=X_train[feat]\n",
    "    X_test=X_test[feat]\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    X_train=pd.DataFrame(X_train,columns=X_test.columns)\n",
    "    # y_train=pd.DataFrame(y_train,columns=y_test.columns)\n",
    "    # Print train test contestants\n",
    "    print(\"Train: \", trainPerson)\n",
    "    print(\"Test: \", testPerson)\n",
    "    \n",
    "\n",
    "    # Logistic Regression\n",
    "    # log_reg = LogisticRegression(max_iter=10000)\n",
    "    # log_reg.fit(X_train, y_train)\n",
    "    # log_reg_pred = log_reg.predict(X_test)\n",
    "    # log_reg_acc = classification_report(y_test, log_reg_pred)\n",
    "    # print(f\"Logistic Regression Accuracy:\", log_reg_acc)\n",
    "\n",
    "    # K-Nearest Neighbors (KNN)\n",
    "    knn = KNeighborsClassifier(n_neighbors=100)\n",
    "    knn.fit(X_train, y_train)\n",
    "    knn_pred = knn.predict(X_test)\n",
    "    knn_rp = classification_report(y_test, knn_pred)\n",
    "    accuracy.append(accuracy_score(y_test, knn_pred))\n",
    "    f1.append(f1_score(y_test, knn_pred,average='macro'))\n",
    "    precision.append(precision_score(y_test, knn_pred,average='macro'))\n",
    "    recall.append(recall_score(y_test, knn_pred,average='macro'))\n",
    "    roc_auc.append(roc_auc_score(y_test, knn_pred))\n",
    "    model.append('KNN')\n",
    "    print('knn ',i)\n",
    "    print(knn_rp)\n",
    "    \n",
    "    \n",
    "#     # Support Vector Machine (SVM)\n",
    "#     svm = SVC(kernel='rbf')  # You can also try 'rbf' or 'poly'\n",
    "#     svm.fit(X_train, y_train)\n",
    "#     svm_pred = svm.predict(X_test)\n",
    "#     svm_rp = classification_report(y_test, svm_pred)\n",
    "#     accuracy.append(accuracy_score(y_test, svm_pred))\n",
    "#     f1.append(f1_score(y_test, svm_pred,average='macro'))\n",
    "#     precision.append(precision_score(y_test, svm_pred,average='macro'))\n",
    "#     recall.append(recall_score(y_test, svm_pred,average='macro'))\n",
    "#     roc_auc.append(roc_auc_score(y_test, svm_pred))\n",
    "#     model.append('SVM')\n",
    "#     print('SVM ',i)\n",
    "#     print(svm_rp)\n",
    "\n",
    "#     # Random Forest Classifier\n",
    "#     rf = RandomForestClassifier(n_estimators=1000)\n",
    "#     rf.fit(X_train, y_train)\n",
    "#     rf_pred = rf.predict(X_test)\n",
    "#     rf_acc = classification_report(y_test, rf_pred)\n",
    "#     print('rf ',i)\n",
    "#     print(rf_acc)\n",
    "\n",
    "#     xgb = XGBClassifier(n_estimators=1000)\n",
    "#     xgb.fit(X_train, y_train)\n",
    "#     xgb_pred = xgb.predict(X_test)\n",
    "#     xgb_acc = classification_report(y_test, xgb_pred)\n",
    "#     print('xgb ',i)\n",
    "#     print(xgb_acc)\n",
    "\n",
    "#     # Neural Network (MLP Classifier)\n",
    "#     mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=10000)\n",
    "#     mlp.fit(X_train, y_train)\n",
    "#     mlp_pred = mlp.predict(X_test)\n",
    "#     mlp_acc = classification_report(y_test, mlp_pred)\n",
    "#     print('MLP ',i)\n",
    "#     print(mlp_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result=pd.DataFrame(np.array([f1,accuracy,precision,recall,roc_auc,model]).T,\n",
    "                       columns=['f1','acccuracy','precision','recall','roc_auc','model'])\n",
    "df_result2=df_result.iloc[:,:-1].astype(float)\n",
    "df_result2['model']=df_result['model']\n",
    "df_result2.groupby('model').describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:40:54.373921Z",
     "iopub.status.busy": "2025-02-02T19:40:54.373592Z",
     "iopub.status.idle": "2025-02-02T19:40:54.379421Z",
     "shell.execute_reply": "2025-02-02T19:40:54.378589Z",
     "shell.execute_reply.started": "2025-02-02T19:40:54.373896Z"
    }
   },
   "outputs": [],
   "source": [
    "(only0, only1, both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "merged_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-02T19:45:05.965421Z",
     "iopub.status.busy": "2025-02-02T19:45:05.965087Z",
     "iopub.status.idle": "2025-02-02T19:45:06.018330Z",
     "shell.execute_reply": "2025-02-02T19:45:06.017393Z",
     "shell.execute_reply.started": "2025-02-02T19:45:05.965393Z"
    }
   },
   "outputs": [],
   "source": [
    "person_len = dict()\n",
    "for e in depression:\n",
    "    person_len[e] = len(pd.read_csv(f'{base_path}/{e}'))\n",
    "person_len = (sorted(person_len.items()))\n",
    "person_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6512233,
     "sourceId": 10529402,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
